\chapter*{Related Work}\label{sec:related-work}\addcontentsline{toc}{chapter}{Related Work}\markboth{Related Work}{Related Work}

In the realm of safe controlled memory updates for functional languages, \emph{functional data structures with holes} and \emph{destination passing} are two very close themes, since \emph{destination passing} provides a flexible and principled way to manipulate such structures. However, despite their conceptual overlap, \emph{functional destination passing} and \emph{functional data structures with holes} remain slightly distinct in their nature.

\emph{Functional destination passing} encompasses techniques where updates to write-once memory cells are exposed through a safe or at least controlled interface. In fact, in previous work, this interface has not often been directly exposed to programmers; instead, in these cases, \emph{destination passing} is employed internally by compilers to optimize functional programs. This includes performance improvements for functional linked data structures (Work~\labelcref{ssec:tmc}) and functional arrays (Work~\labelcref{ssec:shaikhha-dps}), which are written in the usual purely functional style but benefit from behind-the-scenes mutations to reduce allocations and improve performance, with no explicit user control. Ultimately, destinations can also be used in the operational semantics of a theoretical lambda-calculus (Work~\labelcref{ssec:sax}).

In contrast, \emph{functional structures with holes} focus on allowing incomplete data structures, a.k.a. structures with holes, to exist as first-class values---that the user can manipulate explicitely---in a purely functional setting, and be completed or refined later. Completing these structures necessarily involves some form of memory update, but many systems (Work~\labelcref{ssec:minamide,ssec:lorenzen-searchtree}) do not include an explicit notion of first-class write pointer (\emph{destination}) to do the mutation. In contrast, this thesis explores how both \emph{functional structures with holes} and \emph{functional destination passing} can be combined effectively, leveraging the strengths of each to achieve more expressive manipulation patterns of functional data, always in a safe manner.

Both of these notions inherently involve mutation and uninitialized data and therefore require robust static guarantees to ensure safety. \emph{Linear} and \emph{uniqueness type systems} are thus commonly employed to enforce strict control over destinations or structures with holes, preventing unsafe updates and premature reads on incomplete structures. However, as demonstrated in this work, \emph{linearity} alone is insufficient to capture the full range of safety and expressiveness we want. Modal type systems (Work~\labelcref{ssec:oxidizing}) are in that case particularly helpful to let us design a coherent and ergonomic type system, easily, for our specific needs. Complementary approaches such as \emph{permission-based type systems} (Work~\labelcref{ssec:mezzo}) and resource lifetime management techniques \emph{à la} Rust (Work~\labelcref{ssec:rust-lifetimes}) also play an important role to enforce fine-grained control over resources, which may be leveraged to control our destinations or structures with holes.

\section{Tail modulo constructor}\label{ssec:tmc}

\cite{bour_tmc_2021} focuses on the perennial problem that the map function on linked lists isn't tail-recursive, hence consumes stack space. The map function can be made tail recursive, but at the cost of an extra reverse operation on the list. Their observation is that there's a systematic transformation of functions where the only recursive call is under a data constructor application (e.g. \emph{cons} in the map instance) to a destination-passing tail-recursive implementation.

Here, there's no destination in user land, only in the intermediate representation. However, there is a programmatic interface: the programmer annotates a function like
\begin{verbatim}
let[@tail_mod_cons] rec map =
\end{verbatim}
to ask the compiler to perform the translation. The compiler will then throw an error if it can't, making the optimization behavior entirely predictable. This has been included in the OCaml compiler since version 4.14, and is the one example we know of destinations built in a production-grade functional compiler.

Both our \destcalculus{} and DPS Haskell API allow to write the result of a tail-modulo-constructor transformation (that is, the destination-passing tail-recursive program) as a well-typed program in userland, which isn't possible in OCaml. However, we don't provide a way to do a similar automatic transformation itself.

On the flip-side, tail modulo constructor is too weak to handle our difference lists, as it misses first-class support for structure with holes; they can only exist in the background for the duration of a function being transformed. The tail-modulo-constructor transformation also cannot be applied on our breadth-first tree traversal example (see \cref{sec:bft,ssec:bf-tree-traversal}).

\section{Destination-passing style for efficient memory management}\label{ssec:shaikhha-dps}

~\citet{shaikhha_destination-passing_2017} present a destination-based intermediate language for a functional array programming language, with destination-specific optimizations, that boasts near-C performance.

This another significant evidence to date of the benefits of destination-passing style for performance in functional languages, although their work is on array programming, while this PhD manuscript focuses on linked data structures. They can therefore benefit from optimizations that are perhaps less valuable for us, such as allocating one contiguous memory chunk for several arrays.

The other difference between their work and ours is that their language is solely an intermediate language: it would be unsound to program in it manually. We, on the other hand, are proposing a theoretical system, but also a concrete Haskell API to make it sound for the programmer to use destinations directly.

We see these two aspects as complementing each other: good compiler optimizations are important to alleviate the burden from the programmer and allow high-level abstraction; having the possibility to use destinations in code affords the programmer more control, should they need it.

\section{Semi-axiomatic sequent calculus}\label{ssec:sax}

In~\cite{deyoung_sax_2020} constructors return to a destination rather than allocating memory. It is very unlike the other systems described in this chapter in that it's completely founded in the Curry-Howard isomorphism. Specifically it gives an interpretation of a sequent calculus which mixes Gentzen-style deduction rules and Hilbert-style axioms. As a consequence, they feature a \emph{par} connective that is completely symmetric; and, unlike our $[[⌊ T ⌋ ¹ν]]$ type, their dualization connective is involutive.

The cost of this elegance is that computations may try to pattern-match on a hole, in which case they must wait for the hole to be filled. So the semantics of holes is that of a future or a promise. In turns this requires the semantics of their calculus to be fully concurrent, while \destcalculus{} only needs a sequential execution model, with a very tame form of state manipulation (linear substitutions on the evaluation context).

\section{A functional representation of data structures with a hole}\label{ssec:minamide}\label{ssec:ampar-motivation}

The idea of using linear types as a foundation of a functional calculus in which incomplete data structures can exist and be composed as first class values dates back to~\cite{minamide_functional_1998}. Our systems, both theoretically and in the implementations, are strongly inspired by theirs. In~\cite{minamide_functional_1998}, a first-class structure with a hole is called a \emph{hole abstraction}. Hole abstractions are represented by a special kind of linear functions with bespoke restrictions. As with any function, we can't pattern-match on their output (or pass it to another function) until they have been applied; but they also have the restriction that we cannot pattern-match on their argument---the \emph{hole variable}---as that one can only be used directly as argument of data constructors, or of other hole abstractions. The type of hole abstractions, $\ottstype{([[T]], [[S]]) hfun}$ is thus a weak form of linear function type $\ottstype{[[T]] \multimap [[S]]}$.

In~\cite{minamide_functional_1998}, it's only ever possible to represent structures with a single hole. But this is a rather superficial restriction. The author doesn't comment on this, but we believe that this restriction only exists for convenience of the exposition: the language is lowered to a language without function abstraction and where composition is performed by combinators and it's easier to write a combinator for single-argument-function composition.

However, we've seen in \cref{sec:linear-lens} that we can actually design combinators for structures with multiple holes, thanks to linear lenses (at the cost of some extra syntactic burden). So having multiple-hole data structures wouldn't have changed their system in any profound way.

The more important difference is that their system is based on a type of linear functions, while our systems in \cref{chap:dest-calculus,chap:dps-haskell} exploit the expressivity of the linear logic's ``par'' type. In classical linear logic, linear implication $\ottstype{[[T]] \multimap [[S]]}$ is reinterpreted as $\ottstype{[[S]]\mathop{\parr}[[T]]^{\perp}}$. We, likewise, reinterpret $\ottstype{([[T]], [[S]]) hfun}$ as $[[S ⧔ ⌊ T ⌋ ¹ν]]$ or \mintinline{haskellc}/Ampar s (Dest t)/ ---a sort of weak ``par''.

A key consequence is that destinations---as first-class representations of holes---appear naturally in \destcalculus{} or DPS Haskell, while~\cite{minamide_functional_1998} doesn't have them. This means that using~\cite{minamide_functional_1998}, one can implement the examples with difference lists and queues from \cref{ssec:efficient-queue,ssec:dpshaskell-dlist}, but couldn't do our breadth-first traversal example from \cref{sec:bft,ssec:bf-tree-traversal}, since it requires being able to store destinations in a structure.

Nevertheless, we still retain the main restrictions that~\citet{minamide_functional_1998} places on hole abstractions. For instance, we can't pattern-match on $[[S]]$ in (unapplied) $\ottstype{([[T]], [[S]]) hfun}$; so in \destcalculus{}, we can't act directly on the left-hand side $[[S]]$ of $[[S ⧔ T]]$, only on the right-hand side $[[T]]$ (the equivalent restrictions are also in place in DPS Haskell). Similarly, hole variables can only be used as arguments of constructors or hole abstractions; it's reflected in \destcalculus{} by the fact that the only way to act on destinations is via fill operations.

The ability to manipulate and, in particular, to store destinations does come at a cost: \destcalculus{} requires an additional notion of ages to ensure that destinations are used soundly across scopes. In the absence of such a mechanism, as in DPS Haskell, the use of linear destinations must be carefully constrained to preserve soundness. Despite these additional requirements, our systems---both theoretical and practical---are strictly more general than that of \citet{minamide_functional_1998}. Their system can be naturally embedded within \destcalculus{} (see \cref{sec:transl-minamide}) or expressed in DPS Haskell (see \cref{sec:single-hole}).

\section{Tail Recursion Modulo Context and The Functional Essence of Imperative Binary Search Trees}\label{ssec:lorenzen-searchtree}

The recent line of work from \citet{lorenzen_searchtree_2024,leijen_tail_2025} develops in two main axes. The first explores a generalization of Work~\labelcref{ssec:tmc}, by considering the \emph{tail-recursion modulo context} transformation, in which the \emph{context} can be instantiated in various forms. For example, when the context is a one-hole data constructor context---equivalent to the hole abstractions from Work~\labelcref{ssec:minamide}---they recover the \emph{tail-recursion modulo constructor} transformation. But the framework extends further: they are able to handle monoids contexts, semirings contexts, exponentials contexts, and more. Hence, it allows the transformation of a broader class of typically non-tail-recursive functions into efficient tail-recursive equivalents, via a formalized and systematic method, surpassing the scope of the transformation described in Work~\labelcref{ssec:tmc}.

The second axis, which is closer to our own, focuses on the semantics and representation of first-class one-hole data constructor contexts, continuing the lineage of Minamide’s work (\labelcref{ssec:minamide}). In particular, they investigate how such one-hole data constructor contexts (i.e. data structure with one hole) behave under various memory models, particularly in settings where the constructor contexts are not managed linearly! This closely echoes the copy-on-write strategy we initially proposed for \destcalculus{} (see the end of \cref{ssec:sem} and beginning of \cref{sec:implem-destcalculus}), when ampars don't have to be managed linearly. However, their approach goes further: they define formal operational semantics over an explicit memory store, incorporating reference counting. They also propose optimizations to reduce copying overhead, by detecting when a structure with a hole is uniquely referenced and can thus be safely mutated in place---reminiscent of techniques in \cite{lorenzen_fp_2023}.

Furthermore, they implement this \emph{hybrid} strategy---as they call it---in the Koka programming language, and demonstrate performance gains brought by the \emph{tail-recursion modulo context} transformation on various benchmarks. On the \emph{map} example (see \cref{ssec:benchmark-map}), their approach achieves performance on par with, or even superior to, our DPS Haskell implementation.

On the other hand, their system remains at the same level of expressiveness as Minamide’s: destinations are purely internal and not exposed to the user. As they acknowledge, their model cannot represent structures with multiple holes, and thus, like Minamide’s, it cannot support breadth-first tree traversal.

\section{Oxidizing OCaml}\label{ssec:oxidizing}

\citet{lorenzen_oxidizing_2024} present an extension of the OCaml type system to support modes. Their modes are split along three different ``axes'', among which affinity and locality are comparable to our multiplicities and ages from \cref{chap:dest-calculus}.
Like our multiplicities, there are two modes for affinity \verb|once| and \verb|many|, though in~\cite{lorenzen_oxidizing_2024}, \verb|once| supports weakening, whereas \destcalculus{}'s $[[¹]]$ multiplicity is properly linear (proper linearity matters for destination lest we can discard them without filling the corresponding hole, and end up reading uninitialized memory).

Locality tracks scope. There are two locality modes, \verb|local| (doesn't escape the function) and \verb|global| (can escape the current function). The authors present their locality mode as a drastic simplification of Rust's lifetime system (see Work~\labelcref{ssec:rust-lifetimes}), which nevertheless fits their need.

However, this system is too limited to track the scope of destinations as precisely as \destcalculus{} does. The key issue is that if destinations from nested scopes are assigned the same mode (which has to happen when mapping an infinity of ages to just two), we lose the ability to safely distinguish their lifetimes---making it possible to reproduce the counterexamples from \cref{sec:scope-escape-dests}. This suggests that implementing \destcalculus{} in its entirety within modal OCaml is likely infeasible.

That said, if a mechanism could be introduced to prevent discarding resources of mode \verb|once|, then much---if not all---of the destination-passing APIs described in \cref{chap:dps-haskell,chap:dps-haskell} could still be realized in OCaml, as these APIs rely only on linearity, not full age tracking.

\section{Programming with Permissions in Mezzo}\label{ssec:mezzo}

\citet{protzenko_mezzo_2013} introduced the Mezzo programming language, which features user-facing mutable data structures (unlike ours, where mutability is hidden from the user). Mezzo’s soundness is ensured by a powerful capability system, which governs, in particular, how mutable structures or references can be accessed and shared. In this respect, Mezzo bears a strong resemblance to the Rust programming language.

Of particular relevance to our work is Mezzo’s ability to safely ``freeze'' mutable data structures into immutable ones once construction is complete. This principle is applied, for instance, in Mezzo's standard library for lists, where an efficient \emph{map} function on immutable lists is implemented using destination-passing and mutable lists internally. The capability system guarantees the safe and correct use of destinations in this low-level implementation. An earlier example of destination-passing used as a performance optimization in a mutable setting can also be found in~\cite{larus_restructuring_1989}.

\section{Rust lifetimes}\label{ssec:rust-lifetimes}

The Rust programming language uses a system of lifetimes (see e.g.~\cite{pearce_lifetime_2021}) to ensure that borrows don't live longer than what they reference. It plays a similar role as our system of ages in \destcalculus (\cref{chap:dest-calculus}).

Rust lifetimes are symbolic. Borrows and moves generate constraints (inequalities of the form $\alpha\leqslant\beta$) on the symbolic lifetimes. For example, that the lifetime of a reference is larger than the lifetime of any structure the reference is stored in. Without enforcing these constraints, Rust would face the same kinds of issues described in \cref{sec:scope-escape-dests}: a borrow could outlive the data it refers to, just as destinations in our system could outlive the structures they point to if scope escape were not properly prevented.
In Rust, the borrow checker must checks that the constraints are solvable, while in \destcalculus{}, ages are set explicitly, with no analysis needed.

Another difference between the two systems is that \destcalculus{}'s ages (and modes in general) are relative. An explicit modality $\ottstype{!}_{[[¹↑^ka]]}$ must be used when a part has an age different than its parent, and means that the part is $[[ka]]$ scope older than the parent. On the other hand, Rust's lifetimes are absolute, and the lifetime of a part is tracked independently of the lifetime of its parent.

\cleardoublepage\phantomsection\chapter*{Conclusion and future work}\label{chap:global-conclusion}\addcontentsline{toc}{chapter}{Conclusion and future work}\markboth{Conclusion and future work}{Conclusion and future work}

Destination passing is not a novel concept in programming language design. It was used early on---when manual memory management was essential even for simple programs---as a means to avoid unnecessary memory allocations for intermediate results.

It was then partially abandoned during the rise of object-oriented programming, which brought widespread adoption of automatic memory management. Today, however, we reexamine destination passing in the context of functional programming languages, with slightly different expectations.

For instance, we do not advocate a return to full manual memory management, as it was the case when destination passing was used in the past. Indeed, the ability to ignore memory concerns is, in most cases, a key benefit of modern languages. Rather, functional destination passing can pursue two goals: to allow compilers to optimize code by transforming it into destination-passing style automatically at compile time~\cite{bour_tmc_2021,leijen_tail_2025}; or, as demonstrated in this thesis, to provide programmers with the ability to manually opt in to destination passing for specific sections of functional code where improved performance or expressivity is needed.

Because destination passing is inherently imperative, it must be carefully adapted for use in functional programming languages, particularly when aiming to preserve the principles of immutability and purity that are central in such settings.

To address this, we first turned to linear type systems (\cref{chap:preli}). From their foundations in (linear) logic to their modern formulations and implementations, we examined how linear types can be leveraged to ensure that a resource will only be used exactly once.

With linear types in place, we set out to formalize destination passing within a functional model, called \destcalculus{} (\cref{chap:dest-calculus}). The core idea is that a destination---a pointer to a yet-unused memory cell---must be used exactly once. Once used, the corresponding memory cell becomes readable, and the value contained within is now guaranteed not to change (to abide by immutability). Consequently, the main invariant is that a destination should always point to an existing hole (a yet unused memory cell), and that every remaining hole in a structure must be referenced by exactly one destination that hasn't been used yet. Destinations acts as both witnesses and a way of filling those holes, and when no destination remains, the structure should be fully initialized and contain no remaining holes.

Early on this journey however, we encountered the critical issue of \emph{scope escape}, which required over a year of research to resolve. Scope escape (\cref{sec:scope-escape-dests}) arises when a destination is used to store another destination. Even under a strict linear discipline, the type system cannot always distinguish whether a destination has been consumed, meaning the associated memory cell contains a valid value; or if the destination has been merely stored for later use, in which case reading the corresponding memory cell prematurely may cause a segmentation fault or a similar memory error.

To address this, we had to strengthen the type system of \destcalculus{} by introducing a \emph{system of ages} alongside linearity to ensure memory safety. Fortunately, in \cref{sec:modal-lin}, we had already developed a modal presentation of linear type systems, structured around an underlying semiring algebra, that is well suited for easy extension. In particular, this allowed us to integrate both the linear and age systems into a same semiring, hence the resulting type system for \destcalculus{} (\cref{sec:syntax-type-system}) remains close in spirit to earlier work, while addressing the additional safety concerns posed by scope escape.

In \destcalculus{}, the main additions compared to a standard $\lambda$-calculus are ampars---structures that may be partially constructed and contain holes---and destinations, which are linearly tracked pointers to these holes. While holes themselves are not first-class citizens of the language, unlike destinations, they play a crucial role in both typing and semantics. In particular, we introduced a new typing discipline for structures with holes (\cref{ssec:runtime-values}). Both the holes within an ampar and its associated destinations are represented as named bindings in the typing context. A hole and a destination with the same name cancel each other out. As a result, a fully constructed ampar has an empty typing context, while a non-empty context indicates either an unfilled hole or a destination referencing an already-filled one. This is how we ensure, within the type system, that no destination can be reused or forgotten.

The operational semantics of \destcalculus{} (\cref{ssec:sem}) relies on a rather abstract memory model, in which program state is purely defined by the evaluation context and the term under focus. Memory writes triggered by the action of filling a destination are modeled as global substitutions on named holes within the evaluation context. This semantic model is simpler than conventional store-based semantics, as typing rules for evaluation contexts are direct extensions of those for terms, whereas store semantics typically require more complex typing machinery. Despite its simplicity, this approach faithfully captures the behavior of destination-induced memory mutations.

A key contribution of this work is that we were able to formalize \destcalculus{} in the Coq proof assistant (\cref{sec:formal-proof}) and then produce a mechanically verified proof of the usual safety theorems for \destcalculus{}, namely \emph{progress} and \emph{preservation}.

With \destcalculus{}, we thus obtain a formal functional language with destination passing embedded so deeply in its core that we have maximal flexibility in using destinations. For example, standard data constructors are not required as primitive elements of the language, as they can be reconstructed using destination-filling operations. This expressive power, however, comes at the cost of requiring a custom type system to ensure safety.

Thus, the second, and equally important part of the PhD---especially since the PhD is funded by a company with industrial functional programming in its DNA---consisted in porting the core ideas of \destcalculus{} and destination passing into the setting of a practical, industrial functional programming language. Haskell was a natural choice for this, due to its existing support for linear types. Even more so since my industrial supervisor, Arnaud \textsc{Spiwack}, is one of the authors of Linear Haskell~\cite{bernardy_linear_2018,spiwack_linearly_2022} and a strong proponent of improving linear type support and ergonomics within GHC. The main challenge in implementing destination passing in Haskell is that we cannot rely on the custom type system of \destcalculus{}, based on both linearity and ages, to guarantee safety. Instead, we must rely on linearity alone.

Initial experiments with destination-passing style programming in Haskell actually predate the theoretical development of \destcalculus{}. At that time, scope escape was still an open problem, with no solution yet in sight (so the age system had not been introduced either). As a result, in the meantime, we began developing a prototype API for destination passing in Haskell (\cref{chap:dps-haskell}), where scope escape is ruled out by design: we chose to forbid storing destinations inside other destinations as a safety measure. A major concern for the implementation was to avoid mutations (for destination-filling operations) that could disrupt Haskell's memory model. To address this, we used \emph{compact regions}---memory areas outside the reach of the garbage collector---in which unfinished data structures could live without troubles. This practical work ultimately spanned from designing a consistent and ergonomic high-level API down to implementing low-level compiler primitives representing destination-filling operations. The resulting benchmarks (\cref{sec:benchmark}) are encouraging: destination passing proves to be a valuable tool in specific scenarios, improving the performance of some functional programs and enabling more direct, imperative-style code when desired, without compromising memory safety. However, further work is needed to improve both the ergonomics and performance of the DPS implementation if we want it to gain broader adoption in the functional programming community.

One inconvenience with DPS Haskell, in the form presented in \cref{chap:dps-haskell}, is the restriction we imposed initially---that destinations cannot store any linear resource to avoid scope escape. It impedes the flexibility and expressivity gains that we claimed true for \destcalculus. In particular, one of our motivating examples, breadth-first traversal of a tree, cannot be implemented using our destination-passing toolkit alone in this first version of DPS Haskell: at some point, we have no choice than to fall back to standard Haskell data structures rather than relying exclusively on the destination-based structures.

In \cref{chap:ext-linear-nonlinear}, we attempt to recover much of the lost expressivity. However, relaxing the safety constraint that destinations cannot be filled with linear resources requires great care to avoid scope escape and other issues that arise in the absence of ages (and age control). Still, by the end of this effort, we obtain a way to write our favorite breadth-first tree traversal using only destination-based data structures, in Haskell, through an API we believe to be safe.

Further work would consist in verifying the safety of both the original and extended DPS Haskell APIs developed in \cref{chap:dps-haskell,chap:ext-linear-nonlinear}. We have argued that \destcalculus{} provides a framework to reason about the safety and correctness of destination-passing systems---now would be the time to put that claim to the test.

A second direction for improvement is to implement DPS support for Haskell within the garbage-collected heap (that is, the standard memory region where most Haskell data resides) rather than relying on the protective shell of compact regions. The challenge here lies in the tight coupling between memory safety and the garbage collector internals, particularly those concerning when and where immutability assumptions are used.

Finally, a third possible improvement would be to extend destination-passing structure building to data structures with unpacked fields---that is, structures where some fields directly embed child elements rather than storing pointers to them. So far, we have only considered destination passing for purely linked structures, and for good reason: this allows efficient composition (i.e., merging) of structures with holes, by simply writing the address of the child structure into the appropriate field of the parent one, in a single memory operation. In contrast, for structures with unpacked fields, the situation is more delicate. A naive deep copy of the child structure would invalidate any existing destinations pointing to it, requiring careful tracking and potentially more complex mechanisms. Supporting such structures would therefore not come for free.

We hope that, by now, the reader has got a good and enjoyable overview of this exotic journey: an exploration of how imperative techniques and functional principles can be reconciled, from high-level and formal considerations to low-level implementation and associated performance concerns. At last, we can say with confidence: safe, functional destination passing is not an oxymoron---it exists!
