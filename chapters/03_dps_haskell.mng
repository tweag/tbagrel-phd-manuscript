\chapter{A first implementation of first-class destination passing in Haskell}\label{chap:dps-haskell}

In the previous chapter, we saw how we can build a $\lambda$-calculus from the ground up with first-class support for destination passing, and that still achieve memory safety. It's now time to put that into practice in an industrial-grade programming language.

The main ideas of this chapter have resulted in a publication at JFLA 2024\cite{bagrel_destination-passing_2024}. Several sections have been reworked though, since the theoretical work described in \cref{chap:dest-calculus} was still in very early stage when the article \cite{bagrel_destination-passing_2024} got published.

\section{Linear Haskell is our implementation target}\label{intro-dps-haskell}

Designing an industrial-grade programming language \emph{just} to add support for destinations would be a gigantic task, with much risk to fail. Instead, we'll base our work on an existing functional programming language. The Haskell programming language is equipped with support for linear types through its main compiler, \emph{GHC}, since version 9.0.1~\cite{bernardy_linear_2018}. We kindly redirect the reader to \cref{sec:intro-linearity} for a primer on Linear Haskell and how to use it to control resource use.

There aren't many other industrial-grade functional programming languages, and most of them don't have support for linear types, which are the first piece required to make our system safe. OCaml, thanks to recent work from \citet{lorenzen_oxidizing_2024}, has support for \emph{affinity}, but not for \emph{linearity} (despite the aforementioned work using the term linearity): a resource can be restricted to at most one use, but there is no way to ensure it will be used exactly once; it could be dropped without being used at all.

As a result, Haskell appeared to be a promising target for experimenting with destination passing in a practical setting, and try to implement as many ideas from \destcalculus{} (detailed in length\cref{chap:dest-calculus}) as possible. In addition, Haskell is also a \emph{pure} functional language, which is rather in line with the idea of hiding impure memory effects related to destinations behind a \emph{pure} API (as presented in the introduction) by preventing any read before a structure has been completed.

However, the main challenge is that Haskell, albeit incorporating linear types, doesn't have any concept of scope or age control. So we won't be able to avoid the fundamental issues presented in \cref{sec:scope-escape-dests} without imposing limitations on the flexibility of the system.

\section{Restricting \destcalculus{} so that it can be made safe with just linear types}\label{sec:restrict-dps-linhask}

As we've seen in \cref{sec:scope-escape-dests}, linear types are not enough, alone, to make \destcalculus{} ---or any other very flexible destination-passing system--- safe. We definitely need ages and scope control. In this chapter, we will take a radical decision: we will make it so that destinations can only be used to build non-linear (a.k.a. unrestricted) data structures, so that the issue of scope escape disappear completely. In exchange, we won't be able to store destinations inside data structures built using ampars.

In practice, that means that a destination can only be filled with an unrestricted value (which forbids filling a destination with another destination, as destinations are linear resources). We will use the Haskell type \mintinline{haskellc}/data UDest t/ to represent those destinations for unrestricted values, and type \mintinline{haskellc}/data UAmpar s t/ to represent these ampars where the \mintinline{haskellc}/s/ side is unrestricted.

Because there is no difference when creating the spine of a data structures that is linear or unrestricted, our fill functions that adds a new hollow constructor to an existing structure will be exactly the same as in \destcalculus{}. Only the signature of fill operators acting on the leaves of data structures will change in the implementation compared to the formal definition.


The mapping of operators and types between \destcalculus{} and DPS Haskell is given in \cref{fig:mapping-destcalculus-dpshaskell}

In \destcalculus{}, destinations always have finite ages. As a result, we use age $[[∞]]$ as a marker that something doesn't contain destinations. That way, can still enforce scope control independently of linearity. This is particularly visible in rule \rref*{\CTyTerm\CSep\CFromA}, where a linear resource can be extracted from the right of an ampar as long as it has age $[[∞]]$.

In DPS Haskell however, we don't have ages. So we use the fact that destinations are always linear too, and we employ the $[[ω]]$ multiplicity as a marker that something doesn't contain destinations. Of course, this isn't cheap; by doing so we conflate the absence of destination with non-linearity. Controlling scopes that way means we are overly conservative (to preserve safety), which restrain the possibilities of a few operators. % In DPS Haskell, mode $[[ɷ]]$ is equivalent to the pair $[[ω∞]]$ of \destcalculus{}, as there is no no construct in our language that can have unrestricted multiplicity with an intrinsically finite age, it makes sense to map the mode $[[ɷ]]$ of Linear Haskell. Consequently, $[[ˢᴇ ω∞ term]]$ corresponds to \mintinline{haskellc}/Ur term/.


\begin{figure}

\emph{Destination-filling operators:}

\begin{center}
\begin{tabular}{|l|lcl|}\hline
\destcalculus{} & DPS Haskell && \\\hline\hline
$[[d ⨞ ()]]$ & \mintinline{haskellc}/fill @'() d/ &or& \mintinline{haskellc}/d &fill @'()/ \\\hline
$[[d ⨞ Inl]]$ & \mintinline{haskellc}/fill @'Inl d/ &or& \mintinline{haskellc}/d &fill @'Inl/ \\\hline
$[[d ⨞ Inr]]$ & \mintinline{haskellc}/fill @'Inr d/ &or& \mintinline{haskellc}/d &fill @'Inr/ \\\hline
$[[d ⨞ (,)]]$ & \mintinline{haskellc}/fill @'(,) d/ &or& \mintinline{haskellc}/d &fill @'(,)/ \\\hline
$[[d ⨞ ᴇ ω∞]]$ & \mintinline{haskellc}/fill @'Ur d/ &or& \mintinline{haskellc}/d &fill @'Ur/ \\\hline
$[[d ⨞ ( λ x m ⟼ term )]]$ & \mintinline{haskellc}/fillLeaf (\x → term) d/ &or& \mintinline{haskellc}/d &fillLeaf (\x → term)/ \\\hline
$[[d ⨞· term]]$ & \mintinline{haskellc}/fillComp term d/ &or& \mintinline{haskellc}/d &fillComp term/ \\\hline
$[[d ◀ term]]$ & \mintinline{haskellc}/fillLeaf term d/ &or& \mintinline{haskellc}/d &fillLeaf term/ \\\hline

\end{tabular}

\medskip

(one can see \mintinline{haskellc}/&fill @'/ as the equivalent of $[[⨞]]$ in \destcalculus{}, 
\mintinline{haskellc}/&fillLeaf/ as $[[◀]]$, and \mintinline{haskellc}/&fillComp/ as $\mathop{\triangleleft\mycirc}$)

\end{center}

\smallskip

\emph{Types:}

\begin{center}
\begin{tabular}{|l|l|}\hline
\destcalculus{} & DPS Haskell \\\hline\hline
$[[⌊ T ⌋ ω∞]]$ & \mintinline{haskellc}/UDest t/ \\\hline
$[[! ω∞ S ⧔ T]]$ & \mintinline{haskellc}/UAmpar s t/ \\\hline
\end{tabular}
\end{center}

\caption{Mappings between \destcalculus{} and DPS Haskell}\label{fig:mapping-destcalculus-dpshaskell}
\end{figure}

Now, let's see how programs look like in DPS Haskell. We'll start by reimplementing examples from the previous chapter, to see how they take form in a practical setting.

\section{A glimpse of DPS Haskell programming}\label{sec:motivating-examples}

The following subsections present three typical cases in which DPS programming brings expressiveness or performance benefits over a more traditional functional implementation. We'll start by revisiting examples from \cref{sec:working-with-dests}.

\subsection{Efficient difference lists, and proper memory model}\label{ssec:dpshaskell-dlist}

Linked lists are a staple of functional programming, but they aren't efficient for concatenation, as we've seen in \cref{ssec:efficient-queue}, especially when the concatenation calls are nested to the left.

In an imperative context, it would be quite easy to concatenate linked lists efficiently. One just has to keep both a pointer to the root and to the last \emph{cons} cell of each list. Then, to concatenate two lists, one just has to mutate the last \emph{cons} cell of the first one to point to the root of the second list.

In a functional setting, \emph{difference lists} are the closest equivalent, offering constant-time concatenation, and constant-time conversion to a normal linked list. Usually, as we've seen previously, functional difference lists are encoded as functions, but thanks to destination-passing style, we can represent them as an actual list with a hole at the end.

This example will be the opportunity to show how DPS Haskell operates on memory. So far, with \destcalculus{}, we worked on a theoretical memory model with global substitutions (on the whole evaluation context) and no representation of allocations. Here, with DPS Haskell, we assume that we have a proper heap. We pay no attention right now to garbage collection / deallocation; instead we will deal with this topic in \cref{ssec:impl-compact-regions}.

Following the mapping tables of \cref{sec:restrict-dps-linhask}, we know the DPS Haskell representation of difference lists is \mintinline{haskellc}/type DList t = UAmpar [t] (UDest [t])/. As announced previously, because our difference lists are built using UAmpars, they cannot host linear resources. That's the major limitation of this first approach of DPS programming for Haskell.

As with ampars in \destcalculus{}, the left side of the UAmpar carries the structures being built, while the right side carries the destinations of the structure: the \mintinline{haskellc}/UDest [t]/ must be filled (with an unrestricted \mintinline{haskellc}/[t]/) to get a readable (unrestricted) \mintinline{haskellc}/[t]/.

The implementation of destination-backed difference lists is presented in \cref{table:impl-dlist}. Note that Haskell uses \mintinline{haskellc}/⩴/ for typing, and \mintinline{haskellc}/(:)/ for the list \emph{cons} constructor, which is the opposite of what these symbols mean in \destcalculus{}.
% Doesn't bring much more compared to fig:schema-dlist-concat
% \begin{figure}[t]\centering
%   \includegraphics[width=10cm]{fillComp.png}
%   \caption{Memory behavior of \mintinline{haskellc}/fillComp ⩴ UAmpar s t ⊸ UDest s ⊸ t/}
%   \label{fig:schema-fillComp}
% \end{figure}

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos]{haskellc}
-- we recall here the definition of list type in Haskell
data [t] = []          -- nil constructor
           | (:) t [t]  -- cons constructor

-- we also reuse the same linear token API as in Section 1.8
withToken ⩴ (Token ⊸ Ur t) ⊸ Ur t

type DList t = UAmpar [t] (UDest [t])

newDList ⩴ Token ⊸ DList t
newDList = newUAmpar @[t]

append ⩴ DList t ⊸ t → DList t
dlist `append` x =
  dlist `updWith` \d → case (d &fill @'(:)) of
    (dh, dt) → (dh &fillLeaf x) ; dt

concat ⩴ DList t ⊸ DList t ⊸ DList t
dlist1 `concat` dlist2 = dlist1 `updWith` \dt1 → (dt1 &fillComp dlist2)

toList ⩴ DList t ⊸ Ur [t]
toList dlist = fromUAmpar' (dlist `updWith` \dt → dt &fill @'[])
\end{minted}
\caption{Implementation of difference lists in DPS Haskell}
\label{table:impl-dlist}
\end{listing}

% TODO: update syntax
\begin{figure}[t]\centering
  \hspace{-0.5cm}\begin{minipage}{0.3\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/alloc}}
    \caption{\mintinline{haskellc}/newUAmpar tok/}
    \label{fig:schema-alloc}
  \end{minipage}\hspace*{1cm}%
  \begin{minipage}{0.7\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/dlist-toList}}
    \caption{Memory behavior of \mintinline{haskellc}/toList dlist/}
    \label{fig:schema-dlist-toList}
  \end{minipage}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-append}}
  \caption{Memory behavior of \mintinline{haskellc}/append newUAmpar 1/}
  \label{fig:schema-dlist-append}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-concat}}
  \caption{Memory behavior of \mintinline{haskellc}/concat dlist1 dlist2/ (based on \mintinline{haskellc}/fillComp/)}
  \label{fig:schema-dlist-concat}
\end{figure}

% \begin{figure}[p]\centering

% \end{figure}

\begin{itemize}
  \item \mintinline{haskellc}/newDList/ is just an alias for \mintinline{haskellc}/newUAmpar/, to linearly exchange a token for a new \mintinline{haskellc}/UAmpar [t] (UDest [t])/ ---that is, exactly \mintinline{haskellc}/DList t/. Recall that UAmpars are treated as linear resources now, and are created in exchange of a linear token, following the principles described in \cref{sec:linear-scopes,sec:implem-destcalculus}. There is no data
    in this new UAmpar yet, it's just a hole and a destination pointing to it, as we see on \cref{fig:schema-alloc};

  \item \mintinline{haskellc}/append/ (\cref{fig:schema-dlist-append}) adds an element at the tail
    position of a difference list. For this, it first uses
    \mintinline{haskellc}/fill @'(:)/ to fill the hole at the end of the list represented by
    \mintinline{haskellc}/d ⩴ UDest [t]/ with a hollow \mintinline{haskellc}/(:)/ constructor that has two new holes, pointed to by \mintinline{haskellc}/dh ⩴ UDest t/ and \mintinline{haskellc}/dt ⩴ UDest [t]/. Then,
    \mintinline{haskellc}/fillLeaf/ fills the hole represented by
    \mintinline{haskellc}/dh/ with the value
    of type \mintinline{haskellc}/t/
    to append. The hole at the end of the resulting difference list is the one pointed by \mintinline{haskellc}/dt ⩴ UDest [t]/ which hasn't been filled yet, and stays on the right side of the resulting UAmpar.

  \item \mintinline{haskellc}/concat/ (\cref{fig:schema-dlist-concat}) concatenates two difference lists,
    \mintinline{haskellc}/dlist1/ and \mintinline{haskellc}/dlist2/. It uses \mintinline{haskellc}/fillComp/ to fill the destination \mintinline{haskellc}/dt1/
    of the first difference list with the
    root of the second difference list \mintinline{haskellc}/dlist2/. The resulting \mintinline{haskellc}/UAmpar/
    object hence has the same root as the first list, holds the
    elements of both lists, and inherits the hole of the second list. Memory-wise,
    \mintinline{haskellc}/concat/ just writes the address of the second list into the hole of the first one.

  \item \mintinline{haskellc}/toList/ (\cref{fig:schema-dlist-toList}) completes the UAmpar structure by plugging a new \emph{nil} \mintinline{haskellc}/[]/ constructor into its hole with \mintinline{haskellc}/fill @'[]/, and then removes the \mintinline{haskellc}/UAmpar/ wrapper as the structure is now complete, using \mintinline{haskellc}/fromUAmpar'/. The completed list is wrapped in \mintinline{haskellc}/Ur/, as it is allowed to be used non-linearly ---it's always the case with UAmpars--- and so that it can also escape the linear scope created by \mintinline{haskellc}/withToken/ if needed.
\end{itemize}

Linearity of UAmpars, enforced by the linear token technique, is essential\footnote{In \destcalculus{} we could choose to use a smart renaming technique for hole names (morally equivalent to copy-on-write) so that ampars don't have to be managed linearly. Here, as we aim for an efficient implementation, the idea of copying ampars and updating the target of destinations on-the-go doesn't seem promising.} to allow safe, in-place, memory updates when destination-filling operations occur, as shown in \cref{fig:schema-alloc,fig:schema-dlist-append,fig:schema-dlist-concat,fig:schema-dlist-toList}. Otherwise, we could first complete a difference list with \mintinline{haskellc}/let Ur l = toList dlist/, then add a new cons cell to \mintinline{haskellc}/dlist/ with \mintinline{haskellc}/append dlist x/ (actually reusing the destination inside \mintinline{haskellc}/dlist/ for the second time). This would create a hole inside \mintinline{haskellc}/l/, although it is of type \mintinline{haskellc}/[t]/ so we would be able to pattern-match on it, and might get a segfault!

We could expect the implementation of difference list described above to be more efficient than the functional encoding (where a difference list \mintinline{haskellc}/x :/\,$\holesq$ is represented by the function \mintinline{haskellc}/\ys → x : ys/). We'll see in \cref{sec:benchmark} that the prototype implementation of DPS Haskell primitives (covered in \cref{sec:implementation}) cannot yet demonstrate these performance improvements.

\subsection{Breadth-first tree traversal}\label{ssec:bf-tree-traversal}

Let's move on now to breadth-first tree traversal. We want to traverse a binary tree and update its nodes values so that they are numbered in a breadth-first order.

In \cref{sec:bft}, we took full advantage of \destcalculus{}'s flexibility, and implemented the breadth-first traversal using a queue to drive the processing order, as we would do in an imperative programming language. This queue would contain both input subtrees and destination to output subtrees, in breadth-first order. Furthermore, the queue was implemented efficiently using a pair of a queue and a ampar-based difference list.

Unfortunately, in DPS Haskell, destinations cannot be filled with linear elements. So an ampar-based difference list wouldn't be able to store the destinations we need to store (the one representing the output subtrees), and consequently, neither would an ampar-based efficient queue.

However, we can still use the regular, non-ampar-based data structures of Haskell to build a suitable Hood-Melville\cite{hood_queue_1981} queue. That's at least one thing we get from using a language that isn't fully based on destinations to build data structures\footnote{Destination-based data structure building is more general than constructor-based structure building as long as we can fill destinations with linear resources, as in \destcalculus{}. When we add the restriction that destination can only be filled with unrestricted elements, as we do in DPS Haskell, then it is no longer more general than constructor-based structure building, and we need to conserve both building ways in the language to stay at the same level of expressiveness.}. The implementation of Hood-Melville queues is presented in \cref{table:impl-hm-queue}.

As before, for the breadth-first traversal, we'll keep a queue of pairs of a tree to be relabeled and of the destination where the relabeled result is expected, and process each of them when their turn comes. Nothing other than choice of implementation for the queue will change. The DPS Haskell implementation of breadth-first tree traversal is provided in \cref{table:impl-bfs-tree-traversal}.

% TODO: add implem of hood melville queue, and revisit code snippet

\begin{listing}
\figtextsize
\begin{minted}[linenos]{haskellc}
data HMQueue t = ¤HMQueue [t] [t]

newHMQueue :: HMQueue t
newHMQueue = ¤HMQueue [] []

singleton :: t ⊸ HMQueue t
singleton x = ¤HMQueue [x] []

toList :: HMQueue t ⊸ [t]
toList (¤HMQueue front backRev) = front ++ reverse backRev

enqueue :: HMQueue t ⊸ t ⊸ HMQueue t
enqueue (¤HMQueue front backRev) x = ¤HMQueue front (x : backRev)

dequeue :: HMQueue t ⊸ Maybe (t, HMQueue t)
dequeue (¤HMQueue front backRev) = case front of
  [] → case reverse backRev of
    [] → Nothing
    (x : front') → Just (x, ¤HMQueue front' [])
  (x : front') → Just (x, ¤HMQueue front' backRev)
\end{minted}
\caption{Implementation of Hood-Melville queue in Haskell}
\label{table:impl-hm-queue}
\end{listing}

\begin{listing}
\figtextsize
\begin{minted}[linenos]{haskellc}
data Tree t = ¤Nil | ¤Node t (Tree t) (Tree t)

relabelDPS ⩴ Token ⊸ Tree t → Tree Int
relabelDPS tree = fst (mapAccumBFS (\st _ → (st + 1, st)) 1 tree)

mapAccumBFS ⩴ ∀ s t u. Token ⊸ (s → t → (s, u)) → s → Tree t → Ur (Tree u, s)
mapAccumBFS tok f s0 tree =
  fromUAmpar (newUAmpar @(Tree u) tok `updWith` \dtree → go s0 (singleton (¤Ur tree, dtree)))
  where
    go ⩴ s → Queue (Ur (Tree t), UDest (Tree u)) ⊸ Ur s
    go st q = case dequeue q of
      ¤Nothing → ¤Ur st
      ¤Just ((utree, dtree), q') → case utree of
        ¤Ur ¤Nil → dtree &fill @'Nil ; go st q'
        ¤Ur (¤Node x tl tr) → case (dtree &fill @'Node) of
          (dy, dtl, dtr) →
            let q'' = q' `enqueue` (¤Ur tl, dtl) `enqueue` (¤Ur tr, dtr)
                (st', y) = f st x
              in dy &fillLeaf y ; go st' q''
\end{minted}
\caption{Implementation of breadth-first tree traversal in DPS Haskell}
\label{table:impl-bfs-tree-traversal}
\end{listing}

Except from the choice of queue implementation, and the fact that ampars must be created from \mintinline{haskellc}/Token/s, this implementation is very much the same as in \cref{sec:bft}. In the signature of \mintinline{haskellc}/go/ function, the linear arrow enforces the fact that every destination ever put in the queue is eventually consumed at some point, which guarantees that the output tree is complete after the function has run.

We will see in \cref{sec:benchmark} that this imperative-like implementation of breadth-first traversal in DPS Haskell, albeit not using difference-list-based efficient queues, still presents great performance gains compared to the fancy functional implementation from~\citet{gibbons_phases_2023}.

\section{DPS Haskell API and Design concerns}\label{sec:api}

\cref{table:destination-api} presents the pure API of DPS Haskell. This API is sufficient to implement all the examples of \cref{sec:motivating-examples}. This section explains its various parts in detail and how it compares to \cref{chap:dest-calculus}.

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos]{haskellc}
data Token
dup ⩴ Token ⊸ (Token, Token)
drop ⩴ Token ⊸ ()
withToken ⩴ ∀ t. (Token ⊸ Ur t) ⊸ Ur t

data UAmpar s t
newUAmpar ⩴ ∀ s. Token ⊸ UAmpar s (UDest s)
tokenBesides ⩴ ∀ s t. UAmpar s t ⊸ (UAmpar s t, Token)
toUAmpar ⩴ ∀ s. Token ⊸ s → UAmpar s ()
fromUAmpar ⩴ ∀ s t. UAmpar s (Ur t) ⊸ Ur (s, t)
fromUAmpar' ⩴ ∀ s. UAmpar s () ⊸ Ur s
updWith ⩴ ∀ s t u. UAmpar s t ⊸ (t ⊸ u) ⊸ UAmpar s u

data UDest t
type family UDestsOf lCtor t  -- returns dests associated to fields of constructor
fill ⩴ ∀ lCtor t. UDest t ⊸ UDestsOf lCtor t
fillComp ⩴ ∀ s t. UAmpar s t ⊸ UDest s ⊸ t
fillLeaf ⩴ ∀ t. t → UDest t ⊸ ()
\end{minted}
\caption{Destination API for Haskell}
\label{table:destination-api}
\end{listing}

\subsection{The \texttt{UAmpar} type}

As with Ampars from the previous chapter, UAmpar structures, that serve as a wrapper for structures with holes, can be freely passed around and stored, but need to be completed before any reading i.e. pattern-matching can be made on them. As a result, \mintinline{haskellc}/UAmpar s t/ is defined as an opaque data type, with no public constructor.

In \mintinline{haskellc}/UAmpar s t/, \mintinline{haskellc}/s/ stands for the type of the structure being built, and \mintinline{haskellc}/t/ is the type of what needs to be linearly consumed before the structure can be read. Eventually, when complete, the structure will be wrapped in \mintinline{haskellc}/Ur/; this illustrates the fact that it has been made only from unrestricted elements.

The \mintinline{haskellc}/newUAmpar/ operator is the main way for a user of the API to create a new UAmpar. Its signature is equivalent to the one of $[[allocIP]]$ from \cref{sec:implem-destcalculus}.

Also, sometimes, when programming in DPS style, we won't have a \mintinline{haskellc}/Token/ at hand, but only an existing \mintinline{haskellc}/UAmpar/. In that case, we can piggyback on the linearity of that existing UAmpar (as it linearly depends, directly or indirectly, on a token) to get a new linear \mintinline{haskellc}/Token/ so that we can spawn a new UAmpar, or any other linear resource really. This is the goal of the \mintinline{haskellc}/tokenBesides/ function.

The operator \mintinline{haskellc}/tokenBesides/ is particularly useful when implementing efficient queues in DPS Haskell (as in \cref{ssec:efficient-queue}):

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
type DList t = UAmpar [t] (UDest [t])
data EffQueue t = ¤EffQueue [t] (DList t)

newEffQueue ⩴ Token ⊸ EffQueue t
newEffQueue tok = ¤EffQueue [] (newUAmpar @[t] tok)

dequeue ⩴ EffQueue t ⊸ Maybe (t, EffQueue t)
dequeue (¤EffQueue front back) = case front of
  [] → case (toList back) of
    Ur [] → Nothing
    Ur (x : xs) → Just (x, (¤EffQueue xs °\mold{(newUAmpar \textcolor{typcolor}{\textbf{@[t]}} tok)}°))
  (x : xs) → Just (x, (¤EffQueue xs back))
\end{minted}
}
\end{unbreakable}

In the second branch of the inner-most \mintinline{haskellc}/case/ in \mintinline{haskellc}/dequeue/, when we have transformed the back difference list (from which we used to write) into the new front list (from which we will now read), we have to create a new back difference list, that is, a new ampar. However, we don't have a token at hand. It would be quite unpractical for a function like \mintinline{haskellc}/dequeue/ to ask for a linear token to be passed; it's better if tokens are only requested when spawning a new data structure, not when operating on one. That's why \mintinline{haskellc}/tokenBesides/ comes handy: we can instead reuse the linearity requirement of the existing UAmpar:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
tokenBesides ⩴ ∀ s t. UAmpar s t ⊸ (UAmpar s t, Token)

dequeue ⩴ EffQueue t ⊸ Maybe (t, EffQueue t)
dequeue (¤EffQueue front back) = case front of
  [] → case tokenBesides back of (back, tok) → case (toList back) of
    Ur [] → drop tok ; Nothing
    Ur (x : xs) → Just (x, (¤EffQueue xs (newDList tok)))
  (x : xs) → Just (x, (¤EffQueue xs back))
\end{minted}
}
\end{unbreakable}

This new version is not perfect either though. We have to create a new token before even knowing if we will need it. Indeed, we can only know if a new token is really needed when we have read the content of the old UAmpar, and we can only read it when it is no longer a UAmpar... so at that point we cannot spawn a new token any longer. So the solution is to always spawn a new token before consuming the old UAmpar, taking the risk that if the queue is really empty, we will have to discard the fresh token immediately (with \mintinline{haskellc}/drop/) before returning \mintinline{haskellc}/Nothing/. Implicit token passing, as proposed by Linear Constraints\cite{spiwack_linearly_2022,spiwack_linear_prop_2023}, seems to really be the way forward to get rid of this kind of issues altogether.

%------------------------------

\paragraph{Getting out of an UAmpar}

Same as in \destcalculus{}, the structure encapsulated within a UAmpar can be released in two ways: with \mintinline{haskellc}/fromUAmpar'/, the value on the \mintinline{haskellc}/t/ side must be unit (\mintinline{haskellc}/()/), and just the complete \mintinline{haskellc}/s/ is returned, wrapped in \mintinline{haskellc}/Ur/. With \mintinline{haskellc}/fromUAmpar/, the type on the \mintinline{haskellc}/t/ side must be of the form \mintinline{haskellc}/Ur t'/, and then a pair \mintinline{haskellc}/Ur (s, t')/ is returned.

It is actually safe to wrap the structure that has been built in \mintinline{haskellc}/Ur/ because, as we've said previously, its leaves either come from non-linear sources (as \mintinline{haskellc}/fillLeaf ⩴ t → UDest t ⊸ ()/ consumes its first argument non-linearly) or are made of 0-ary constructors added with \mintinline{haskellc}/fill/, both of which can be used in an unrestricted fashion safely; and its spine, made of hollow constructors, can be duplicated at will.

% \mintinline{haskellc}/UAmpar s t/ has a linear functor instance to map on the \mintinline{haskellc}/t/ side (the one carrying destinations) which forces the continuation to be linear:

% {\figtextsize
% \begin{minted}[escapeinside=°°]{haskellc}
% instance Functor (UAmpar a) where
%   fmap ⩴ ∀ b c. (b ⊸ c) ⊸ UAmpar a b ⊸ UAmpar b c
%   fmap f (¤UAmpar (x, d)) = ¤UAmpar (x, f d)
% \end{minted}
% }

% And \mintinline{haskellc}/newUAmpar ⩴ ∀ s. Token ⊸ UAmpar s (UDest s)/` is the only function in which a \mintinline{haskellc}/UDest/ appears in positive position, but locked by an \mintinline{haskellc}/UAmpar/ (which is an opaque wrapper for the user). So destinations can only ever be accessed by mapping over an \mintinline{haskellc}/UAmpar/ with \mintinline{haskellc}/fmap//\mintinline{haskellc}/`updWith`/, and cannot leak to the outside. It isn't possible either for a \mintinline{haskellc}/UDest t/ to be linearly consumed by filling another \mintinline{haskellc}/UDest (UDest t)/ with \mintinline{haskellc}/fillLeaf/, as the first argument of the \mintinline{haskellc}/fillLeaf/ function isn't used linearly.\footnote{It would actually be desirable to have \mintinline{haskellc}/UDest (UDest t)/ work. But it turns out that doing so naively compromises the type safety properties related to linearity that we describe in this section. How to recover type safety in presence of destinations of destinations is still an open problem.}

% Morally, this linear \mintinline{haskellc}/Functor/ instance says that one can temporary forget about the root of the structure being built, and just manipulate the destinations as first-class objects that will produce remote building effects onto the structure that is invisible in the inner scope.

\subsection{Filling functions for destinations}

The last part of the API is the one in charge of actually building the structures in a top-down fashion. To fill a hole represented by \mintinline{haskellc}/UDest t/, three functions are available:

\mintinline{haskellc}/fillLeaf ⩴ ∀ t. t → UDest t ⊸ ()/ uses a value of type \mintinline{haskellc}/t/ to fill the hole represented by the destination, as $[[◀]]$ from \destcalculus{}. However, if the destination is consumed linearly, as in \destcalculus{}, the value to fill the hole isn't (as indicated by the first non-linear arrow). This is key to the fact that UAmpar only host unrestricted data. Memory-wise, when \mintinline{haskellc}/fillLeaf/ is used, the address of the object of type \mintinline{haskellc}/t/ is written into the memory cell pointed to by the destination of type \mintinline{haskellc}/UDest t/ (see \cref{fig:schema-fillLeaf}).

\mintinline{haskellc}/fillComp ⩴ ∀ s t. UAmpar s t ⊸ UDest s ⊸ t/ is used to plug two \mintinline{haskellc}/UAmpar/ objects together. The parent \mintinline{haskellc}/UAmpar/ isn't represented in the signature of the function, as with the similar operator $\mathop{\triangleleft\mycirc}$ from \destcalculus{}. Instead, only the hole of the parent UAmpar that will receive the address of the child UAmpar is represented in the signature of the function by \mintinline{haskellc}/UDest s/; while \mintinline{haskellc}/UAmpar s t/ in the signature refers to the child UAmpar. A call to \mintinline{haskellc}/fillComp/ always takes place in the scope of \mintinline{haskellc}/`updWith`/ over the parent one:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parent ⩴ UAmpar BigStruct (UDest SmallStruct, UDest OtherStruct)
child ⩴ UAmpar SmallStruct (UDest Int)
comp = parent `updWith` \(ds, do) → (ds &fillComp child, do)
       ⩴ UAmpar BigStruct (UDest Int, UDest OtherStruct)
\end{minted}
}
\end{unbreakable}

The resulting structure \mintinline{haskellc}/comp/ is morally a \mintinline{haskellc}/BigStruct/ like \mintinline{haskellc}/parent/, that inherited the hole from the child structure (\mintinline{haskellc}/UDest Int/) and still has its other hole (\mintinline{haskellc}/UDest OtherStruct/) waiting to be filled. An example of memory behavior of \mintinline{haskellc}/fillComp/ in action can be seen in \cref{fig:schema-dlist-concat}.

Finally, \mintinline{haskellc}/fill ⩴ ∀ lCtor t. UDest t ⊸ UDestsOf lCtor t/ is the generic function to fill a destination with hollow constructors. It takes a data constructor as a type parameter (\mintinline{haskellc}/lCtor/) and allocates a corresponding hollow constructor, that is, a heap object that has the same header as the specified constructor but unspecified fields. The address of the allocated hollow constructor is written in the destination that is passed to \mintinline{haskellc}/fill/. An example of the memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/ is given in \cref{fig:schema-fillCons} and the one for \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/ is given in \cref{fig:schema-fillNil}.

The \mintinline{haskellc}/fill/ function also returns one destination of matching type for each of the fields of the constructor; in Haskell this is represented by \mintinline{haskellc}/UDestsOf lCtor t/. \mintinline{haskellc}/UDestsOf/ is a type family (i.e. a function from types to types) whose role is to map a constructor (lifted as a type) to the type of destinations for its fields. For example, \mintinline{haskellc}/UDestsOf '[] [t] = ()/ and \mintinline{haskellc}/UDestsOf '(:) [t] = (UDest t, UDest [t])/. More generally, the \mintinline{haskellc}/UDestsOf/ typeclass reflects the duality between the types of fields of a constructor and the ones of destinations for a hollow constructor, as first evoked in \cref{ssec:build-up-vocab}.

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/fillCons}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/}
  \label{fig:schema-fillCons}

  \scalebox{\figscale}{\tikzfig{schemas/fillNil}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/}
  \label{fig:schema-fillNil}

  \scalebox{\figscale}{\tikzfig{schemas/fillLeaf}}
  \caption{Memory behavior of \mintinline{haskellc}/fillLeaf ⩴ t → UDest [t] ⊸ ()/}
  \label{fig:schema-fillLeaf}
\end{figure}

\section{Compact Regions: a playground to implement the DPS Haskell API}\label{sec:implementation}

Having incomplete structures in the memory inherently introduces a lot of tension with both the garbage collector and compiler. Indeed, the garbage collector of GHC assumes that every heap object it traverses is well-formed, whereas UAmpar structures are absolutely ill-formed: they contain uninitialized pointers, which the GC should absolutely not follow. Also, the compiler and GC can make some optimizations because they assume that every object is immutable, while DPS programming breaks that guarantee by mutating constructors after they have been allocated (albeit only one update can happen). Consequently, we looked for an alternative memory management scheme, mostly independent from the garbage collector, that would let us implement the DPS Haskell API more easily.

\subsection{Compact Regions}\label{ssec:impl-compact-regions}

\emph{Compact regions} from~\citet{yang_efficient_2015} are special memory \emph{arenas} for Haskell. A compact region represents a memory area in the Haskell heap that is almost fully independent from the GC and the rest of the garbage-collected heap. For the GC, each compact region is seen as a single heap object with a single lifetime. The GC can efficiently check whether there is at least one pointer in the garbage-collected heap that points into the region, and while this is the case, the region is kept alive. When this condition is no longer matched, the whole region is discarded. The result is that the GC won't traverse any node from the region: it is treated as one opaque block (even though it is actually implemented as a chain of blocks of the same size, this doesn't change the principle). Also, compact regions are immobile in memory; the GC won't move them, so a destination to a hole in the compact region can just be implemented as a raw pointer (type \mintinline{haskellc}/Addr#/ in Haskell): \mintinline{haskellc}/data UDest r t = ¤UDest Addr#/, as we have the guarantee that the UAmpar containing the pointed hole won't move.

By using compact regions to implement DPS programming, we completely elude the concerns of tension between the garbage collector and UAmpar structures that we just mentioned above. In exchange, we get two extra restrictions imposed by compact regions. First, every structure in a region must be in a fully-evaluated form. This is contrasting with the usual Haskell evaluation scheme, where everything is lazy by default. Consequently, as regions are strict, any heap object that is copied to a region is first forced into normal form (i.e. it is being fully evaluated). This might not always be a win, sometimes laziness is preferable for better performance.

Secondly, data in a region cannot contain pointers to the garbage-collected heap, or pointers to other regions: it must be self-contained. This forces us to slightly modify the API, to add a phantom type parameter \mintinline{haskellc}/r/ that tags each object with the identifier of the region it belongs to so that our API remains memory-safe, without runtime checks. There are two related consequences: first, when a value from the garbage-collected heap is used as an argument to \mintinline{haskellc}/fillLeaf/, it has to be fully evaluated and copied into the region instead of making just a pointer update; and secondly, \mintinline{haskellc}/fillComp/ can only plug together two \mintinline{haskellc}/UAmpar/s that come from the same region.

A typeclass \mintinline{haskellc}/Region r/ is also needed to carry around the details about a region that are required for the implementation. This typeclass has a single method \mintinline{haskellc}/reflect/, not available to the user, that returns the \mintinline{haskellc}/RegionInfo/ structure associated to identifier \mintinline{haskellc}/r/.

The \mintinline{haskellc}/inRegion/ function is the new addition to the modified API presented in \cref{table:destination-api-regions}. It receives an expression of arbitrary type in which \mintinline{haskellc}/r/ must be a free type variable. Internally, when used, it spawns a new compact region and a fresh type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ (not a variable), and uses the \mintinline{text}/reflection/ library to provide an instance of \mintinline[escapeinside=°°]{haskellc}/Region °\muline{r}°/ on-the-fly that links \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ and the \mintinline{haskellc}/RegionInfo/ for the new region, and then make type application for the supplied expression at the concrete type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/. %This is fairly standard practice since~\cite{launchbury_lazy_1994}.
Actually, \mintinline{haskellc}/inRegion/ is a form of scope function (although this time, it isn't linear).

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
data Token
dup ⩴ Token ⊸ (Token, Token)
drop ⩴ Token ⊸ ()
withToken ⩴ ∀ t. (Token ⊸ Ur t) ⊸ Ur t

type Region r ⩴ Constraint
°\mnew{inRegion ⩴ ∀ t. (∀ r. Region r ⇒ t) ⊸ t}°

data UAmpar r s t
newUAmpar ⩴ ∀ r s. Region r ⇒ Token ⊸ UAmpar s (UDest r s)
tokenBesides ⩴ ∀ r s t. Region r ⇒ UAmpar r s t ⊸ (UAmpar r s t, Token)
toUAmpar ⩴ ∀ r s. Region r ⇒ Token ⊸ s → UAmpar r s ()
fromUAmpar  ⩴ ∀ r s t. Region r ⇒ UAmpar r s (Ur t) ⊸ Ur (s, t)
fromUAmpar' ⩴ ∀ r s. Region r ⇒ UAmpar r s () ⊸ Ur s
updWith ⩴ ∀ r s t u. Region r ⇒ UAmpar r s t ⊸ (t ⊸ u) ⊸ UAmpar r s u

data UDest r t
type family UDestsOf lCtor r t  -- returns dests associated to fields of constructor
fill ⩴ ∀ lCtor r t. Region r ⇒ UDest r t ⊸ UDestsOf lCtor r t
fillComp ⩴ ∀ r s t. Region r ⇒ UAmpar r s t ⊸ UDest r s ⊸ t
fillLeaf ⩴ ∀ r t. Region r ⇒ t → UDest r t ⊸ ()
\end{minted}
\caption{Destination API using compact regions}
\label{table:destination-api-regions}
\end{listing}

\subsection{DPS programming in Compact regions: Deserializing, lifetime, and garbage collection}\label{ssec:parser-sexpr}

We will now study an example, related to implementation concerns, for which DPS programming really shines (and for which compact regions are a really nice fit).

In client-server applications, the following pattern is very frequent: the server receives a request from a client with a serialized payload, the server then deserializes the payload, runs some code, and respond to the request. Most often, the deserialized payload is kept alive for the entirety of the request handling. In a garbage collected language, there's a real cost to this: the garbage collector (GC) will traverse the deserialized payload again and again, although we know that all its internal pointers are live for the duration of the request.

Instead, we'd rather consider the deserialized payload as a single heap object, which doesn't need to be traversed, and can be freed as a block. Compact regions are, in fact, the perfect tool for this job, as the GC never follows pointers into a compact region and consider each region as a having the same lifetime for all its contents.

If we use compact regions as-is, with the API provided with GHC, we would first deserialize the payload normally, in the GC heap, then copy it into a compact region and then only keep a reference to the copy. That way, internal pointers of the region copy will never be followed by the GC, and that copy will be collected as a whole later on, whereas the original one in the GC heap will be collected immediately.

However, we are still allocating two copies of the deserialized payload. This is wasteful, it would be much better to allocate directly in the region. Fortunately, with our implementation of DPS Haskell with compact regions, we now have a much better way to allocate and build structures directly into these compact regions!

Let's see how using destinations and compact regions for a parser of S-expressions (representing our request payload) can lead to greater performance. S-expressions are parenthesized lists whose elements are separated by spaces. These elements can be of several types: int, string, symbol (a textual token with no quotes around it), or a list of other S-expressions.

Parsing an S-expression can be done naively with mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskellc}/parseSExpr/ scans the next character, and either dispatches to \mintinline{haskellc}/parseSList/ if it encounters an opening parenthesis, or to \mintinline{haskellc}/parseSString/ if it encounters an opening quote, or eventually parses the string into a number or symbol;
  \item \mintinline{haskellc}/parseSList/ calls \mintinline{haskellc}/parseSExpr/ to parse the next token, and then calls itself again until reaching a closing parenthesis, accumulating the parsed elements along the way.
\end{itemize}

Only the implementation of \mintinline{haskellc}/parseSList/ will be presented here as it is enough for our purpose, but the full implementation of both the naive and destination-based versions of the whole parser can be found in \texttt{src/Compact/Pure/SExpr.hs} of~\cite{linear_dest}.

The implementation presented in \cref{table:impl-parser-naive} is quite standard: the accumulator \mintinline{haskellc}/acc/ collects the nodes that are returned by \mintinline{haskellc}/parseSExpr/ in the reverse order (because it's the natural building order for a linked list without destinations). When the end of the list is reached (line 5), the accumulator is reversed, wrapped in the \mintinline{haskellc}/¤SList/ constructor, and returned. We also store, in the parsed result, the index \mintinline{haskellc}/i/ corresponding to the end position of the structure in the input string.

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExpr ⩴ ByteString → Int → Either Error SExpr
% parseSExpr bs i = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSList bs (i + 1) []
%     '"' → parseSString bs (i + 1) ¤False []
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%          in if null tok then parseSExpr bs (i + 1) else case parseInt tok of
%               ¤Just int → ¤Right (¤SInteger (i + length tok - 1) int)
%               ¤Nothing → ¤Right (¤SSymbol (i + length tok - 1) (toString tok))
% parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
% parseSList bs i acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → ¤Right (¤SList i (reverse acc))
%     | isSpace x → parseSList bs (i + 1) acc
%     | otherwise → case parseSExpr bs i of
%         ¤Left err → ¤Left err
%         ¤Right child → parseSList bs (endPos child + 1) (child : acc)
% parseSString ⩴ ByteString → Int → Bool → [Char] → Either Error SExpr
% parseSString bs i escape acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → ¤Right (SString i (reverse acc))
%     '\\' | not escape → parseSString bs (i + 1) ¤True acc
%     'n'  | escape → parseSString bs (i + 1) ¤False ('\n' : acc)
%     _ → parseSString bs (i + 1) ¤False (x : acc)
% \end{minted}
% \caption{Implementation of the S-expression parser without destinations}
% \label{table:impl-sexpr-parser-without-dest}
% \end{listing}

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExprDPS ⩴ ByteString → Int → UDest SExpr ⊸ Either Error Int
% parseSExprDPS bs i d = case bs !? i of
%   ¤Nothing → °\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → °\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSListDPS bs (i + 1) °\mnew{(fill @'SList d)}°
%     '"' → parseSStringDPS bs (i + 1) ¤False °\mnew{(fill @'SString d)}°
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%         in if null tok then parseSExprDPS bs (i + 1) d else case parseInt tok of
%               ¤Just int → let °\mnew{!dint = fill @'SInteger d}°
%                           in °\mnew{fillLeaf int dint}° ; ¤Right (i + length tok - 1)
%               _ → let °\mnew{!dsym = fill @'SSymbol d}°
%                    in °\mnew{fillLeaf (toString tok) dsym}° ; ¤Right (i + length tok - 1)
% parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
% parseSListDPS bs i d = case bs !? i of
%   ¤Nothing → °\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → °\mnew{fill @'[] d}° ; ¤Right i
%     | isSpace x → parseSListDPS bs (i + 1) d
%     | otherwise → let !(dh, dt) = °\mnew{fill @'(:) d}°
%                    in case parseSExprDPS bs i °\mnew{dh}° of
%                         ¤Left err → fill @'[] dt ; ¤Left err
%                         ¤Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°
% parseSStringDPS ⩴ ByteString → Int → Bool → UDest [Char] ⊸ Either Error Int
% parseSStringDPS bs i escape d = case bs !? i of
%   ¤Nothing → °\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → °\mnew{fill @'[] d}° ; ¤Right i
%     '\\' | not escape → parseSStringDPS bs (i + 1) ¤True d
%     'n'  | escape → let °\mnew{!(dh, dt) = fill @'(:) d}°
%                      in °\mnew{fillLeaf '\textbackslash{}n' dh}° ; parseSStringDPS bs (i + 1) ¤False °\mnew{dt}°
%     _ → let °\mnew{!(dh, dt) = fill @'(:) d}°
%          in °\mnew{fillLeaf x dh}° ; parseSStringDPS bs (i + 1) ¤False °\mnew{dt}°
% \end{minted}
% \caption{Implementation of the S-expression parser with destinations}
% \label{table:impl-sexpr-parser-with-dest}
% \end{listing}

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
parseSList bs i acc = case bs !? i of
  ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → ¤Right (¤SList i (reverse acc))
    | isSpace x → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        ¤Left err → ¤Left err
        ¤Right child → parseSList bs (endPos child + 1) (child : acc)
\end{minted}
\caption{Implementation of the S-expression parser without destinations}
\label{table:impl-parser-naive}
\end{listing}

\begin{listing}[b]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
parseSListDPS bs i d = case bs !? i of
  ¤Nothing → °\mnew{d &fill @'[]}° ; ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → °\mnew{d &fill @'[]}° ; ¤Right i
    | isSpace x → parseSListDPS bs (i + 1) d
    | otherwise →
        case °\mnew{d &fill @'(:)}° of
          (dh, dt) → case parseSExprDPS bs i °\mnew{dh}° of
              ¤Left err → dt &fill @'[] ; ¤Left err
              ¤Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°
\end{minted}
\caption{Implementation of the S-expression parser with destinations}
\label{table:impl-parser-dps}
\end{listing}

We will see that destinations can bring very significative performance gains with only very little stylistic changes in the code. Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location and in the right order!

Code for \mintinline{haskellc}/parseSListDPS/ is presented in \cref{table:impl-parser-dps}. Let's see what changed compared to the naive implementation:

\begin{itemize}
  \item even for error cases, we are forced to consume the destination that we receive as an argument (to stay linear), hence we write some sensible default data to it (see line 3);
  \item the \mintinline{haskellc}/SExpr/ value resulting from \mintinline{haskellc}/parseSExprDPS/ is not collected by \mintinline{haskellc}/parseSListDPS/ but instead written directly into its final location by \mintinline{haskellc}/parseSExprDPS/ through the passing and filling of destination \mintinline{haskellc}/dh/ (see line 9);
  \item adding an element of type \mintinline{haskellc}/SExpr/ to the accumulator \mintinline{haskellc}/[SExpr]/ is replaced with writing a new cons cell with \mintinline{haskellc}/fill @'(:)/ into the hole represented by the \mintinline{haskellc}/UDest [SExpr]/, writing an element to the new \emph{head} destination, and then doing a recursive call with the new \emph{tail} destination passed as an argument (which has type \mintinline{haskellc}/UDest [SExpr]/ again);
  \item instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskellc}/fill @'[]/, see line 5), as the list has been built in a top-down approach;
  \item ultimately, DPS functions just return the offset of the next character to read instead of returning a parsed value (as the parsed value is written directly into the destination received as a parameter).
\end{itemize}

Thanks to that new implementation which is barely longer (in terms of lines of code) than the naive one, the program runs almost twice as fast, mostly because garbage-collection time goes to almost zero. The detailed benchmark is available in \cref{sec:benchmark}.

We see here that compact regions and destination-passing style are quite symbiotic; compact regions makes the DPS Haskell API easy to implement, and destination-passing style makes compact regions more efficient and flexible to use.

\subsection{Memory representation of \texttt{UAmpar} objects in Compact Regions}\label{ssec:repr-ampar}

As we detailed in \cref{ssec:runtime-values,ssec:dpshaskell-dlist}, we want \mintinline{haskellc}/UAmpar r s t/ to contains a value of type \mintinline{haskellc}/s/ and one of type \mintinline{haskellc}/t/, and let the value of type \mintinline{haskellc}/s/ free when the one of type \mintinline{haskellc}/t/ has been fully consumed (or linearly transformed into \mintinline{haskellc}/Ur t'/).% So the most straightforward implementation for \mintinline{haskellc}/UAmpar/ would be a pair \mintinline{haskellc}/(s, t)/, where \mintinline{haskellc}/s/ in the pair is only partially complete.

We also know that \mintinline{haskellc}/newUAmpar/ returns an \mintinline{haskellc}/UAmpar r s (UDest s)/: there is nothing more here than an empty memory cell that will host the root of the future structure of type \mintinline{haskellc}/s/, which the associated destination of type \mintinline{haskellc}/UDest s/ points to, as presented in \cref{fig:schema-alloc}. As we said earlier, whatever goes in the destination is exactly what will be retrieved in the \mintinline{haskellc}/s/ side.

The naive and most direct idea is to represent \mintinline{haskellc}/UAmpar r s t/ in memory as a pair-like constructor with one field of type \mintinline{haskellc}/s/ and one of type \mintinline{haskellc}/t/, with the first field being there to host the root of the structure being built (as in \cref{fig:schema-alloc}). However, the root hole, that will later host the structure of type \mintinline{haskellc}/s/, might contain garbage data, so the GC must be prevented to read it and follow uninitialized pointers (otherwise we risk a segmentation fault). In our compact region implementation, we can prevent this issue by having the root hole live inside the compact region (so that the GC doesn't look into it). But we also want the \mintinline{haskellc}/¤UAmpar/ constructor to live in the garbage-collected heap so that it can sometimes be optimized away by the compiler, and always deallocated as soon as possible. These two requirements are, apparently, incompatible, as the root hole corresponds to the first field of the \mintinline{haskellc}/¤UAmpar/ constructor in this representation.

Given that UAmpars hold unrestricted data, one potential workaround is to represent \mintinline{haskellc}/UAmpar r s t/ in memory as a constructor with one field of type \mintinline{haskellc}/Ur s/ and one of type \mintinline{haskellc}/t/ (instead of one of type \mintinline{haskellc}/s/ and one of type \mintinline{haskellc}/t/ previously). It means we need an intermediary \mintinline{haskellc}/¤Ur/ constructor between the UAmpar wrapper and the structure of type \mintinline{haskellc}/s/ being built, and we can decide to allocate this \mintinline{haskellc}/¤Ur/ constructor inside the region, with its field of type \mintinline{haskellc}/s/, also inside the region, serving as the root hole. With this approach, illustrated in \cref{fig:schema-alloc-region-notchosen}, we have a root hole that won't be read by the GC, while the \mintinline{haskellc}/UAmpar/ wrapper can live in the GC heap without issues and be discarded as soon as possible, as we wanted! We also get a very efficient implementation of \mintinline{haskellc}/fromUAmpar'/, as the first field of a completed UAmpar is directly what \mintinline{haskellc}/fromUAmpar'/ should return (it doesn't help for \mintinline{haskellc}/fromUAmpar/ though). The downside is that every UAmpar will now allocate a few words in the region (to host the \mintinline{haskellc}/¤Ur/ constructor\footnote{One might ask why \mintinline{haskellc}/Ur/ can't be a zero-cost \mintinline{haskellc}/newtype/ wrapper. First, if \mintinline{haskellc}/Ur/ were a \mintinline{haskellc}/newtype/, it wouldn't work for what we are trying to achieve here, as we are relying on the fact that it creates an indirection in memory. Secondly, and more importantly, there are semantics motivations, detailed in\cite{spiwack_ur_2024}.}) that won't be collected by the GC for a long time even if the parent \mintinline{haskellc}/UAmpar/ is collected. In particular, this makes \mintinline{haskellc}/toUAmpar/ quite inefficient memory-wise, as it will have to allocate a \mintinline{haskellc}/Ur/ wrapper in the region that is useless for already complete structures (because already complete structures don't need to have a root hole living in the compact region, as they don't have holes at all).

\begin{figure}
\centering
\scalebox{\figscale}{\tikzfig{schemas/alloc-region-notchosen}}
\caption{Representation of UAmpars in the compact region implementation, using \mintinline{haskellc}/Ur/ (not chosen)}\label{fig:schema-alloc-region-notchosen}
\end{figure}

Another option, that we decided to go for in our real implementation, is to allocate an object inside the compact region to host the root hole of the structure \emph{only} for truly incomplete structures created with \mintinline{haskellc}/newUAmpar/. For already complete structures that are turned into an \mintinline{haskellc}/UAmpar/ with \mintinline{haskellc}/toUAmpar/, we skip this allocation; but we preserve the same underlying types for the fields of the UAmpar in both cases (\mintinline{haskellc}/newUAmpar/ and \mintinline{haskellc}/toUAmpar/). This is made possible by the use of the special indirection object (\mintinline{haskellc}/stg_IND/ in GHC codebase) in the UAmpar returned by \mintinline{haskellc}/newUAmpar/. A \mintinline{haskellc}/stg_IND/ object is a kind of one-field constructor that is considered to have type \mintinline{haskellc}/s/ although its field also has type \mintinline{haskellc}/s/. We illustrate this in \cref{fig:schema-alloc-region}:

\begin{figure}
\centering
\scalebox{\figscale}{\tikzfig{schemas/alloc-region}}
\caption{Chosen representation for UAmpars in the compact region implementation, using indirections}\label{fig:schema-alloc-region}
\end{figure}

\begin{itemize}
  \item in the pair-like structure returned by \mintinline{haskellc}/newUAmpar/, the \mintinline{haskellc}/s/ side points to an indirection object, which is allocated in the region, and serves as the root hole for the incomplete structure (because it is in the compact region, the GC won't follow garbage pointers that it might contain at the moment);
  \item in the pair-like structure returned by \mintinline{haskellc}/toUAmpar/, the \mintinline{haskellc}/s/ side directly points to the object of type \mintinline{haskellc}/s/ that has been copied to the region, without indirection.
\end{itemize}
Compared to the previous solution, this one is more efficient when using \mintinline{haskellc}/toUAmpar/ (as no long-lived garbage is produced), but does no longer give efficiency benefits for \mintinline{haskellc}/fromUAmpar'/ (as we no longer produce an \mintinline{haskellc}/Ur/ object). This is the solution we arbitrarily chose to implement in the original artifact \cite{linear_dest}, but it could be worth comparing and benchmarking it with the one based on \mintinline{haskellc}/Ur/ indirection in a variety of real-world use-cases.

In the end, in \cite{linear_dest}, we have the following private definitions\footnote{In the sense that they are opaque for the consumer of the API.} for our API types:
\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
data Token = ¤Token  -- same representation as ()
data UAmpar r s t = ¤UAmpar s t  -- same representation as (s, t),
                                        -- with sometimes an indirection on the s field
data UDest r t = ¤UDest Addr#  -- boxed Addr#, same representation as Ptr t
\end{minted}
}
\end{unbreakable}

\subsection{Deriving \texttt{fill} for all constructors with \texttt{Generics}}\label{ssec:impl-generics}

In \destcalculus, it was quite easy to have a dedicated destination-filling function for each corresponding data constructor. Indeed, we only had to account for a finite number of them (one for unit, two for sums, one for pair, and one for exponential; with the one for function being quite optional).

In Haskell however, we want to be able to do destination passing with arbitrary data types, even user-defined ones, so it wouldn't be feasible to implement, manually, one filling function per possible data constructor. So instead, we have to generalize all filling functions into a polymorphic \mintinline{haskellc}/fill/ function that is able to work for any data constructor.

To this extend, we create a typeclass \mintinline{haskellc}/Fill lCtor t/, and we define \mintinline{haskellc}/fill/ as the only method of this class. Having such a typeclass let us tie the behaviour of \mintinline{haskellc}/fill/ to the type parameter \mintinline{haskellc}/lCtor/. The idea is that \mintinline{haskellc}/lCtor/ represents the type-level name of the data constructor we want to use \mintinline{haskellc}/fill/ with. The syntax at call site is of the form \mintinline{haskellc}/fill @'Ctor/: we lift the constructor \mintinline{haskellc}/¤Ctor/ into a type-level name with the \mintinline{haskellc}/'/ operator, then make a type application with \mintinline{haskellc}/@/. We recall that the \mintinline{haskellc}/fill/ function should plug a new hollow constructor of the specified variant into the hole of a structure whose corresponding destination is received as an argument.

Let's now see how we can use the type-level name of the constructor \mintinline{haskellc}/lCtor/ and its base type \mintinline{haskellc}/t/ to obtain all the information we need to write the concrete implementation of the corresponding \mintinline{haskellc}/fill/ function. The first thing we need to know is the shape of the constructor and more precisely the number and types of its fields, as every data constructor for a linked data type\footnote{Dealing with primitive or unboxed types is, on the other hand, quite challenging, see the mention at the end of \cref{sec:implem-destcalculus}.} can be seen as a n-ary product constructor. So we will leverage \mintinline{haskellc}/GHC.Generics/ to find the required information.

\mintinline{haskellc}/GHC.Generics/ is a built-in Haskell library that provides compile-time inspection of a type metadata through the \mintinline{haskellc}/Generic/ typeclass: list of constructors, their fields, memory representation, etc. And that typeclass can be derived automatically for (almost) any type! Here's, for example, the \mintinline{haskellc}/Generic/ representation of \mintinline{haskellc}/Maybe t/:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
repl> :k! Rep (Maybe a) () -- display the Generic representation of Maybe a
M1 D (MetaData "Maybe" "GHC.Maybe" "base" False) (
  M1 C (MetaCons "¤Nothing" PrefixI False) U1
  :+: M1 C (MetaCons "¤Just" PrefixI False) (M1 S ¤[...¤] (K1 R t)))
\end{minted}
}
\end{unbreakable}

We see that there are two different constructors (indicated by \mintinline{haskellc}/M1 C .../ lines): \mintinline{haskellc}/¤Nothing/ has zero fields (indicated by \mintinline{haskellc}/U1/) and \mintinline{haskellc}/¤Just/ has one field of type \mintinline{haskellc}/t/ (indicated by \mintinline{haskellc}/K1 R t/).

As illustrated with the example above, the generic representation of a type contains most of what we want to know about its constructors. So, with type-level programming techniques\footnote{see \texttt{src/Compact/Pure/Internal.hs:418} in~\cite{linear_dest}}, in particular with type families, we can extract the parts of this generic representation that are relevant to us (as type-level expressions), and refer to them in the head of our typeclass' instances, to have several specialized implementation of \mintinline{haskellc}/fill/. For instance, in \cite{linear_dest}, we have one specialized implementation of \mintinline{haskellc}/fill/ for every possible number of fields in \mintinline{haskellc}/lCtor/, from 0 to 7\footnote{We could go higher, 7 is just an arbitrary limit for the number of fields that is rather common in standard Haskell libraries.}. The main reason is that \mintinline{haskellc}/fill/ should return a tuple containing as many new destinations as there are fields in the the chosen constructor, and at the moment, there is no way to abstract over the length of a tuple in Haskell, so we need to harcode each possible case.

The resolution of the \mintinline{haskellc}/UDestsOf lCtor t/ type family into a concrete tuple type of destinations is made similarly, by type-level expressions based on the generic representation of the base type \mintinline{haskellc}/t/ which \mintinline{haskellc}/lCtor/ belongs to.

At this point we still miss a major ingredient though: the internal Haskell machinery to allocate the proper hollow constructor object in the compact region.

\subsection{Changes to GHC internals and its RTS}\label{ssec:impl-ghc}

%STOPPED HERE%

We will see here how to allocate a hollow constructor, that is, a hollow heap object for a given constructor, but let's first take a detour to give more context about the internals of the compiler.

Haskell's runtime system (RTS) is written in a mix of C and C-\,-. The RTS has many roles, among which managing threads, organizing garbage collection or managing compact regions. It also defines various primitive operations, named \emph{external primops}, that expose the RTS capabilities as normal functions that can be used in Haskell code. Despite all its responsibilities, however, the RTS is not responsible for the allocation of normal constructors (built in the garbage-collected heap). One reason is that it doesn't have all the information needed to build a constructor heap object, namely, the info table associated to the constructor.

In Haskell, a heap object is a piece of data in memory, that corresponds to a given instance of a data constructor, or a (partially-applied) function. The info table is what defines both the layout and behavior of a heap object. All heap objects representing a same data constructor (let's say \mintinline{haskellc}/¤Just/) have the same info table, which acts as the identity card for this constructor, even when the associated types are different (e.g. \mintinline{haskellc}/Just x ⩴ Maybe Int/ and \mintinline{haskellc}/Just y ⩴ Maybe Bool/ shares the same info table). In the compilation process, during the code generation, all instances of the \mintinline{haskellc}/Just/ constructor will hold the label \mintinline{text}/Just_con_info/, that is later resolved by the linker into an actual pointer to the shared info table, that all corresponding heap objects for this constructor will carry.

On the other hand, the RTS is a static piece of code that is compiled once when GHC is built, and is then copied into every executable built by GHC. Only when a program is launched does the RTS run (to overwatch the program execution), so the RTS has no direct way to access the information that had been emitted during the compilation of the program. In particular, it has no way to inspect the info table labels have long been replaced by actual pointers (which are indistinguishable in memory from any other data). But on the other hand, the RTS is the one which knows how to allocate space inside a compact region for our new hollow constructor.

As a result, we need a way to pass information, or more precisely, the info table pointer, from compile time to the runtime. Consequently, we manage the creation of a new hollow constructor in a compact region through two new primitives:

\begin{itemize}
\item one \emph{internal primop} which resolves, at compile time, a data constructor into the (static) value representing its info table pointer.
\item one \emph{external primop}, in the RTS, which allocates space inside a compact region for a hollow constructor, and which sets the info table pointer of the hollow constructor to a value received as an argument, that the developer can provide using the internal primop.
\end{itemize}

All the alterations to GHC that will be showed here are available in full form in~\cite{custom_ghc}.

\paragraph{Internal primop: obtain the info table pointer of a constructor as a static value}

Internal primops are macros that are transformed at compile time into C-\,- code. So for our new internal primop, in charge of obtaining the info table label (later resolved into a pointer) of a constructor, we must indicate our choice of constructor as some type-level information so that it can be inspected as compile-time (as, of course, term-level values cannot be inspected easily at compile time). For that, we have to lift the chosen constructor into a type-level value, using operator \mintinline{haskellc}/'/, and have the internal primop accept a type parameter (representing our choice of constructor) and inspect it.

Usually, in Haskell, we use a parameter of type \mintinline{haskellc}/Proxy t/ (the unit type with a phantom type parameter \mintinline{haskellc}/t/) as a carrier for a type-level input that we want to pass to a function. Unfortunately, primops are special functions, and due to a quirk of the compiler, they no longer have access to the type of their arguments at the stage in which they are resolved, so designing our primop with a \mintinline{haskellc}/Proxy lCtor/ parameter wouldn't let it read the supplied type. However primops can ---surprisingly--- access their return type. Consequently, we design a custom return type \mintinline{haskellc}/InfoPtrPlaceholder#/ for our primop that carries the output value of the primop (that is to say, an info table pointer); but we also add a phantom type parameter \mintinline{haskellc}/lCtor/ to \mintinline{haskellc}/InfoPtrPlaceholder#/ that has no relation to the underlying value, but just serves as a carrier for our type-level input representing the chosen constructor!

The concrete implementation is presented brielfy in \cref{table:impl-reifyInfoPtr}. This implementation goes a bit further than what we just described above, as \mintinline{haskellc}/reifyInfoPtr#/ can obtain the info table pointer of data constructors (as announced), but also the info table pointer of special compiler objects like the indirection object we used in \cref{ssec:repr-ampar}. The primop pattern-matches on the type \mintinline{haskellc}/resTy/ of its return value (which should be of the form of the form \mintinline{haskellc}/InfoPtrPlaceholder# lCtorOrSym/). In the case it reads a lifted data constructor (which is the most common case), it resolves the primop call into the label \mintinline{text}/<ctor>_con_info/ which corresponds to the info table pointer of that constructor. In the case \mintinline{haskellc}/lCtorOrSym/ is a symbol (that is, a type-level string literal), it resolves the primop call into the label \mintinline{text}/stg_<sym>/ (e.g. to allocate a \mintinline{haskellc}/stg_IND/ object, as we just mentionned). The returned \mintinline{haskellc}/InfoPtrPlaceholder# lCtorOrSym/ can later be converted back to an \mintinline{haskellc}/Addr#/ using the \mintinline{haskellc}/unsafeCoerceAddr/ function (nothing is particularly \emph{unsafe} here, despite the name, as both types share the same underlying representation).

\begin{listing}
\figtextsize
\begin{minted}[linenos]{haskellc}
case primop of
  [...]
  ¤ReifyInfoPtrOp → \_ →  -- we don't care about the function argument (# #)
    opIntoRegsTy $ \[res] resTy → emitAssign (¤CmmLocal res) $ case resTy of
      -- when the phantom type parameter is a lifted data constructor, extracts it as a DataCon
      ¤TyConApp _infoPtrPlaceholderTyCon [_typeParamKind, ¤TyConApp tyCon _]
        | ¤Just dataCon ← isPromotedDataCon_maybe tyCon →
          ¤CmmLit (¤CmmLabel (
            mkConInfoTableLabel (dataConName dataCon) ¤DefinitionSite))
      -- when the phantom type parameter is a Symbol, we extracts the symbol value in 'sym'
      ¤TyConApp _infoPtrPlaceholderTyCon [_typeParamKind, ¤LitTy (¤StrTyLit sym)] →
          ¤CmmLit (¤CmmLabel (
            mkCmmInfoLabel rtsUnitId (fsLit "stg_" `appendFS` sym)))
      _ → [...] -- error when no pattern matches
\end{minted}
\caption{\texttt{reifyInfoPtr\#} implementation in \texttt{compiler/GHC/StgToCmm/Prim.hs}}
\label{table:impl-reifyInfoPtr}
\end{listing}

\paragraph{External primop: allocate a hollow constructor in a region}

Our external primop, as part of the RTS, is directly written in C-\,-. Its implementation is presented in \cref{table:impl-compactAddHollow}, under the name \mintinline{c}/stg_compactAddHollowzh/; but in Haskell code we access it through the name \mintinline{haskellc}/compactAddHollow#/. The primop consists mostly in a glorified call to the \mintinline{haskellc}/ALLOCATE/ macro defined in the \mintinline{text}/Compact.cmm/ file, which tries to do a pointer-bumping allocation in the current block of the compact region if there is enough space, and otherwise add a new block to the region. Then, it takes the info table pointer of the constructor to allocate, received as its second parameter \mintinline{c}/W_ info/ (as it cannot obtain this information itself), and write it to the first word of the heap object using \mintinline{c}/SET_HDR/. Then the pointer to the newly allocated hollow constructor is set as the return value.

\begin{listing}
\figtextsize
\begin{minted}[linenos]{c}
// compactAddHollow#
//   ⩴ Compact# → Addr# → State# RealWorld → (# State# RealWorld, a #)
stg_compactAddHollowzh(P_ compact, W_ info) {
    W_ pp, ptrs, nptrs, size, tag, hp;
    P_ to, p; p = NULL;  // p isn't actually used by ALLOCATE macro
    again: MAYBE_GC(again); STK_CHK_GEN();

    pp = compact + SIZEOF_StgHeader + OFFSET_StgCompactNFData_result;
    ptrs  = TO_W_(%INFO_PTRS(%STD_INFO(info)));
    nptrs  = TO_W_(%INFO_NPTRS(%STD_INFO(info)));
    size = BYTES_TO_WDS(SIZEOF_StgHeader) + ptrs + nptrs;
    
    ALLOCATE(compact, size, p, to, tag);
    P_[pp] = to;
    SET_HDR(to, info, CCS_SYSTEM);
  #if defined(DEBUG)
    ccall verifyCompact(compact);
  #endif
    return (P_[pp]);
}
\end{minted}
\caption{\texttt{compactAddHollow\#} implementation in \texttt{rts/Compact.cmm}}
\label{table:impl-compactAddHollow}
\end{listing}

\paragraph{Combining both primops to obtain a new hollow constructor}

It's time to show the two primops in action. Here is how we could allocate, for example, a hollow \mintinline{haskellc}/¤Just/ in a compact region:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos]{haskellc}
hollowJust ⩴ Maybe a = compactAddHollow#
  region
  (unsafeCoerceAddr (reifyInfoPtr# (# #) ⩴ InfoPtrPlaceholder# 'Just ))
\end{minted}
}
\end{unbreakable}

It's important to note that the expression \mintinline{haskellc}/reifyInfoPtr# (# #)/ will be replaced at compile-time by a static value representing the info table pointer of \mintinline{haskellc}/¤Just/; while the call to \mintinline{haskellc}/compactAddHollow#/ behaves as a normal function call, and will only be executed when the program runs.

\paragraph{Built-in type family to go from a lifted constructor to the associated symbol}

The internal primop \mintinline{haskellc}/reifyInfoPtr#/ that we just introduced uses a constructor lifted at type level as an input. So the \mintinline{haskellc}/fill/ function, which uses \mintinline{haskellc}/reifyInfoPtr#/ and \mintinline{haskellc}/compactAddHollow#/ under the hood, should also use a constructor lifted at type level as a way of selecting the hollow constructor that will be added to a structure with holes.

However, \mintinline{haskellc}/fill/ relies on \mintinline{haskellc}/GHC.Generics/ to obtain various informations on the chosen constructor (see \cref{ssec:impl-generics}), and in the \mintinline{haskellc}/Generic/ representation of a type, constructors are identified by their name (as type-level strings), which are distinct type-level entities than the constructors lifted at type level like we used in \mintinline{haskellc}/reifyInfoPtr#/.

Consequently, we need a way to translate a constructor lifted at type level into the type-level string representing the name of this constructor\footnote{We do the translation in this specific direction because the type-level string representing the name of the constructor is not enough to fully identify a given constructor.}. This is the role of the type family \mintinline{haskellc}/LCtorToSymbol/ that we also added to GHC. It just inspects its (type-level) parameter representing a constructor, fetches its associated \mintinline{haskellc}/DataCon/ structure, and returns a type-level string (kind \mintinline{haskellc}/Symbol/) carrying the constructor name, as presented in \cref{table:impl-LCtorToSymbol}.

\begin{listing}
\figtextsize
\begin{minted}[linenos]{haskellc}
matchFamLCtorToSymbol ⩴ [Type] → Maybe (CoAxiomRule, [Type], Type)
matchFamLCtorToSymbol [kind, ty]
  | ¤TyConApp tyCon _ ← ty, ¤Just dataCon ← isPromotedDataCon_maybe tyCon =
      let symbolLit = (mkStrLitTy . occNameFS . occName . getName $ dataCon)
       in ¤Just (axLCtorToSymbolDef, [kind, ty], symbolLit)
matchFamLCtorToSymbol tys = ¤Nothing

axLCtorToSymbolDef =
  mkBinAxiom "LCtorToSymbolDef" typeLCtorToSymbolTyCon ¤Just
    (\case { ¤TyConApp tyCon _ → isPromotedDataCon_maybe tyCon ; _ → ¤Nothing })
    (\_ dataCon → ¤Just (mkStrLitTy . occNameFS . occName . getName $ dataCon))
\end{minted}
\caption{\mintinline{haskellc}/LCtorToSymbol/ implementation in \texttt{compiler/GHC/Builtin/Types/Literal.hs}}
\label{table:impl-LCtorToSymbol}
\end{listing}

\paragraph{Putting it all together, and further evolutions}

All these elements combined provide the low-level backbone needed to implement our \mintinline{haskellc}/fill/ function. The implementations presented above have been thought to require the minimal number of changes on GHC, as we considered destination passing to be a niche concern that couldn't justify large exotic changes to this industrial-grade compiler.

However, since this first experimentation\cite{custom_ghc}, a pull request has been opened\cite{bagrel_primitives_2024} to gather community input on the topic, with the goal to eventually merge support for hollow constructor building into the main, publicly-distributed branch of GHC. It seems that we are moving towards a slightly more complete set of primitives than the three aforementioned ones, in particular with primitive forms for \mintinline{haskellc}/fill/ being part of the GHC additions (instead of being only in library code, as it is now). Still, much work remains to be done before we can reach a mergeable state.

\section{Evaluating the performance of DPS programming}\label{sec:benchmark}

It's now time to see if our claims of performance are verified with our prototype destination-passing implementation \cite{linear_dest}.

\paragraph{Benchmarking methodology}

Without surprise, we will compare programs in both naive style and DPS style, and see if we can observe differences in terms of speed but also memory efficiency. But first we must be careful in the way we measure time and space usage, especially since Haskell defaults to a lazy evaluation strategy.

In every DPS implementation that we'll benchmark, the output produced by the program is stored in a compact region (we don't really have the choice). As we said in \cref{ssec:impl-compact-regions}, compact regions also force strictness i.e. the structure will be automatically in a fully evaluated form. It might be counterproductive in some use-cases, but at least it makes things simpler for the benchmark (in which we want to force the result to a fully evaluated form).

For the naive implementations on the other hand, we have a choice to make on the way we fully evaluate the result. We can either keep the result inside the GC heap, and use the function \mintinline{haskellc}/Control.DeepSeq.force/ to recursively force each thunk of the GC heap into an evaluated form; or we can use \mintinline{haskellc}/Data.Compact.compact/ to copy the result from the GC heap to a compact region, that is strict by default and thus will force evaluation. 

That being said, having the result of the function copied into a compact region is only desirable for a handful of programs, for which the result will be held in memory for a long time and used in full (as the unused parts cannot be collected if it is in a compact region). Consequently, we often benchmark the naive implementations with \mintinline{haskellc}/force/ (the associated benchmark names are denoted with a ``*'' suffix), and only benchmark with both \mintinline{haskellc}/force/ and \mintinline{haskellc}/compact/ copy when it seems relevant.

\begin{figure}[t]\centering
  \hspace*{-1.5cm}\includegraphics[width=16.8cm]{graphics/bench-charts.pdf}
  \caption{Benchmarks performed on AMD EPYC 7401P @ 2.0 GHz (single core, \texttt{-N1 -O2})}
  \label{fig:bench-charts}
\end{figure}

\subsection{Concatenating lists and difference lists}

We compared three implementations for list concatenation.

The first one, \mintinline{haskellc}/foldr (++)/*, has calls to \mintinline{haskellc}/(++)/ nested to the right, giving the most optimal context for list concatenation: it should run in $\mathcal{O}(n)$ time. We only use it as a reference, as it is quite unrealistic: we often want to concatenate lists with nesting to the left, e.g. when appending lines to a log before flushing it to the disk.

Hence, for the two other implementations, the calls to concat nested to the left. The implementation \mintinline[escapeinside=°°]{haskellc}/foldl' concat°$\lambda$°/* uses function-backed difference lists, and \mintinline{haskellc}/foldl' concatDPS/ uses destin\-ation-backed ones (from \cref{ssec:dpshaskell-dlist}). They should still run in $\mathcal{O}(n)$ however, thanks to difference list magic.

We see in part \textbf{A} of \cref{fig:bench-charts} that the destination-backed difference lists have a comparable memory use as the two other implementations, while being quite slower (by a factor 2-4) on all datasets. It's still unclear where the performance loss comes from. We tried to profile the program but we couldn't identify clear culprit that would cause a particular slowdown. We must admit that programming with destinations and linear types in general still require a bit of embarassing boilerplate compared to naive versions, where some performance might be lost. These tests would need to be redone though in a more recent version of GHC, as performance of linear types has been improved in GHC 9.8.

\subsection{Breadth-first relabeling}\label{par:benchmark-bf-tree-traversal}

For breadth-first tree traversal, we benchmark the implementation of \cref{ssec:bf-tree-traversal} against a fancy functional implementation based on \emph{Phases} applicatives presented in~\cite{gibbons_phases_2023}:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos]{haskellc}
import Control.Monad.State.Lazy (runState, state)

data Phases m a where
  Pure :: a → Phases m a
  Link :: (a → b → c) → m a → Phases m b → Phases m c

instance Functor (Phases m) where ...
instance (Applicative m) ⇒ Applicative (Phases m) ...

now :: (Applicative m) ⇒ m a → Phases m a
now xs = Link (curry fst) xs (Pure ())

later :: (Applicative m) ⇒ Phases m a → Phases m a
later xs = Link (curry snd) (pure ()) xs

runPhases :: (Applicative m) ⇒ Phases m a → m a
runPhases (Pure x) = pure x
runPhases (Link f xs ys) = pure f <*> xs <*> runPhases ys

traverseBFS :: (Applicative m) ⇒ (a → m b) → BinTree a → Phases m (BinTree b)
traverseBFS _ Nil = pure Nil
traverseBFS f (Node x tl tr) =
  pure Node <*> now (f x) <*> later ((traverseBFS f) tl) <*> later ((traverseBFS f) tr)

relabelPhases :: BinTree () → (BinTree Int, Int)
relabelPhases tree = runState (runPhases $ traverseBFS (\_ → state (\s → (s, s + 1))) tree) 0
\end{minted}
}
\end{unbreakable}

We see in part \textbf{B} of \cref{fig:bench-charts} that the destination-based tree traversal is almost one order of magnitude more efficient, both time-wise and memory-wise, compared to the implementation from \citet{gibbons_phases_2023}. We must admit though that we didn't particularly try to optimize the performance of the \emph{Phases} implementation as much as we did for our DPS framework in general.

\subsection{Parsing S-expressions}

In part \textbf{C} of \cref{fig:bench-charts}, we compare the naive and DPS implementations of the S-expression parser presented in \cref{ssec:parser-sexpr}. For this particular program, using compact regions is interesting even without destination-passing considerations, as it will reduce the GC load of the application as long as the data is held in memory (which is quite usual with parsed documents). Thus, we benchmark the naive version twice: once where the results stays in the GC heap and is evaluated with \mintinline{haskellc}/force/ (its name is suffixed with a star), and once to produce a result that we copy in a compact region using \mintinline{haskellc}/compact/.

The DPS implementation starts by being less efficient than the naive versions for small inputs, but gets an edge as soon as garbage collection kicks in (on datasets of size $\leq 2^{16}$, no garbage collection cycle is required as the heap size stays small).

On the largest dataset ($2^{22} \simeq 4$\,MiB file), the DPS implementation still makes about 45\% more allocations than the starred naive one, but uses 35\% less memory at its peak, and more importantly, spends 47$\times$ less time in garbage collection. As a result, the DPS implementation terminates in 0.65$\times$ the time it takes for the best of the two naive implementation to complete, thanks to garbage collection savings. All of this also indicates that most of the data allocated in the GC heap by the DPS version is wrappers such as \mintinline{haskellc}/UAmpar/s and \mintinline{haskellc}/UDest/s that just last one generation and thus can be discarded very early by the GC (as intended), without needing to be copied into the next generation, unlike the data nodes allocated by the naive versions that have to be persisted by GC (by copying or moving them). In a real-world scenario, where data is processed for some time after having been parsed, we would expect the naive implementation using \mintinline{haskellc}/compact/ to get more efficient in terms of garbage collection time (and thus, run time) than the starred naive version using \mintinline{haskellc}/force/, but it would still be behind the DPS implementation which saves unecessary copies from the GC heap to the compact region.

\subsection{Mapping a function over a list}\label{ssec:benchmark-map}

In a strict functional language such as OCaml, the choice of implementation for the \emph{map} function on lists is crucial as the naive, non tail-recursive one (further referred to as \mintinline{haskellc}/map/) makes the stack grow linearly with the size of the processed list. To alleviate the issue, a strict tail-recursive implementation is possible (\mintinline{haskellc}/mapTR'/), but it requires an extra $\mathcal{O}(n)$ operation at the end of the processing to reverse the accumulator. In Haskell, the issue is of a lesser importance perhaps, as the lazy-by-default evaluation strategy makes the naive \mintinline{haskellc}/map/ perform quite well in most real-world programs. Still, let see what our DPS API brings to the table.

With destinations, \emph{map} can be implemented in a tail-recursive fashion too (\mintinline{haskellc}/mapDPS'/), as explained in \cref{ssec:map-tr}, without requiring the reverse operation that \mintinline{haskellc}/mapTR'/ needs, as the list is built directly in a top-down approach. It can alternatively be implemented as a fold (\mintinline{haskellc}/mapDPSFold'/), as we also show below. Here, the \mintinline{haskellc}/!/ in front of a variable name denotes a (weakly) strict binding, so the expression assigned to the variable will be partially evaluated before the body of the \mintinline{haskellc}/let/ is evaluated:
{\figtextsize
\begin{minted}[linenos]{haskellc}
append ⩴ UDest [t] ⊸ t → UDest [t]
d `append` x = case d &fill @'(:) of (dh, dt) → dh &fillLeaf x ; dt

mapDPS' _ [] d = d &fill @'[]
mapDPS' f (x : xs) d = let !y = f x ; !d' = d `append` y in mapDPS' f xs d'

mapDPSFold' f l dl = fill @'[] (foldl' (\d x → let !y = f x in d `append` y) d l)
\end{minted}
}

% TODO: update figure

We see in part 4 of \cref{fig:bench-charts} that the destination-based implementations \mintinline{haskellc}/mapDPS'/ and \mintinline{haskellc}/mapDPSFold'/ takes 1.5-4$\times$ more time than the naive \mintinline{haskellc}/map/ and \mintinline{haskellc}/mapTR'/ (depending on the dataset size), but memory-wise both \mintinline{haskellc}/mapDPS'/ and \mintinline{haskellc}/mapDPSFold'/ are more efficient than \mintinline{haskellc}/map/; and \mintinline{haskellc}/mapDPS'/ even manage to make 13\% fewer allocs than \mintinline{haskellc}/mapTR'/ on the largest dataset.

In OCaml, the equivalent of \mintinline{haskellc}/mapDPS'/ is always more performant time-wise ($0.5-0.85\times$) than the equivalent of \mintinline{haskellc}/mapTR'/, even for small lists, as detailed in benchmarks of \cite{bour_tmc_2021}.

\section{Conclusion}

Programming with destinations definitely has a place in practical functional programming, as shown by the recent adoption of \emph{Tail Modulo Cons}~\cite{bour_tmc_2021} in the OCaml compiler. In this chapter, we have shown how we can take most ideas from \destcalculus{} (\cref{chap:dest-calculus}) and adapt them to allow safe destination passing in Haskell, without modifying the core principles of this existing language. We also showed that most of the examples presented in chapter \cref{chap:dest-calculus} can be implemented in DPS Haskell with little to no adaptations required, and we also emphasized how our particular implementation of destination passing for Haskell can help to improve the performance of programs in which garbage collection is very costly. To that extend, we rely on the \emph{compact regions}\cite{yang_efficient_2015} memory management scheme for Haskell; but our work also extend the way in which compact regions can be used efficiently.

Finally, we also demonstrated practical gains brought by destination-passing for some of the algorithms we presented all along this thesis; even though our DPS Haskell implementation is a bit heavyweight still and thus doesn't always let the destination-based algorithms match the theoretical performance expectations.

In this chapter, we could only use DPS Haskell for structures carrying unrestricted data. This was decided to keep a (relatively) simple API while avoiding the issues of scope escape (\cref{sec:scope-escape-dests}). In the next chapter, we'll revisit this limitation and find ways to modify DPS Haskell so that we can safely store linear resources in structures with holes.
