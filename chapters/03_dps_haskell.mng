\chapter{A first implementation of first-class destination passing in Haskell}\label{chap:dps-haskell}

In the previous chapter, we saw how we can build a $\lambda$-calculus from the ground up with first-class support for destination passing, and that still achieve memory safety. It's now time to put that into practice into an industrial-grade programming language.

\begin{quote}
  This chapter is adapted from article \cite{bagrel_destination-passing_2024}, published in Proceedings of JFLA 2024. Several sections have been reworked, since the theoretical work described in \cref{chap:dest-calculus} was still in very early stage when this article got published.

  Since the conceptual and theoretical aspects of destination passing have been covered already in the previous chapters, this one can focus more on implementation concerns and Haskell specificities than the article it is based on. Notations have also been made as consistent as possible with the ones in previous chapters.
\end{quote}

\section{Linear Haskell is our implementation target}\label{intro-dps-haskell}

Designing an industrial-grade programming language \emph{just} to add support for destinations would be a gigantic task, with much risk to fail. Instead, we'll base our work on an existing functional programming language. The Haskell programming language is equipped with support for linear types through its main compiler, \emph{GHC}, since version 9.0.1~\cite{bernardy_linear_2018}. There aren't many other industrial-grade functional programming languages, and most of them don't have support for linear types, which are the first piece required to make our system safe. OCaml, thanks to recent work from \citet{lorenzen_oxidizing_2024}, has support for \emph{affinity}, but not for linearity (despite the aforementioned work using the term ``linearity''): a resource can be restricted to at most one use, but there is no way to ensure it will be used exactly once; it could be dropped without being used at all.

As a result, Haskell appeared to be a promising target for a real-world implementation of \destcalculus{}, which is detailed in depth in \cref{chap:dest-calculus}. In addition, Haskell is also a \emph{pure} functional language, which is rather in line with the idea of hiding impure memory effects related to destinations behind a \emph{pure} API by preventing any read before a structure has been completed.

However, the main challenge is that Haskell, albeit incorporating linear types, doesn't have any concept of scope or age control. So we won't be able to avoid the fundamental issues presented in \cref{sec:scope-escape-dests} without imposing limitations on the flexibility of the system.

\section{Restricting \destcalculus{} so that it can be made safe with just linear types}\label{sec:restrict-dps-linhask}

As we've seen in \cref{sec:scope-escape-dests}, linear types are not enough, alone, to make \destcalculus{} safe. We definitely need ages. In this chapter, we will take a radical decision: we will make it so that destinations can only be used to build non-linear (a.k.a. unrestricted) data structures, so that the issue of scope escape disappear completely. In exchange, we won't be able to store destinations inside data structures built using ampars.

In practice, that means that a destination can only be filled with an unrestricted value (which forbids filling a destination with another destination, as destinations are linear resources). We will use the Haskell type \mintinline{haskellc}/data UDest t/ to represent those destinations for unrestricted values, and type \mintinline{haskellc}/data UAmpar s t/ to represent these ampars where the \mintinline{haskellc}/s/ side is unrestricted.

Because there is no difference when creating the spine of a data structures that is linear or unrestricted, our fill functions that adds a new hollow constructor to an existing structure will be exactly the same as in \destcalculus{}. Only the signature of fill operators acting on the leaves of data structures will change in the implementation compared to the formal definition.


The mapping of operators and types between \destcalculus{} and DPS Haskell is given in \cref{fig:mapping-destcalculus-dpshaskell}

In \destcalculus{}, destinations always have finite ages. As a result, we use age $[[∞]]$ as a marker that something doesn't contain destinations. That way, can still enforce scope control independently of linearity. This is particularly visible in rule \rref*{\CTyTerm\CSep\CFromA}, where a linear resource can be extracted from the right of an ampar as long as it has age $[[∞]]$.

In DPS Haskell however, we don't have ages. So we use the fact that destinations are always linear too, and we employ the $[[ω]]$ multiplicity as a marker that something doesn't contain destinations. Of course, that isn't cheap; by doing that we conflate the absence of destination with non-linearity. As we don't have a way in that world to control scopes, except in banning scope-sensitive resources altogether (a.k.a. destinations) by using the $[[ω]]$ multiplicity, we have to be overly conservative to preserve safety which restrain the possibilities of a few operators. % In DPS Haskell, mode $[[ɷ]]$ is equivalent to the pair $[[ω∞]]$ of \destcalculus{}, as there is no no construct in our language that can have unrestricted multiplicity with an intrinsically finite age, it makes sense to map the mode $[[ɷ]]$ of Linear Haskell. Consequently, $[[ˢᴇ ω∞ term]]$ corresponds to \mintinline{haskellc}/Ur term/.


\begin{figure}

\begin{tabular}{|l|lcl|}\hline
\destcalculus{} & DPS Haskell && \\\hline\hline
$[[d ⨞ ()]]$ & \mintinline{haskellc}/fill @'() d/ &or& \mintinline{haskellc}/d &fill @'()/ \\\hline
$[[d ⨞ Inl]]$ & \mintinline{haskellc}/fill @'Inl d/ &or& \mintinline{haskellc}/d &fill @'Inl/ \\\hline
$[[d ⨞ Inr]]$ & \mintinline{haskellc}/fill @'Inr d/ &or& \mintinline{haskellc}/d &fill @'Inr/ \\\hline
$[[d ⨞ (,)]]$ & \mintinline{haskellc}/fill @'(,) d/ &or& \mintinline{haskellc}/d &fill @'(,)/ \\\hline
$[[d ⨞ ᴇ ω∞]]$ & \mintinline{haskellc}/fill @'Ur d/ &or& \mintinline{haskellc}/d &fill @'Ur/ \\\hline
$[[d ⨞ ( λ x m ⟼ term )]]$ & \mintinline{haskellc}/fillLeaf (\x -> term) d/ &or& \mintinline{haskellc}/d &fillLeaf (\x -> term)/ \\\hline
$[[d ⨞· term]]$ & \mintinline{haskellc}/fillComp term d/ &or& \mintinline{haskellc}/d &fillComp term/ \\\hline
$[[d ◀ term]]$ & \mintinline{haskellc}/fillLeaf term d/ &or& \mintinline{haskellc}/d &fillLeaf term/ \\\hline

\end{tabular}

(one can see \mintinline{haskellc}/&fill @'/ as the equivalent of $[[⨞]]$ in \destcalculus{}, \mintinline{haskellc}/&fillLeaf/ as $[[◀]]$, and \mintinline{haskellc}/&fillComp/ as $\mathop{\triangleleft\mycirc}$)

\begin{tabular}{|l|l|}\hline
\destcalculus{} & DPS Haskell \\\hline\hline
$[[⌊ T ⌋ ω∞]]$ & \mintinline{haskellc}/UDest t/ \\\hline
$[[! ω∞ S ⧔ T]]$ & \mintinline{haskellc}/UAmpar s t/ \\\hline
\end{tabular}

\caption{Mappings between \destcalculus{} and DPS Haskell}\label{fig:mapping-destcalculus-dpshaskell}
\end{figure}

Now, let's see how programs look like in DPS Haskell. We'll start by reimplementing examples from the previous chapter, to see how they take form in a practical setting.

\section{A glimpse of DPS Haskell programming}\label{sec:motivating-examples}

The following subsections present three typical settings in which DPS programming brings expressiveness or performance benefits over a more traditional functional implementation. We'll start by revisiting examples from \label{sec:working-with-dests}.

\subsection{Efficient difference lists, and proper memory model}\label{ssec:dpshaskell-dlist}

Linked lists are a staple of functional programming, but they aren't efficient for concatenation, as we've seen in \cref{ssec:efficient-queue}, especially when the concatenation calls are nested to the left.

In an imperative context, it would be quite easy to concatenate linked lists efficiently. One just has to keep both a pointer to the root and to the last \emph{cons} cell of each list. Then, to concatenate two lists, one just has to mutate the last \emph{cons} cell of the first one to point to the root of the second list.

In a functional setting, \emph{difference lists} are the closest equivalent, offering constant-time concatenation, and constant-time conversion to a normal linked list. Usually, as we've seen previously, functional difference lists are encoded as functions, but thanks to destination-passing style, we can represent them as an actual list with a hole at the end.

This example will be the opportunity to show how DPS Haskell operates on memory. So far, with \destcalculus{}, we worked on a theoretical memory model with global substitutions and no explicit (de)allocations. Here, with DPS Haskell, we assume that we have a proper heap. We pay no attention right now to garbage collection; as it is a bit tricky; instead we will deal with this topic in \cref{ssec:impl-compact-regions}.

Following the mapping tables of \cref{sec:restrict-dps-linhask}, we know the DPS Haskell representation of difference lists is \mintinline{haskellc}/type DList t = UAmpar [t] (UDest [t])/. As announced previously, because our difference lists are built using UAmpars, they cannot host linear resources. That's the major limitation of this first approach of DPS for Haskell.

As with \destcalculus{}, the left side of the UAmpar carries the structures being built, while the right side carries the destinations of the structure: the \mintinline{haskellc}/UDest [t]/ must be filled (with an unrestricted \mintinline{haskellc}/[t]/) to get a readable \mintinline{haskellc}/[t]/.

The implementation of destination-backed difference lists is presented in Listing~\ref{table:impl-dlist}.
% Doesn't bring much more compared to fig:schema-dlist-concat
% \begin{figure}[t]\centering
%   \includegraphics[width=10cm]{fillComp.png}
%   \caption{Memory behavior of \mintinline{haskellc}/fillComp ⩴ UAmpar s t ⊸ UDest s ⊸ t/}
%   \label{fig:schema-fillComp}
% \end{figure}

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos]{haskellc}
-- we recall here the definition of list type in Haskell
data [t] = []          -- nil constructor
           | (:) t [t]  -- cons constructor

type DList t = UAmpar [t] (UDest [t])

newDList ⩴ Token ⊸ DList t
newDList = newUAmpar @[t]

append ⩴ DList t ⊸ t → DList t
dlist `append` x =
  dlist `updWith` \d → case (d &fill @'(:)) of
    (dh, dt) → (dh &fillLeaf x) ; dt

concat ⩴ DList t ⊸ DList t ⊸ DList t
dlist1 `concat` dlist2 = dlist1 `updWith` \dt1 → (dt1 &fillComp dlist2)

toList ⩴ DList t ⊸ Ur [t]
toList dlist = fromUAmpar' (dlist `updWith` \dt → dt &fill @'[])
\end{minted}
\caption{Implementation of difference lists in DPS Haskell}
\label{table:impl-dlist}
\end{listing}

% TODO: update syntax
\begin{figure}[t]\centering
  \hspace{-0.5cm}\begin{minipage}{0.3\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/alloc}}
    \caption{\mintinline{haskellc}/newUAmpar tok/}
    \label{fig:schema-alloc}
  \end{minipage}\hspace{0cm}%
  \begin{minipage}{0.7\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/dlist-toList}}
    \caption{Memory behavior of \mintinline{haskellc}/toList dlist/}
    \label{fig:schema-dlist-toList}
  \end{minipage}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-append}}
  \caption{Memory behavior of \mintinline{haskellc}/append newUAmpar 1/}
  \label{fig:schema-dlist-append}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-concat}}
  \caption{Memory behavior of \mintinline{haskellc}/concat dlist1 dlist2/ (based on \mintinline{haskellc}/fillComp/)}
  \label{fig:schema-dlist-concat}
\end{figure}

% \begin{figure}[p]\centering

% \end{figure}

\begin{itemize}
  \item \mintinline{haskellc}/newDList/ is just an alias for a call to \mintinline{haskellc}/newUAmpar/ to linearly exchange a token for a new \mintinline{haskellc}/UAmpar [t] (UDest [t])/ ---that is, exactly \mintinline{haskellc}/DList t/. There is no data
    in this UAmpar yet, it's just a hole and a destination pointing to it, as we see on \cref{fig:schema-alloc};


  \item \mintinline{haskellc}/append/ (Figure~\ref{fig:schema-dlist-append}) adds an element at the tail
    position of a difference list. For this, it first uses
    \mintinline{haskellc}/fill @'(:)/ to fill the hole at the end of the list represented by
    \mintinline{haskellc}/d ⩴ UDest [t]/ with a hollow \mintinline{haskellc}/(:)/ constructor that has two new holes, pointed to by \mintinline{haskellc}/dh ⩴ UDest t/ and \mintinline{haskellc}/dt ⩴ UDest [t]/. Then,
    \mintinline{haskellc}/fillLeaf/ fills the hole represented by
    \mintinline{haskellc}/dh/ with the value
    of type \mintinline{haskellc}/t/
    to append. The hole at the end of the resulting difference list is the one pointed by \mintinline{haskellc}/dt ⩴ UDest [t]/ which hasn't been filled yet, and stays on the right side of the resulting UAmpar.

  \item \mintinline{haskellc}/concat/ (Figure~\ref{fig:schema-dlist-concat}) concatenates two difference lists,
    \mintinline{haskellc}/dlist1/ and \mintinline{haskellc}/dlist2/. It uses \mintinline{haskellc}/fillComp/ to fill the destination \mintinline{haskellc}/dt1/
    of the first difference list with the
    root of the second difference list \mintinline{haskellc}/dlist2/. The resulting \mintinline{haskellc}/UAmpar/
    object hence has the same root as the first list, holds the
    elements of both lists, and inherits the hole of the second list. Memory-wise,
    \mintinline{haskellc}/concat/ just writes the address of the second list into the hole of the first one.

  \item \mintinline{haskellc}/toList/ (Figure~\ref{fig:schema-dlist-toList}) completes the UAmpar structure by plugging a new \emph{nil} \mintinline{haskellc}/[]/ constructor into its hole with \mintinline{haskellc}/fill @'[]/, and then removes the \mintinline{haskellc}/UAmpar/ wrapper as the structure is now complete, using \mintinline{haskellc}/fromUAmpar'/. The completed list is wrapped in \mintinline{haskellc}/Ur/, as it is allowed to be used non-linearly ---it's always the case with UAmpars--- and so that it can also escape the \mintinline{haskellc}/withToken/ linear scope if needed.
\end{itemize}

Of course, we can only do in-place memory mutations, as described in \cref{fig:schema-alloc,fig:schema-dlist-append,fig:schema-dlist-concat,fig:schema-dlist-toList} if the values of type \mintinline{haskellc}/UAmpar/ are used linearly, as first explained in \cref{sec:implem-destcalculus}.

Otherwise, we could first complete a difference list with \mintinline{haskellc}/l = toList dlist/, then add a new cons cell to \mintinline{haskellc}/dlist/ with \mintinline{haskellc}/append dlist x/ (actually reusing the destination inside \mintinline{haskellc}/dlist/ for the second time). Doing that creates a hole inside \mintinline{haskellc}/l/, although it is of type \mintinline{haskellc}/[t]/ so we would be able to pattern-match on it, and might get a segfault! That's why \mintinline{haskellc}/newUAmpar/ consumes a linear token to produce a new UAmpar: it actually infects the UAmpar with linearity, providing that tokens are managed linearly.

With the implementation of difference list described above, we can expect it to be more efficient than the functional encoding (where a difference list \mintinline{haskellc}/x :/\,$\holesq$ is represented by the function \mintinline{haskellc}/\ys -> x : ys/). We'll see in Section~\ref{sec:benchmark} that the prototype implementation of DPS Haskell primitives (covered in Section~\ref{sec:implementation}) cannot yet demonstrate these performance improvements.

\subsection{Breadth-first tree traversal}\label{ssec:bf-tree-traversal}

Let's move on now to breadth-first tree traversal. We want to traverse a binary tree and update its nodes values so that they are numbered in a breadth-first order.

In \cref{sec:bft}, we took full advantage of \destcalculus{}'s flexibility, and implemented the breadth-first traversal using a queue to drive the processing order, as we would do in an imperative programming language. This queue would contain both input subtrees and destination to output subtrees, in breadth-first order.

Unlike the example of the previous subsection, we cannot just port the algorithm from \destcalculus{} into DPS Haskell. The major issue is that in \cref{ssec:efficient-queue}, we built an efficient queue, inspired from Hood-Melville ones, but with an ampar-based difference list for the list representing newly enqueued elements (so that we don't have to reverse it before consuming it when the front list is depleted). But in DPS Haskell, destinations cannot be filled with linear elements. So an ampar-based difference list wouldn't be able to store the destinations we need to store (the one representing the output subtrees), neither would an ampar-based efficient queue.

Fortunately, we can still use the regular, non-ampar-based data structures of Haskell to build a suitable Hood-Melville queue. That's at least one thing we get from using a language that isn't fully based on destinations to build data structures.\footnote{Destination-based data structure building is more general than constructor-based structure building as long as we can fill destinations with linear resources, as in \destcalculus{}. When we add the restriction that destination can only be filled with unrestricted elements, as we do in DPS Haskell, then it is no longer more general than constructor-based structure building, and we need to conserve both building ways in the language to stay at the same level of expressiveness.}

As before, we'll keep a queue of pairs of a tree to be relabeled and of the destination where the relabeled result is expected, and process each of them when their turn comes. Nothing other than choice of implementation for the queue will change. The DPS Haskell implementation of breadth-first tree traversal is provided in Listing~\ref{table:impl-bfs-tree-traversal}.

% TODO: add implem of hood melville queue, and revisit code snippet

\begin{listing}[p]
\figtextsize
\begin{minted}[linenos]{haskellc}
data HMQueue t = ¤HMQueue [t] [t]

newHMQueue :: HMQueue t
newHMQueue = ¤HMQueue [] []

singleton :: t ⊸ HMQueue t
singleton x = ¤HMQueue [x] []

toList :: HMQueue t ⊸ [t]
toList (¤HMQueue front backRev) = front ++ reverse backRev

enqueue :: HMQueue t ⊸ t ⊸ HMQueue t
enqueue (¤HMQueue front backRev) x = ¤HMQueue front (x : backRev)

dequeue :: HMQueue t ⊸ Maybe (t, HMQueue t)
dequeue (¤HMQueue front backRev) = case front of
  [] -> case reverse backRev of
    [] -> Nothing
    (x : front') -> Just (x, ¤HMQueue front' [])
  (x : front') -> Just (x, ¤HMQueue front' backRev)

-------------------------------------------------------------------------------

data Tree t = ¤Nil | ¤Node t (Tree t) (Tree t)

relabelDPS ⩴ Token ⊸ Tree t → Tree Int
relabelDPS tree = fst (mapAccumBFS (\st _ → (st + 1, st)) 1 tree)

mapAccumBFS ⩴ ∀ s t u. Token ⊸ (s → t → (s, u)) → s → Tree t → (Tree u, s)
mapAccumBFS tok f s0 tree =
  unFromUAmpar (
    newUAmpar @(Tree u) tok `updWith` \dtree → go s0 (singleton (¤Ur tree, dtree)))
  where
    go ⩴ s → Queue (Ur (Tree t), UDest (Tree u)) ⊸ Ur s
    go st q = case dequeue q of
      ¤Nothing → ¤Ur st
      ¤Just ((utree, dtree), q') → case utree of
        ¤Ur ¤Nil → dtree &fill @'Nil ; go st q'
        ¤Ur (¤Node x tl tr) → case (dtree &fill @'Node) of
          (dy, dtl, dtr) →
            let q'' = q' `enqueue` (¤Ur tl, dtl) `enqueue` (¤Ur tr, dtr)
                (st', y) = f st x
              in dy &fillLeaf y ; go st' q''
\end{minted}
\caption{Implementation of breadth-first tree traversal in DPS Haskell}
\label{table:impl-bfs-tree-traversal}
\end{listing}

Except from the choice of queue implementation, and the fact that ampars must be created from \mintinline{haskellc}/Token/s, this implementation is very much the same as in \cref{sec:bft}. In the signature of \mintinline{haskellc}/go/ function, the linear arrow enforces the fact that every destination ever put in the queue is eventually consumed at some point, which guarantees that the output tree is complete after the function has run.

We will see in \ref{sec:benchmark} that this imperative-like implementation of breadth-first traversal in DPS Haskell, albeit not using difference-list-based efficient queues, still presents great performance gains compared to the fancy functional implementation from~\cite{gibbons_phases_2023}.

\section{DPS Haskell API and Design concerns}\label{sec:api}

Table~\ref{table:destination-api} presents the pure API of DPS Haskell. This API is sufficient to implement all the examples of Section~\ref{sec:motivating-examples}. This section explains its various parts in detail and how it compares to \cref{chap:dest-calculus}.

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos]{haskellc}
data Token
dup ⩴ Token ⊸ (Token, Token)
drop ⩴ Token ⊸ ()
withToken ⩴ ∀ t. (Token ⊸ Ur t) ⊸ Ur t

data UAmpar s t
newUAmpar ⩴ ∀ s. Token ⊸ UAmpar s (UDest s)
newUAmparBesides ⩴ ∀ s t u. UAmpar s t ⊸ (UAmpar s t, UAmpar u (UDest u))
toUAmpar ⩴ ∀ s. Token ⊸ s → UAmpar s ()
fromUAmpar ⩴ ∀ s t. UAmpar s (Ur t) ⊸ Ur (s, t)
fromUAmpar' ⩴ ∀ s. UAmpar s () ⊸ Ur s
updWith ⩴ ∀ s t u. UAmpar s t ⊸ (t ⊸ u) ⊸ UAmpar s u

data UDest t
type family UDestsOf lCtor t  -- returns dests associated to fields of constructor
fill ⩴ ∀ lCtor t. UDest t ⊸ UDestsOf lCtor t
fillComp ⩴ ∀ s t. UAmpar s t ⊸ UDest s ⊸ t
fillLeaf ⩴ ∀ t. t → UDest t ⊸ ()
\end{minted}
\caption{Destination API for Haskell}
\label{table:destination-api}
\end{listing}

\subsection{The \texttt{UAmpar} type}

As with Ampars from the previous chapter, UAmpar data structures can be freely passed around and stored, but need to be completed before any reading i.e. pattern-matching can be made on them. As a result, \mintinline{haskellc}/UAmpar s t/ is defined as an opaque data type, with no public constructor.

In \mintinline{haskellc}/UAmpar s t/, \mintinline{haskellc}/s/ stands for the type of the structure being built, and \mintinline{haskellc}/t/ is the type of what needs to be linearly consumed before the structure can be read. Eventually, when complete, the structure will be wrapped in \mintinline{haskellc}/Ur/; this illustrates the fact that it has been made only from unrestricted elements.

The \mintinline{haskellc}/newUAmpar/ operator is the main way for a user of the API to create a new UAmpar. Its signature is identical to $[[allocIP]]$ from \cref{sec:implem-destcalculus}.

There is also a new alternative way to create a fresh UAmpar: \mintinline{haskellc}/newUAmparBesides/. Sometimes, when programming in DPS style, we won't have a \mintinline{haskellc}/Token/ at hand, but only an existing \mintinline{haskellc}/UAmpar/. In that case, we can piggyback on the linearity of that existing UAmpar (as it linearly depends, directly or indirectly, on a token) to enforce linearity discipline on the new UAmpar, which is the second element of the pair returned by \mintinline{haskellc}/newUAmparBesides/.

The operator \mintinline{haskellc}/newUAmparBesides/ is particularly useful when implementing efficient queues in DPS Haskell (as in \cref{ssec:efficient-queue}):

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
type DList t = UAmpar [t] (UDest [t])
type EffQueue t = ([t], DList t)

newEffQueue ⩴ Token ⊸ EffQueue t
newEffQueue tok = ([], newUAmpar @[t] tok)

dequeue ⩴ EffQueue t ⊸ Maybe (t, EffQueue t)
dequeue q = case q of
  ((x : xs), dlist) -> Just (x, (xs, dlist))
  ([], dlist) -> case (toList dlist) of
    Ur [] -> Nothing
    Ur (x : xs) -> Just (xs, °\mold{newUAmpar @[t] tok}°)
\end{minted}
}
\end{unbreakable}

In the second branch of the inner-most \mintinline{haskellc}/case/ in \mintinline{haskellc}/dequeue/, when we have transformed the back difference list (from which we used to write) into the new front list (from which we will now read), we have to create a new back difference list, that is, a new ampar. However, we don't have a token at hand. It would be quite unpractical for a function like \mintinline{haskellc}/dequeue/ to ask for a linear token to be passed; it's better if tokens are only requested when spawning a new data structure, not when operating on one. That's why \mintinline{haskellc}/newUAmparBesides/ comes handy: we can instead reuse the linearity requirement of the existing UAmpar:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
newUAmparBesides ⩴ ∀ s t u. UAmpar s t ⊸ (UAmpar s t, UAmpar u (UDest u))

dequeue ⩴ EffQueue t ⊸ Maybe (t, EffQueue t)
dequeue q = case q of
  ((x : xs), dlist) -> Just (x, (xs, dlist))
  ([], dlist) -> case newUAmparBesides dlist of (dlist, dlist') -> case (toList dlist) of
    Ur [] -> case (toList dlist') of Ur _ -> Nothing
    Ur (x : xs) -> Just (xs, dlist')
\end{minted}
}
\end{unbreakable}

This new version is not perfect either though. We have to create the new UAmpar before even knowing if we will need it. Indeed, we can only know if a new UAmpar is really needed when we have read the content of the old one, and we can only read it when it is no longer a UAmpar... so at that point we cannot spawn a new one any longer. So the way forward is to always spawn a new UAmpar (difference list in that case) before consuming the old one, taking the risk that if the queue is really empty, we will have to discard the fresh UAmpar immediately (with \mintinline{haskellc}/case (toList dlist') of Ur _ -> Nothing/ instead of just returning \mintinline{haskellc}/Nothing/). Implicit token passing, as proposed by Linear Constraints\cite{spiwack_linearly_2022,spiwack_linear_prop_2023}, seems to really be the way forward to get rid of this kind of issues altogether.

%------------------------------

Same as in \destcalculus{}, the structure encapsulated within a UAmpar can be released in two ways: with \mintinline{haskellc}/fromUAmpar'/, the value on the \mintinline{haskellc}/t/ side must be unit (\mintinline{haskellc}/()/), and just the complete \mintinline{haskellc}/s/ is returned, wrapped in \mintinline{haskellc}/Ur/. With \mintinline{haskellc}/fromUAmpar/, the type on the \mintinline{haskellc}/t/ side must be of the form \mintinline{haskellc}/Ur t'/, and then a pair \mintinline{haskellc}/Ur (s, t')/ is returned.

It is actually safe to wrap the structure that has been built in \mintinline{haskellc}/Ur/ because, as we've said previously, its leaves either come from non-linear sources (as \mintinline{haskellc}/fillLeaf ⩴ t → UDest t ⊸ ()/ consumes its first argument non-linearly) or are made of 0-ary constructors added with \mintinline{haskellc}/fill/, both of which can be used in an unrestricted fashion safely; and its spine, made of hollow constructors, can be duplicated at will.

% \mintinline{haskellc}/UAmpar s t/ has a linear functor instance to map on the \mintinline{haskellc}/t/ side (the one carrying destinations) which forces the continuation to be linear:

% {\figtextsize
% \begin{minted}[escapeinside=°°]{haskellc}
% instance Functor (UAmpar a) where
%   fmap ⩴ ∀ b c. (b ⊸ c) ⊸ UAmpar a b ⊸ UAmpar b c
%   fmap f (¤UAmpar (x, d)) = ¤UAmpar (x, f d)
% \end{minted}
% }

% And \mintinline{haskellc}/newUAmpar ⩴ ∀ s. Token ⊸ UAmpar s (UDest s)/` is the only function in which a \mintinline{haskellc}/UDest/ appears in positive position, but locked by an \mintinline{haskellc}/UAmpar/ (which is an opaque wrapper for the user). So destinations can only ever be accessed by mapping over an \mintinline{haskellc}/UAmpar/ with \mintinline{haskellc}/fmap//\mintinline{haskellc}/`updWith`/, and cannot leak to the outside. It isn't possible either for a \mintinline{haskellc}/UDest t/ to be linearly consumed by filling another \mintinline{haskellc}/UDest (UDest t)/ with \mintinline{haskellc}/fillLeaf/, as the first argument of the \mintinline{haskellc}/fillLeaf/ function isn't used linearly.\footnote{It would actually be desirable to have \mintinline{haskellc}/UDest (UDest t)/ work. But it turns out that doing so naively compromises the type safety properties related to linearity that we describe in this section. How to recover type safety in presence of destinations of destinations is still an open problem.}

% Morally, this linear \mintinline{haskellc}/Functor/ instance says that one can temporary forget about the root of the structure being built, and just manipulate the destinations as first-class objects that will produce remote building effects onto the structure that is invisible in the inner scope.

\subsection{Filling functions for destinations}

The last part of the API is the one in charge of actually building the structures in a top-down fashion. To fill a hole represented by \mintinline{haskellc}/UDest t/, three functions are available:

\mintinline{haskellc}/fillLeaf ⩴ ∀ t. t → UDest t ⊸ ()/ uses a value of type \mintinline{haskellc}/t/ to fill the hole represented by the destination, as $[[◀]]$ from \destcalculus{}. However, if the destination is consumed linearly as in \destcalculus{}, the value to fill the hole isn't (as indicated by the first non-linear arrow). This is key to the fact that UAmpar only host unrestricted data. Memory-wise, when \mintinline{haskellc}/fillLeaf/ is used, the address of the object of type \mintinline{haskellc}/t/ is written into the memory cell pointed to by the destination of type \mintinline{haskellc}/UDest t/ (see Figure~\ref{fig:schema-fillLeaf}).

\mintinline{haskellc}/fillComp ⩴ ∀ s t. UAmpar s t ⊸ UDest s ⊸ t/ is used to plug two \mintinline{haskellc}/UAmpar/ objects together. The larger \mintinline{haskellc}/UAmpar/ isn't represented in the signature of the function, as with the similar operator $\mathop{\triangleleft\mycirc}$ from \destcalculus{}. Instead, only the hole of the bigger UAmpar that will receive the address of the smaller UAmpar is represented by \mintinline{haskellc}/UDest s/; and \mintinline{haskellc}/UAmpar s t/ in the signature refers to the smaller UAmpar. A call to \mintinline{haskellc}/fillComp/ always takes place in the scope of \mintinline{haskellc}/`updWith`/ over the parent object:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parent ⩴ UAmpar BigStruct (UDest SmallStruct, UDest OtherStruct)
child ⩴ UAmpar SmallStruct (UDest Int)
comp = parent `updWith` \(ds, extra) → fillComp child ds
       ⩴ UAmpar BigStruct (UDest Int, UDest OtherStruct)
\end{minted}
}
\end{unbreakable}

The resulting structure \mintinline{haskellc}/comp/ is morally a \mintinline{haskellc}/BigStruct/ like \mintinline{haskellc}/parent/, that inherited the hole from the child structure (\mintinline{haskellc}/UDest Int/) and still has its other hole (\mintinline{haskellc}/UDest OtherStruct/) remaining to be filled. An example of memory behavior of \mintinline{haskellc}/fillComp/ in action can be seen in Figure~\ref{fig:schema-dlist-concat}.

Finally, \mintinline{haskellc}/fill ⩴ ∀ lCtor t. UDest t ⊸ UDestsOf lCtor t/ is the generic function to fill a destination with hollow constructors. It takes a constructor as a type parameter (\mintinline{haskellc}/lCtor/) and allocates a hollow heap object that has the same header/tag as the specified constructor but unspecified fields. The address of the allocated hollow constructor is written in the destination that is passed to \mintinline{haskellc}/fill/. An example of the memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/ is given in Figure~\ref{fig:schema-fillCons} and the one of \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/ is given in Figure~\ref{fig:schema-fillNil}.

The \mintinline{haskellc}/fill/ function also returns one destination of matching type for each of the fields of the constructor; in Haskell this is represented by \mintinline{haskellc}/UDestsOf lCtor t/. \mintinline{haskellc}/UDestsOf/ is a type family (i.e. a function operating on types) whose role is to map a constructor to the type of destinations for its fields. For example, \mintinline{haskellc}/UDestsOf '[] [t] = ()/ and \mintinline{haskellc}/UDestsOf '(:) [t] = (UDest t, UDest [t])/. More generally, the \mintinline{haskellc}/UDestsOf/ typeclass reflects the duality between the types of fields of a constructor and the ones of destinations for a hollow constructor, as first evoked in \cref{ssec:build-up-vocab}.

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/fillCons}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/}
  \label{fig:schema-fillCons}

  \scalebox{\figscale}{\tikzfig{schemas/fillNil}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/}
  \label{fig:schema-fillNil}

  \scalebox{\figscale}{\tikzfig{schemas/fillLeaf}}
  \caption{Memory behavior of \mintinline{haskellc}/fillLeaf ⩴ t → UDest [t] ⊸ ()/}
  \label{fig:schema-fillLeaf}
\end{figure}

\section{Compact Regions: a playground to Implement the DPS Haskell API}\label{sec:implementation}

Having incomplete structures in the memory inherently introduces a lot of tension with both the garbage collector and compiler. Indeed, the garbage collector of GHC assumes that every heap object it traverses is well-formed, whereas UAmpar structures are absolutely ill-formed: they contain uninitialized pointers, which the GC should absolutely not follow. Also, the compiler and GC can make some optimizations because they assume that every object is immutable, while DPS programming breaks that guarantee by mutating constructors after they have been allocated (albeit only one update can happen). As a result, we looked for a memory management alternative for Haskell that would let us implement DPS Haskell API more easily.

\subsection{Compact Regions}\label{ssec:impl-compact-regions}

\emph{Compact regions} from~\citet{yang_efficient_2015} make it very convenient to implement DPS programming in Haskell. A compact region represents a memory area in the Haskell heap that is almost fully independent from the GC and the rest of the garbage-collected heap. For the GC, each compact region is seen as a single heap object with a single lifetime. The GC can efficiently check whether there is at least one pointer in the garbage-collected heap that points into the region, and while this is the case, the region is kept alive. When this condition is no longer matched, the whole region is discarded. The result is that the GC won't traverse any node from the region: it is treated as one opaque block (even though it is actually implemented as a chain of blocks of the same size, that doesn't change the principle). Also, compact regions are immobile in memory; the GC won't move them, so a destination to a hole in the compact region can just be implemented as a raw pointer (type \mintinline{haskellc}/Addr#/ in Haskell): \mintinline{haskellc}/data UDest r t = ¤UDest Addr#/, as we have the guarantee that the pointed UAmpar (which contains the hole) won't move.

By using compact regions to implement DPS programming, we completely elude the concerns of tension between the garbage collector and UAmpar structures we want to build. Instead, we get two extra restrictions. First, every structure in a region must be in a fully-evaluated form. This is contrasting with usual Haskell evaluation scheme, where everything is lazy by default. Consequently, as regions are strict, any heap object that is copied to a region is first forced into normal form (i.e. it is being fully evaluated). This might not always be a win, sometimes laziness is preferable for better performance.

Secondly, data in a region cannot contain pointers to the garbage-collected heap, or pointers to other regions: it must be self-contained. That forces us to slightly modify the API, to add a phantom type parameter \mintinline{haskellc}/r/ which tags each object with the identifier of the region it belongs to so that our API remains memory-safe, without runtime checks. There are two related consequences: first, when a value from the garbage-collected heap is used as an argument to \mintinline{haskellc}/fillLeaf/, it has to be fully evaluated and copied into the region instead of making just a pointer update; and secondly, \mintinline{haskellc}/fillComp/ can only plug together two \mintinline{haskellc}/UAmpar/s that come from the same region.

A typeclass \mintinline{haskellc}/Region r/ is also needed to carry around the details about a region that are required for the implementation. This typeclass has a single method \mintinline{haskellc}/reflect/, not available to the user, that returns the \mintinline{haskellc}/RegionInfo/ structure associated to identifier \mintinline{haskellc}/r/.

The \mintinline{haskellc}/inRegion/ function is the new addition to the modified API presented in Listing~\ref{table:destination-api-regions}. It receives an expression of arbitrary type in which \mintinline{haskellc}/r/ must be a free type variable. It then spawns a new compact region and a fresh type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ (not a variable), and uses the \mintinline{text}/reflection/ library to provide an instance of \mintinline[escapeinside=°°]{haskellc}/Region °\muline{r}°/ on-the-fly that links \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ and the \mintinline{haskellc}/RegionInfo/ for the new region, and then make type application for the supplied expression at the concrete type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/. %This is fairly standard practice since~\cite{launchbury_lazy_1994}.

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
data Token
dup ⩴ Token ⊸ (Token, Token)
drop ⩴ Token ⊸ ()
withToken ⩴ ∀ t. (Token ⊸ Ur t) ⊸ Ur t

type Region r ⩴ Constraint
°\mnew{inRegion ⩴ ∀ t. (∀ r. Region r ⇒ t) ⊸ t}°

data UAmpar r s t
newUAmpar ⩴ ∀ r s. Region r ⇒ Token ⊸ UAmpar s (UDest s)
newUAmparBesides ⩴ ∀ r1 r2 s t u. (Region r1, Region r2) ⇒ UAmpar r1 s t ⊸ (UAmpar r1 s t, UAmpar r2 u (UDest u))
toUAmpar ⩴ ∀ r s. Region r ⇒ Token ⊸ s → UAmpar r s ()
fromUAmpar  ⩴ ∀ r s t. Region r ⇒ UAmpar r s (Ur t) ⊸ Ur (s, t)
fromUAmpar' ⩴ ∀ r s. Region r ⇒ UAmpar r s () ⊸ Ur s
updWith ⩴ ∀ r s t u. Region r ⇒ UAmpar r s t ⊸ (t ⊸ u) ⊸ UAmpar r s u

data UDest r t
type family UDestsOf lCtor r t  -- returns dests associated to fields of constructor
fill ⩴ ∀ lCtor r t. Region r ⇒ UDest r t ⊸ UDestsOf lCtor r t
fillComp ⩴ ∀ r s t. Region r ⇒ UAmpar r s t ⊸ UDest r s ⊸ t
fillLeaf ⩴ ∀ r t. Region r ⇒ t → UDest r t ⊸ ()
\end{minted}
\caption{Destination API using compact regions}
\label{table:destination-api-regions}
\end{listing}

\begin{figure}
\scalebox{\figscale}{\tikzfig{schemas/alloc-region}}
\caption{Memory behaviour of \mintinline{haskellc}/newUAmpar/ and \mintinline{haskellc}/toUAmpar/ in the region implementation}\label{fig:schema-alloc-region}
\end{figure}

\subsection{DPS programming in Compact regions: Deserializing, lifetime, and garbage collection}\label{ssec:parser-sexpr}

We will now tackle a new example of DPS programming which is more tied to implementation concerns and compact regions themselves than the previous ones.

In client-server applications, the following pattern is very frequent: the server receives a request from a client with a serialized payload, the server then deserializes the payload, runs some code, and respond to the request. Most often, the deserialized payload is kept alive for the entirety of the request handling. In a garbage collected language, there's a real cost to this: the garbage collector (GC) will traverse the deserialized payload again and again, although we know that all its internal pointers are live for the duration of the request.

Instead, we'd rather consider the deserialized payload as a single heap object, which doesn't need to be traversed, and is freed as a block. Compact regions are, in fact, the perfect tool for this job, as the GC never follows pointers into a compact region and consider each region as a having the same lifetime for all its contents.

If we use compact regions as-is, with the API provided with GHC, we would first deserialize the payload normally, in the GC heap, then copy it into a compact region and then only keep a reference to the copy. That way, internal pointers of the region copy will never be followed by the GC, and that copy will be collected as a whole later on, whereas the original in the GC heap will be collected immediately.

However, we are still allocating two copies of the deserialized payload. This is wasteful, it would be much better to allocate directly in the region. Fortunately, with our implementation of DPS Haskell throughout compact regions, we now have a much better way to allocate and build structures directly into them!

Let's see how using destinations and compact regions for a parser of S-expressions (representing our request payload) can lead to greater performance. S-expressions are parenthesized lists whose elements are separated by spaces. These elements can be of several types: int, string, symbol (a textual token with no quotes around it), or a list of other S-expressions.

Parsing an S-expression can be done naively with mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskellc}/parseSExpr/ scans the next character, and either dispatches to \mintinline{haskellc}/parseSList/ if it encounters an opening parenthesis, or to \mintinline{haskellc}/parseSString/ if it encounters an opening quote, or eventually parses the string into a number or symbol;
  \item \mintinline{haskellc}/parseSList/ calls \mintinline{haskellc}/parseSExpr/ to parse the next token, and then calls itself again until reaching a closing parenthesis, accumulating the parsed elements along the way.
\end{itemize}

Only the implementation of \mintinline{haskellc}/parseSList/ will be presented here as it is enough for our purpose, but the full implementation of both the naive and destination-based versions of the whole parser can be found in \texttt{src/Compact/Pure/SExpr.hs} of~\cite{linear_dest}.

The implementation presented in Listing~\ref{table:impl-parser-naive} is quite standard: the accumulator \mintinline{haskellc}/acc/ collects the nodes that are returned by \mintinline{haskellc}/parseSExpr/ in the reverse order (because it's the natural building order for a linked list without destinations). When the end of the list is reached (line 5), the accumulator is reversed, wrapped in the \mintinline{haskellc}/¤SList/ constructor, and returned.

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExpr ⩴ ByteString → Int → Either Error SExpr
% parseSExpr bs i = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSList bs (i + 1) []
%     '"' → parseSString bs (i + 1) ¤False []
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%          in if null tok then parseSExpr bs (i + 1) else case parseInt tok of
%               ¤Just int → ¤Right (¤SInteger (i + length tok - 1) int)
%               ¤Nothing → ¤Right (¤SSymbol (i + length tok - 1) (toString tok))
% parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
% parseSList bs i acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → ¤Right (¤SList i (reverse acc))
%     | isSpace x → parseSList bs (i + 1) acc
%     | otherwise → case parseSExpr bs i of
%         ¤Left err → ¤Left err
%         ¤Right child → parseSList bs (endPos child + 1) (child : acc)
% parseSString ⩴ ByteString → Int → Bool → [Char] → Either Error SExpr
% parseSString bs i escape acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → ¤Right (SString i (reverse acc))
%     '\\' | not escape → parseSString bs (i + 1) ¤True acc
%     'n'  | escape → parseSString bs (i + 1) ¤False ('\n' : acc)
%     _ → parseSString bs (i + 1) ¤False (x : acc)
% \end{minted}
% \caption{Implementation of the S-expression parser without destinations}
% \label{table:impl-sexpr-parser-without-dest}
% \end{listing}

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExprDPS ⩴ ByteString → Int → UDest SExpr ⊸ Either Error Int
% parseSExprDPS bs i d = case bs !? i of
%   ¤Nothing → °\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → °\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSListDPS bs (i + 1) °\mnew{(fill @'SList d)}°
%     '"' → parseSStringDPS bs (i + 1) ¤False °\mnew{(fill @'SString d)}°
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%         in if null tok then parseSExprDPS bs (i + 1) d else case parseInt tok of
%               ¤Just int → let °\mnew{!dint = fill @'SInteger d}°
%                           in °\mnew{fillLeaf int dint}° ; ¤Right (i + length tok - 1)
%               _ → let °\mnew{!dsym = fill @'SSymbol d}°
%                    in °\mnew{fillLeaf (toString tok) dsym}° ; ¤Right (i + length tok - 1)
% parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
% parseSListDPS bs i d = case bs !? i of
%   ¤Nothing → °\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → °\mnew{fill @'[] d}° ; ¤Right i
%     | isSpace x → parseSListDPS bs (i + 1) d
%     | otherwise → let !(dh, dt) = °\mnew{fill @'(:) d}°
%                    in case parseSExprDPS bs i °\mnew{dh}° of
%                         ¤Left err → fill @'[] dt ; ¤Left err
%                         ¤Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°
% parseSStringDPS ⩴ ByteString → Int → Bool → UDest [Char] ⊸ Either Error Int
% parseSStringDPS bs i escape d = case bs !? i of
%   ¤Nothing → °\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → °\mnew{fill @'[] d}° ; ¤Right i
%     '\\' | not escape → parseSStringDPS bs (i + 1) ¤True d
%     'n'  | escape → let °\mnew{!(dh, dt) = fill @'(:) d}°
%                      in °\mnew{fillLeaf '\textbackslash{}n' dh}° ; parseSStringDPS bs (i + 1) ¤False °\mnew{dt}°
%     _ → let °\mnew{!(dh, dt) = fill @'(:) d}°
%          in °\mnew{fillLeaf x dh}° ; parseSStringDPS bs (i + 1) ¤False °\mnew{dt}°
% \end{minted}
% \caption{Implementation of the S-expression parser with destinations}
% \label{table:impl-sexpr-parser-with-dest}
% \end{listing}

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
parseSList bs i acc = case bs !? i of
  ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → ¤Right (¤SList i (reverse acc))
    | isSpace x → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        ¤Left err → ¤Left err
        ¤Right child → parseSList bs (endPos child + 1) (child : acc)
\end{minted}
\caption{Implementation of the S-expression parser without destinations}
\label{table:impl-parser-naive}
\end{listing}

\begin{listing}[b]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
parseSListDPS bs i d = case bs !? i of
  ¤Nothing → °\mnew{d &fill @'[]}° ; ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → °\mnew{d &fill @'[]}° ; ¤Right i
    | isSpace x → parseSListDPS bs (i + 1) d
    | otherwise →
        case °\mnew{d &fill @'(:)}° of
          (dh, dt) → case parseSExprDPS bs i °\mnew{dh}° of
              ¤Left err → dt &fill @'[] ; ¤Left err
              ¤Right endPos → parseSListDPS bs (endPos + 1) °\mnew{dt}°
\end{minted}
\caption{Implementation of the S-expression parser with destinations}
\label{table:impl-parser-dps}
\end{listing}

We will see that destinations can bring very significative performance gains with only very little stylistic changes in the code. Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location.

Code for \mintinline{haskellc}/parseSListDPS/ is presented in Listing~\ref{table:impl-parser-dps}. Let's see what changed compared to the naive implementation:

\begin{itemize}
  \item even for error cases, we are forced to consume the destination that we receive as an argument (to stay linear), hence we write some sensible default data to it (see line 3);
  \item the \mintinline{haskellc}/SExpr/ value resulting from \mintinline{haskellc}/parseSExprDPS/ is not collected by \mintinline{haskellc}/parseSListDPS/ but instead written directly into its final location by \mintinline{haskellc}/parseSExprDPS/ through the passing and filling of destination \mintinline{haskellc}/dh/ (see line 9);
  \item adding an element of type \mintinline{haskellc}/SExpr/ to the accumulator \mintinline{haskellc}/[SExpr]/ is replaced with adding a newUAmpar cons cell with \mintinline{haskellc}/fill @'(:)/ into the hole represented by \mintinline{haskellc}/UDest [SExpr]/, writing an element to the \emph{head} destination, and then doing a recursive call with the \emph{tail} destination passed as an argument (which has type \mintinline{haskellc}/UDest [SExpr]/ again);
  \item instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskellc}/fill @'[]/, see line 5), as the list has been built in a top-down approach;
  \item DPS functions return the offset of the next character to read instead of a parsed value.
\end{itemize}

Thanks to that new implementation which is barely longer (in terms of lines of code) than the naive one, the program runs almost twice as fast, mostly because garbage-collection time goes to almost zero. The detailed benchmark is available in Section~\ref{sec:benchmark}.

We see here that compact regions and destination-passing style are quite symbiotic; compact regions makes DPS easier to implement, and DPS makes compact regions more efficient and flexible to use.

\subsection{Representation of \texttt{UAmpar} objects in Compact Regions}\label{ssec:repr-ampar}

Ideally, as we detailed in \cref{ssec:runtime-values,ssec:dpshaskell-dlist}, we want \mintinline{haskellc}/UAmpar r s t/ to be a kind of pair that contains a value of type \mintinline{haskellc}/s/ and one of type \mintinline{haskellc}/t/, and let the value of type \mintinline{haskellc}/s/ free when the one of type \mintinline{haskellc}/t/ has been fully consumed (or linearly transformed into \mintinline{haskellc}/Ur t'/).% So the most straightforward implementation for \mintinline{haskellc}/UAmpar/ would be a pair \mintinline{haskellc}/(s, t)/, where \mintinline{haskellc}/s/ in the pair is only partially complete.

We also know that \mintinline{haskellc}/newUAmpar/ returns an \mintinline{haskellc}/UAmpar r s (UDest s)/: there is nothing more here than an empty memory cell that will host the root of the future structure of type \mintinline{haskellc}/s/, which the associated destination of type \mintinline{haskellc}/UDest s/ points to, as presented in Figure~\ref{fig:schema-alloc}. As we said as early as \cref{ssec:build-up-vocab}, whatever goes in the hole is exactly what will be retrieved in the \mintinline{haskellc}/s/ side.

If \mintinline{haskellc}/UAmpar r s t/ is represented by a pair \mintinline{haskellc}/(s, t)/, then the cell hosting the root of the structure should be the first field of the pair. However, that cell must be in the compact region, otherwise the GC might follow the garbage pointer(s) that lives inside; whereas the \mintinline{haskellc}/UAmpar/ wrapper (that is discarded when \mintinline{haskellc}/fromUAmpar/ or \mintinline{haskellc}/fromUAmpar'/ are called) must be in the garbage-collected heap so that it can sometimes be optimized away by the compiler, and always deallocated as soon as possible.

Given that UAmpar hold unrestricted data, one potential solution is to represent \mintinline{haskellc}/UAmpar r s t/ by a pair \mintinline{haskellc}/(Ur s, t)/ where \mintinline{haskellc}/Ur/ is allocated inside the region and its field \mintinline{haskellc}/s/ serves as the cell hosting the root of the structure. With this approach, the \mintinline{haskellc}/UAmpar/ wrapper can live in the GC heap and be discarded as soon as possible, while the cell receiving the root of the incomplete structure lives in the region. With that representation, we can also have a very efficient implementation of \mintinline{haskellc}/fromUAmpar'/, as the first element of the pair representing the UAmpar is directly what \mintinline{haskellc}/fromUAmpar'/ should return (it doesn't help for \mintinline{haskellc}/fromUAmpar/ though). The downside is now that every \mintinline{haskellc}/UAmpar/ will now allocate a few words in the region (to host the \mintinline{haskellc}/Ur/ constructor\footnote{One might ask why \mintinline{haskellc}/Ur/ can't be a zero-cost \mintinline{haskellc}/newtype/ wrapper; it mostly comes down to semantics motivations, see \cite{spiwack_ur_2024}.}) that won't be collected by the GC for a long time even if the parent \mintinline{haskellc}/UAmpar/ is collected. In particular, this makes \mintinline{haskellc}/toUAmpar/ quite inefficient memory-wise too, as the \mintinline{haskellc}/Ur/ wrapper that will stay in the region is useless for already complete structures.

Another solution is to allocate a wrapper in the region to host the root of the structure \emph{only} for actual incomplete structures, and skip that allocation for already complete structures that are turned into an \mintinline{haskellc}/UAmpar/ object with \mintinline{haskellc}/toUAmpar/, while preserving a same type for both use-cases. This is made possible by replacing the \mintinline{haskellc}/Ur/ wrapper inside the \mintinline{haskellc}/UAmpar/ by an indirection object (\mintinline{haskellc}/stg_IND/ label) for the actually incomplete case. To conclude, the \mintinline{haskellc}/UAmpar r s t/ wrapper will be represented by a pair \mintinline{haskellc}/(s, t)/ allocated in the garbage-collected heap, with slight variations as illustrated in \cref{fig:schema-alloc-region}:
\begin{itemize}
  \item in the pair \mintinline{haskellc}/(s, t)/ returned by \mintinline{haskellc}/newUAmpar/, the \mintinline{haskellc}/s/ side points to an indirection object (a sort of constructor with one field, whose resulting type \mintinline{haskellc}/s/ is the same as the field type \mintinline{haskellc}/s/), that is allocated in the region, and serves as the cell hosting the root of the incomplete structure (because it is in the compact region, the GC won't follow yet-unspecified pointers that it might contain);
  \item in the pair \mintinline{haskellc}/(s, t)/ returned by \mintinline{haskellc}/toUAmpar/, the \mintinline{haskellc}/s/ side directly points to the object of type \mintinline{haskellc}/s/ that has been copied to the region, without indirection.
\end{itemize}
Compared to the previous solution, this one is more efficient when using \mintinline{haskellc}/toUAmpar/ (as no long-lived garbage is produced), but does no longer bring improvements to memory efficiency for \mintinline{haskellc}/fromUAmpar'/. This is the solution we chose to implement in the original artifact \cite{linear_dest}, but it would be worth comparing and benchmarking it with the other one.

In the end, in \cite{linear_dest}, we have the following private definitions (in the sense that they are opaque for the consumer of the API) :
\begin{minted}[linenos,escapeinside=°°]{haskellc}
data Token = ¤Token  -- same representation as ()
data UAmpar r s t = ¤UAmpar s t  -- same representation as (s, t)
data UDest r t = ¤UDest Addr#  -- boxed Addr#, same representation as Ptr t
\end{minted}

\subsection{Deriving \texttt{fill} for all constructors with \texttt{Generics}}\label{ssec:impl-generics}

In \destcalculus, it was quite easy to have a dedicated fill function for each data constructor. Indeed, we only had to account for a finite number of them (one for unit, two for sums, one for pair, and one for exponential; with the one for function being quite optional).

In Haskell however, we want to be able to do destination passing with arbitrary data types, even user-defined ones, so it wouldn't be feasible to implement, manually, one filling function per possible data constructor. So instead, we have to generalize all filling functions into a single, polymorphic \mintinline{haskellc}/fill/ function that is able to work for any data constructor.

To this extend, we add a typeclass \mintinline{haskellc}/Fill lCtor t/, to which \mintinline{haskellc}/fill/ becomes a method, so that we are able to specialize the behaviour of \mintinline{haskellc}/fill/ based on the type parameter \mintinline{haskellc}/lCtor/. The idea is that \mintinline{haskellc}/lCtor/ represent the type-level name of the data constructor we want to use with \mintinline{haskellc}/fill/ (that's why the syntax is \mintinline{haskellc}/fill @'Ctor/: we lift \mintinline{haskellc}/¤Ctor/ into a type-level name with the \mintinline{haskellc}/'/ operator, then make a type application with \mintinline{haskellc}/@/). We will see how this type-level name can be used to derive all the information we need to decide on the concrete implementation for \mintinline{haskellc}/fill/, which should plug a new hollow constructor of the specified variant into the hole of a structure pointed to by the specified destination.

What we need for \mintinline{haskellc}/fill/ is to generically is the shape of the constructor, and more precisely the number and type of its fields. So we will leverage \mintinline{haskellc}/GHC.Generics/ to find the required information.

\mintinline{haskellc}/GHC.Generics/ is a built-in Haskell library that provides compile-time inspection of a type metadata through the \mintinline{haskellc}/Generic/ typeclass: list of constructors, their fields, memory representation, etc. And that typeclass can be derived automatically for any type! Here's, for example, the \mintinline{haskellc}/Generic/ representation of \mintinline{haskellc}/Maybe t/:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
repl> :k! Rep (Maybe a) () -- display the Generic representation of Maybe a
M1 D (MetaData "Maybe" "GHC.Maybe" "base" False) (
  M1 C (MetaCons "¤Nothing" PrefixI False) U1
  :+: M1 C (MetaCons "¤Just" PrefixI False) (M1 S ¤[...¤] (K1 R a)))
\end{minted}
}
\end{unbreakable}

We see that there are two different constructors (indicated by \mintinline{haskellc}/M1 C .../ lines): \mintinline{haskellc}/¤Nothing/ has zero fields (indicated by \mintinline{haskellc}/U1/) and \mintinline{haskellc}/¤Just/ has one field of type \mintinline{haskellc}/t/ (indicated by \mintinline{haskellc}/K1 R t/).

With a bit of type-level programming\footnote{see \texttt{src/Compact/Pure/Internal.hs:418} in~\cite{linear_dest}}, we can extract the parts of the representation of \mintinline{haskellc}/t/ which gives information on its constructor \mintinline{haskellc}/lCtor/ and use them inside the instance head of \mintinline{haskellc}/Fill lCtor t/ so the implementation of \mintinline{haskellc}/fill/ can depend on them. In particular, we implement one specialized version of \mintinline{haskellc}/fill/ per number of fields in \mintinline{haskellc}/lCtor/, from 0 to 7\footnote{We could go higher, 7 is just an arbitrary limit for the number of fields that is rather common in standard Haskell libraries.}, because there is no way to abstract over the length of a tuple in Haskell, and the number of fields of the chosen constructor is equal to the number of new destinations we must return (in a tuple, with 0 to 7 elements) from a call to \mintinline{haskellc}/fill/. 

The resolution of the \mintinline{haskellc}/UDestsOf lCtor t ⩴ Type/ type family into a concrete type is also made thanks to the generic representation of \mintinline{haskellc}/t/, to extract what it needs to know about \mintinline{haskellc}/lCtor/ and its fields.

At the end of the day, it's no surprise that we are able to implement \mintinline{haskellc}/fill/ generically for all linked data structures\footnote{Dealing with primitive or unboxed types is, on the other hand, quite challenging, see the mention at the end of \cref{sec:implem-destcalculus}.}: as the end of the day, every data constructor for a linked data type can be seen as a n-ary product constructor, and we just scale the recipe for \mintinline{haskellc}/fill @'(:)/ to more (or fewer) fields and destinations.

Still, with all of that done, we still need internal Haskell machinery to allocate the proper hollow constructor object in the compact region. \mintinline{haskellc}/fill/ is just the external layer dealing with destinations, with a type-safe signature, etc.

\subsection{Changes to GHC internals and RTS}\label{ssec:impl-ghc}

We will see here how to allocate a hollow heap object for a given constructor, but let's first take a detour to give more context about the internals of the compiler.

Haskell's runtime system (RTS) is written in a mix of C and C-{}-. The RTS has many roles, among which managing threads, organizing garbage collection or managing compact regions. It also defines various primitive operations, named \emph{external primops}, that expose the RTS capabilities as normal functions. Despite all its responsibilities, however, the RTS is not responsible for the allocation of normal constructors (built in the garbage-collected heap). One reason is that it doesn't have all the information needed to build a constructor heap object, namely, the info table associated to the constructor.

The info table is what defines both the layout and behavior of a heap object. All heap objects representing a same constructor (let's say \mintinline{haskellc}/¤Just/) have the same info table, which acts as the identity card for a given data constructor, even when the associated types are different (e.g. \mintinline{haskellc}/Maybe Int/ and \mintinline{haskellc}/Maybe Bool/ shares the same info table). Heap objects representing this constructor all point to a label \mintinline{text}/<ctor>_con_info/ that will be later resolved by the linker into an actual pointer to the shared info table.

On the other hand, the RTS is a static piece of code that is compiled once when GHC is built. So the RTS has no direct way to access the information emitted during the compilation of a program. In other words, when the RTS runs, it has no way to inspect the program that it runs and info table labels have long been replaced by actual pointers so it cannot find them itself. But the RTS is the one which knows how to allocate space inside a compact region.

As a result, we need a way to pass information from compile time to the runtime need. We do that with two new primitives:

\begin{itemize}
\item one \emph{external primop} to allocate space inside a compact region for a hollow constructor. This primop has to be implemented inside the RTS for the aforementioned reasons;
\item one \emph{internal primop} (internal primops are macros which generates C-{}- code) that will be resolved into a normal albeit static value representing the info table pointer of a given constructor. This value will be passed as an argument to the external primop.
\end{itemize}

All the alterations to GHC that will be showed here are available in full form in~\cite{custom_ghc}.

\paragraph{External primop: allocate a hollow constructor in a region}

The implementation of the external primop is presented in Listing~\ref{table:impl-compactAddHollow}. The \mintinline{c}/stg_compactAddHollowzh/ function (whose equivalent on the Haskell side is \mintinline{haskellc}/compactAddHollow#/) is mostly a glorified call to the \mintinline{haskellc}/ALLOCATE/ macro defined in the \mintinline{text}/Compact.cmm/ file, which tries to do a pointer-bumping allocation in the current block of the compact region if there is enough space, and otherwise add a newUAmpar block to the region.

As announced, this primop takes the info table pointer of the constructor to allocate as its second parameter (\mintinline{c}/W_ info/) because it cannot access that information itself. The info table pointer is then written to the first word of the heap object in the call to \mintinline{c}/SET_HDR/.

\paragraph{Internal primop: reify an info table label into a runtime value}

The only way, in Haskell, to pass a constructor to a primop so that the primop can inspect it, is to lift the constructor into a type-level literal. It's common practice to use a \mintinline{haskellc}/Proxy t/ (the unit type with a phantom type parameter) to pass the type \mintinline{haskellc}/t/ as an input to a function. Unfortunately, due to a quirk of the compiler, primops don't have access to the type of their arguments. They can, however, access their return type. So we use a phantom type \mintinline{haskellc}/InfoPtrPlaceholder# t/ as the return type, to pass the contructor as an input!

The gist of this implementation is presented in Listing~\ref{table:impl-reifyInfoPtr}. The primop \mintinline{haskellc}/reifyInfoPtr#/ pattern-matches on the type \mintinline{haskellc}/resTy/ of its return value. In the case it reads a string literal, it resolves the primop call into the label \mintinline{text}/stg_<name>/ (this is used in particular to allocate a \mintinline{haskellc}/stg_IND/ object as mentionned in \cref{ssec:repr-ampar}). In the case it reads a lifted data constructor, it resolves the primop call into the label which corresponds to the info table pointer of that constructor. The returned \mintinline{haskellc}/InfoPtrPlaceholder# t/ can later be converted back to an \mintinline{haskellc}/Addr#/ using the \mintinline{haskellc}/unsafeCoerceAddr/ function.

As an example, here is how to allocate a hollow \mintinline{haskellc}/¤Just/ constructor in a compact region:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos]{haskellc}
hollowJust ⩴ Maybe a = compactAddHollow#
  compactRegion#
  (unsafeCoerceAddr (reifyInfoPtr# (# #) ⩴ InfoPtrPlaceholder# 'Just ))
\end{minted}
\vspace{-0.8\baselineskip}
}
\end{unbreakable}

\paragraph{Built-in type family to go from a lifted constructor to the associated symbol}

The internal primop \mintinline{haskellc}/reifyInfoPtr#/ that we introduced above takes as input a constructor lifted into a type-level literal, so this is also what \mintinline{haskellc}/fill/ will use to know which constructor it should operate with. But \mintinline{haskellc}/UDestsOf/ have to find the metadata of a constructor in the \mintinline{haskellc}/Generic/ representation of a type, in which only the constructor name appears.

So we added a newUAmpar type family \mintinline{haskellc}/LCtorToSymbol/ inside GHC that inspects its (type-level) parameter representing a constructor, fetches its associated \mintinline{haskellc}/DataCon/ structure, and returns a type-level string (kind \mintinline{haskellc}/Symbol/) carrying the constructor name, as presented in Listing~\ref{table:impl-LCtorToSymbol}.

\begin{listing}[p]
\figtextsize
\begin{minted}[linenos]{c}
// compactAddHollow#
//   ⩴ Compact# → Addr# → State# RealWorld → (# State# RealWorld, a #)
stg_compactAddHollowzh(P_ compact, W_ info) {
    W_ pp, ptrs, nptrs, size, tag, hp;
    P_ to, p; p = NULL;  // p isn't actually used by ALLOCATE macro
    again: MAYBE_GC(again); STK_CHK_GEN();

    pp = compact + SIZEOF_StgHeader + OFFSET_StgCompactNFData_result;
    ptrs  = TO_W_(%INFO_PTRS(%STD_INFO(info)));
    nptrs  = TO_W_(%INFO_NPTRS(%STD_INFO(info)));
    size = BYTES_TO_WDS(SIZEOF_StgHeader) + ptrs + nptrs;
    
    ALLOCATE(compact, size, p, to, tag);
    P_[pp] = to;
    SET_HDR(to, info, CCS_SYSTEM);
  #if defined(DEBUG)
    ccall verifyCompact(compact);
  #endif
    return (P_[pp]);
}
\end{minted}
\caption{\texttt{compactAddHollow\#} implementation in \texttt{rts/Compact.cmm}}
\label{table:impl-compactAddHollow}
\end{listing}

\begin{listing}[p]
\figtextsize
\begin{minted}[linenos]{haskellc}
case primop of
  [...]
  ¤ReifyStgInfoPtrOp → \_ →  -- we don't care about the function argument (# #)
    opIntoRegsTy $ \[res] resTy → emitAssign (¤CmmLocal res) $ case resTy of
      -- when 'a' is a Symbol, and extracts the symbol value in 'sym'
      ¤TyConApp _addrLikeTyCon [_typeParamKind, ¤LitTy (¤StrTyLit sym)] →
          ¤CmmLit (¤CmmLabel (
            mkCmmInfoLabel rtsUnitId (fsLit "stg_" `appendFS` sym)))
      -- when 'a' is a lifted data constructor, extracts it as a DataCon
      ¤TyConApp _addrLikeTyCon [_typeParamKind, ¤TyConApp tyCon _]
        | ¤Just dataCon ← isPromotedDataCon_maybe tyCon →
          ¤CmmLit (¤CmmLabel (
            mkConInfoTableLabel (dataConName dataCon) ¤DefinitionSite))
      _ → [...] -- error when no pattern matches
\end{minted}
\caption{\texttt{reifyInfoPtr\#} implementation in \texttt{compiler/GHC/StgToCmm/Prim.hs}}
\label{table:impl-reifyInfoPtr}
\end{listing}

\begin{listing}[p]
\figtextsize
\begin{minted}[linenos]{haskellc}
matchFamLCtorToSymbol ⩴ [Type] → Maybe (CoAxiomRule, [Type], Type)
matchFamLCtorToSymbol [kind, ty]
  | ¤TyConApp tyCon _ ← ty, ¤Just dataCon ← isPromotedDataCon_maybe tyCon =
      let symbolLit = (mkStrLitTy . occNameFS . occName . getName $ dataCon)
       in ¤Just (axLCtorToSymbolDef, [kind, ty], symbolLit)
matchFamLCtorToSymbol tys = ¤Nothing

axLCtorToSymbolDef =
  mkBinAxiom "LCtorToSymbolDef" typeLCtorToSymbolTyCon ¤Just
    (\case { ¤TyConApp tyCon _ → isPromotedDataCon_maybe tyCon ; _ → ¤Nothing })
    (\_ dataCon → ¤Just (mkStrLitTy . occNameFS . occName . getName $ dataCon))
\end{minted}
\caption{\mintinline{haskellc}/LCtorToSymbol/ implementation in \texttt{compiler/GHC/Builtin/Types/Literal.hs}}
\label{table:impl-LCtorToSymbol}
\end{listing}

\paragraph{Putting it all together, and further evolutions}

Combining all these elements, we are able to implement the low-level operations needed for destination passing and hollow constructor allocation.

The implementation presented above has been thought to require the minimal number of changes on GHC, as we considered destination passing to be a niche concern that couldn't justify large exotic changes to this industrial-grade compiler.

However, since this first experimentation\cite{custom_ghc}, a pull request has been opened\cite{bagrel_primitives_2024} to try to merge support for hollow constructor building in compact regions into the main, publicly-distributed branch of GHC. This PR tends to take the path of a slightly more complete set of primitives than the three aforementioned ones, in particular with primitive forms for \mintinline{haskellc}/fill/ being part of it (instead of being only in library code, as it is now). Still, much work remains to be done before reaching a mergeable state. I hope to dedicate a few weeks to work on the matter at the very end or just after the end of my PhD.

\section{Evaluating the performance of DPS programming}\label{sec:benchmark}

% ----------------------

\paragraph{Benchmarking methodology}

In this chapter, we talked about programs in both naive style and DPS style. With DPS programs, the result is stored in a compact region, which also forces strictness i.e. the structure is automatically in fully evaluated form.

For naive versions, we have a choice to make on how to fully evaluate the result: either force each chunk of the result inside the GC heap (using \mintinline{haskellc}/Control.DeepSeq.force/), or copy the result in a compact region that is strict by default (using \mintinline{haskellc}/Data.Compact.compact/).

In programs where there is no particular long-lived piece of data, having the result of the function copied into a compact region isn't particularly desirable since it will generally inflate memory allocations. So we use \mintinline{haskellc}/force/ to benchmark the naive version of those programs (the associated benchmark names are denoted with a ``*'' suffix).

\begin{figure}[t]\centering
  \hspace*{-1.5cm}\includegraphics[width=16.8cm]{graphics/bench-charts.pdf}
  \caption{Benchmarks performed on AMD EPYC 7401P @ 2.0 GHz (single core, \texttt{-N1 -O2})}
  \label{fig:bench-charts}
\end{figure}

\paragraph{Concatenating lists and difference lists}

We compared three implementations. \\\mintinline{haskellc}/foldr (++)/* has calls to \mintinline{haskellc}/(++)/ nested to the right, giving the most optimal context for list concatenation (it should run in $\mathcal{O}(n)$ time). \mintinline[escapeinside=°°]{haskellc}/foldl' concat°$\lambda$°/* uses function-backed difference lists, and \mintinline{haskellc}/foldl' concatDPS/ uses destin\-ation-backed ones, so both should run in $\mathcal{O}(n)$ even if calls to concat are nested to the left.

We see in part \textbf{A} of Figure~\ref{fig:bench-charts} that the destination-backed difference lists have a comparable memory use as the two other linear implementations, while being quite slower (by a factor 2-4) on all datasets. We would expect better results though for a DPS implementation outside of compact regions because those cause extra copying.

\paragraph{Breadth-first relabeling}\label{par:benchmark-bf-tree-traversal}

We see in part \textbf{B} of Figure~\ref{fig:bench-charts} that the destination-based tree traversal is almost one order of magnitude more efficient, both time-wise and memory-wise, compared to the implementation based on \emph{Phases} applicatives presented in~\cite{gibbons_phases_2023}.

\paragraph{Parsing S-expressions}

In part \textbf{C} of Figure~\ref{fig:bench-charts}, we compare the naive implementation of the S-expression parser and the DPS one (see Section~\ref{ssec:parser-sexpr}). For this particular program, where using compact regions might reduce the future GC load of the application, it is relevant to benchmark the naive version twice: once with \mintinline{haskellc}/force/ and once with \mintinline{haskellc}/compact/.

The DPS version starts by being less efficient than the naive versions for small inputs, but gets an edge as soon as garbage collection kicks in (on datasets of size $\leq 2^{16}$, no garbage collection cycle is required as the heap size stays small).

On the largest dataset ($2^{22} \simeq 4$MiB file), the DPS version still makes about 45\% more allocations than the starred naive version, but uses 35\% less memory at its peak, and more importantly, spends 47$\times$ less time in garbage collection. As a result, the DPS version only takes 0.55-0.65$\times$ the time spent by the naive versions, thanks to garbage collection savings. All of this also indicates that most of the data allocated in the GC heap by the DPS version just lasts one generation and thus can be discarded very early by the GC, without needing to be copied into the next generation, unlike most nodes allocated by the naive versions.

Finally, copying the result of the naive version to a compact region (for future GC savings) incurs a significant time and memory penalty, that the DPS version offers to avoid.

% \subsection{Mapping a function over a list}\label{ssec:benchmark-map}

% It seemed important to also measure the performance of a \mintinline{haskellc}/map/ function implementation using destinations. In a strict functional language such as OCaml, the choice of implementation for \mintinline{haskellc}/map/ is crucial as the naive one makes the stack grow linearly with the size of the processed list. A strict tail-recursive version (\mintinline{haskellc}/mapTR'/) takes $\mathcal{O}(1)$ space, but it requires an extra $\mathcal{O}(n)$ operation at the end of the processing (reversing the accumulator). 

% With destinations, \mintinline{haskellc}/map/ can be implemented in a tail-recursive fashion without the need for the reverse operation (as the list is built in a top-down approach). It can also be implemented as a fold:
% {\figtextsize
% \begin{minted}[linenos]{haskellc}
% append ⩴ UDest [a] ⊸ a → UDest [a]
% append d x = let !(dh, dt) = fill @'(:) d in fillLeaf x dh ; dt

% mapDPS' _ [] d = fill @'[] d
% mapDPS' f (x : xs) d = let !y = f x ; !d' = append d y in mapDPS' f xs d'

% mapDPSFold' f l dl = fill @'[] (foldl' (\d x → let !y = f x in append d y) d l)
% \end{minted}
% }

% We see in part 4 of Figure~\ref{fig:bench-charts} that the destination-based implementations takes 1.5-4$\times$ more time than \mintinline{haskellc}/map/ and \mintinline{haskellc}/mapTR'/ (depending on the dataset size), but memory-wise both \mintinline{haskellc}/mapDPS'/ and \mintinline{haskellc}/mapDPSFold'/ are more efficient than \mintinline{haskellc}/map/; and \mintinline{haskellc}/mapDPS'/ even manage to make 13\% fewer allocs than \mintinline{haskellc}/mapTR'/ on the largest dataset.

% In OCaml, \mintinline{haskellc}/mapDPS'/ is actually more performant time-wise than \mintinline{haskellc}/mapTR'/ ($0.5-0.85\times$) even for small lists, as detailed in~\cite{bour_tmc_2021}.

\section{Conclusion and future work}

Programming with destinations definitely has a place in the realm of functional programming, as the recent adoption of \emph{Tail Modulo Cons}~\cite{bour_tmc_2021} in the OCaml compiler shows. In this paper, we have shown how destination-passing style programming can be used in user-land in Haskell safely, thanks to a linear type discipline. Adopting DPS programming opens the way for more natural and efficient programs in a variety of contexts, where the major points are being able to build structures in a top-down fashion, manipulating and composing UAmpar structures, and managing holes in these structures through first-class objects (destinations). Our DPS implementation relies only on a few alterations to the compiler, thanks to \emph{compact regions} that are already available as part of GHC. Simultaneously, it allows to build structures in those regions without copying, which wasn't possible before.

There are two limitations that we would like to lift in the future. First, DPS programming could be useful outside of compact regions: destinations could probably be used to manipulate the garbage-collected heap (with proper read barriers in place), or other forms of secluded memory areas that aren't traveled by the GC (RDMA, network serialized buffers, etc.). Secondly, at the moment, the type of \mintinline{haskellc}/fillLeaf/ implies that we can't store destinations (which are always linear) in a difference list implemented as in Section~\ref{ssec:dpshaskell-dlist}, whereas we can store them in a regular list or queue (like we do, for instance, in Section~\ref{ssec:bf-tree-traversal}). This unwelcome restriction ensures memory safety but it's quite coarse grain. In the future we'll be trying to have a more fine-grained approach that would still ensure safety.
