\chapter{A first implementation of first-class destination passing in Haskell}\label{chap:dps-haskell}

\section{Introduction}\label{intro-dps-haskell}

In the previous chapter, we saw how we can build a $\lambda$-calculus from the ground up with first-class support for destination passing, and that still achieve memory safety. It's now time to put that into practice.

However, it wouldn't be feasible to design an industrial-grade programming language \emph{just} to add support for destinations. Instead, we'll base our work on an existing functional programming language.

The Haskell programming language is equipped with support for linear types through its main compiler, \emph{GHC}, since version 9.0.1~\cite{bernardy_linear_2018}. There aren't many other industrial-grade functional programming languages, and most of them don't have support for linear types, which are the first piece required to make our system safe. OCaml, thanks to recent work from \citet{lorenzen_oxidizing_2024}, has support for \emph{affinity}, but not for linearity (despite the aforementioned work using the term ``linearity''): a resource can be restricted to at most one use, but there is no way to ensure it will be used exactly once; it could be dropped without being used at all.

As a result, Haskell appeared to be a promising target for a real-world implementation of \destcalculus{}, as detailed in depth in \cref{chap:dest-calculus}. In addition, Haskell is also a \emph{pure} functional language, which is rather in line with the idea of hiding impure memory effects related to destinations behind a \emph{pure} API by preventing any read before a structure has been completed.

However, the main challenge is that Haskell, albeit incorporating linear types, doesn't have any concept of scope or age control. So we won't be able to avoid the fundamental issues presented in \cref{sec:scope-escape-dests} without imposing limitations on the flexibility of the system.

\section{Linear Types in Haskell}\label{sec:intro-linearity}

Linear Haskell~\cite{bernardy_linear_2018} is a language extension for the Glasgow Haskell Compiler (GHC) that introduces the linear function arrow, \mintinline{haskellc}/t ⊸ u/ and modifies the type checker of GHC so that it can enforce linearity requirement. A linear function of type \mintinline{haskellc}/t ⊸ u/ guarantees that the argument of the function will be consumed exactly once when the result of the function is consumed exactly once. The regular function arrow \mintinline{haskellc}/t → u/ is still available when Linear Haskell is enabled; this one doesn't guarantee how many times its argument will be consumed when its result is consumed once. There is also a multiplicity-polymorphic arrow, \mintinline{haskellc}/t %p → u/, much like $[[T m → U]]$ in \destcalculus{}.

A value is said to be \emph{consumed once} (or \emph{consumed linearly}) when it is pattern-matched on and its sub-components are consumed once; or when it is passed as an argument to a linear function whose result is consumed once. A function is said to be \emph{consumed once} when it is applied to an argument and when the result is consumed exactly once. We say that a variable \mintinline{haskellc}/x/ is \emph{used linearly} in an expression \mintinline{haskellc}/u/ when consuming \mintinline{haskellc}/u/ once implies consuming \mintinline{haskellc}/x/ exactly once. Linearity on function arrows thus creates a chain of requirements about consumption of values.

\paragraph{Unrestricted Values}

Linear Haskell introduces a wrapper named \mintinline{haskellc}/Ur/ which is used to indicate that a value in a linear context doesn't have to be used linearly. \mintinline{haskellc}/Ur t/ is equivalent to $[[! T]]$ in linear logic ($[[! ɷ T]]$ in \CLdm{}), and there is an equivalence between \mintinline{haskellc}/Ur t ⊸ u/ and \mintinline{haskellc}/t → u/. As in \CLTwo{} and \CLdm{}, we can pattern-match on a term of type \mintinline{haskellc}/Ur t/ with \mintinline{haskellc}/case term of ¤Ur x ⊸ term'/ to obtain an unrestricted variable binding \mintinline{haskellc}/x/ of type \mintinline{haskellc}/t/.

As usual with linear type systems, only values already wrapped in \mintinline{haskellc}/¤Ur/ or coming from the left of a non-linear arrow can be put in another \mintinline{haskellc}/¤Ur/ without breaking linearity. This echoes rules \rref*{\CLOne\CTy\CSep\CBangProm} or \rref*{\CLTwoOrm\CTy\CSep\CExp} where a term wrapped in $\ottsctor{Many}$ or $\expcons{[[ɷ]]}$ must only depend on an unrestricted context. The only exceptions to this rule are terms of types that implement the \mintinline{haskellc}/Movable/ typeclass\footnote{The \mintinline{haskellc}/Movable/ typeclass is not part of the Linear Haskell language extension, but instead defined in the \texttt{linear-base} library.} such as \mintinline{haskellc}/Int/ or \mintinline{haskellc}/()/. \mintinline{haskellc}/Movable/ provides the function \mintinline{haskellc}/move ⩴ t ⊸ Ur t/ so that a value can escape linearity restrictions.

% Arnaud: this sentence sounds premature to me
% Destinations are represented by the type \mintinline{haskellc}/UDest t/, where \mintinline{haskellc}/t/ stands for the type of the associated hole. \mintinline{haskellc}/UDest/s are meant to be managed linearly, so don't implement \mintinline{haskellc}/Movable/.

\paragraph{Operators}

Some Haskell operators and notations are often used in the rest of this article:

\mintinline{haskellc}/(;) ⩴ () ⊸ u ⊸ u/ is used to chain a linear operation returning \mintinline{haskellc}/()/ with one returning a value of type \mintinline{haskellc}/u/ without breaking linearity. It's a shorthand for pattern-matching on the unit type.

\mintinline{haskellc}/Class ⇒ .../ is notation for typeclass constraints (resolved implicitly by the compiler).

\section{Restricting \destcalculus{} so that it can be made safe with just linear types}

As we've seen in \cref{sec:scope-escape-dests}, linear types are not enough, alone, to make \destcalculus{} safe. We definitely need ages. In this chapter, we will take a radical decision: we will make it so that destinations can only be used to build non-linear (a.k.a. unrestricted) data structures, so that the issue of scope escape disappear completely. In exchange, we won't be able to store destinations inside data structures built using ampars.

In practice, that means that a destination can only be filled with an unrestricted value (which forbids filling a destination with another destination, as destinations are linear resources). We will use the Haskell type \mintinline{haskellc}/data UDest t/ to represent those destinations for unrestricted values, and type \mintinline{haskellc}/data UAmpar s t/ to represent these ampars where the \mintinline{haskellc}/s/ side is unrestricted.

Because there is no difference when creating the spine of a data structures that is linear or unrestricted, our fill functions that adds a new hollow constructor to an existing structure will be exactly the same as in \destcalculus{}. Only the signature of fill operators acting on the leaves of data structures will change in the implementation compared to the formal definition.

The mapping of operators between \destcalculus{} and DPS Haskell is given in \cref{fig:mapping-destcalculus-dpshaskell}

\begin{figure}

\begin{tabular}{|l|lcl|}\hline
\destcalculus{} & DPS Haskell \\\hline\hline
$[[d ⨞ ()]]$ & \mintinline{haskellc}/fill @'() d/ &or& \mintinline{haskellc}/d & fill @'()/ \\\hline
$[[d ⨞ Inl]]$ & \mintinline{haskellc}/fill @'Inl d/ &or& \mintinline{haskellc}/d & fill @'Inl/ \\\hline
$[[d ⨞ Inr]]$ & \mintinline{haskellc}/fill @'Inr d/ &or& \mintinline{haskellc}/d & fill @'Inr/ \\\hline
$[[d ⨞ (,)]]$ & \mintinline{haskellc}/fill @'(,) d/ &or& \mintinline{haskellc}/d & fill @'(,)/ \\\hline
$[[d ⨞ ᴇ ω∞]]$ & \mintinline{haskellc}/fill @'Ur d/ &or& \mintinline{haskellc}/d & fill @'Ur/ \\\hline
$[[d ⨞ ( λ x m ⟼ term )]]$ & \mintinline{haskellc}/fillLeaf (\x -> term) d/ &or& \mintinline{haskellc}/d & fillLeaf (\x -> term)/ \\\hline
$[[d ⨞· term]]$ & \mintinline{haskellc}/fillComp term d/ &or& \mintinline{haskellc}/d & fillComp term/ \\\hline
$[[d ◀ term]]$ & \mintinline{haskellc}/fillLeaf term d/ &or& \mintinline{haskellc}/d & fillLeaf term/ \\\hline

\end{tabular}

\caption{Mapping between \destcalculus{} operators and DPS Haskell ones}\label{fig:mapping-destcalculus-dpshaskell}
\end{figure}

\section{Motivating examples for DPS programming}\label{sec:motivating-examples}

The following subsections present three typical settings in which DPS programming brings expressiveness or performance benefits over a more traditional functional implementation.

\subsection{Efficient difference lists}\label{ssec:dlist}

Linked lists are a staple of functional programming, but they aren't efficient for concatenation, especially when the concatenation calls are nested to the left.

In an imperative context, it would be quite easy to concatenate linked lists efficiently. One just has to keep both a pointer to the root and to the last \emph{cons} cell of each list. Then, to concatenate two lists, one just has to mutate the last \emph{cons} cell of the first one to point to the root of the second list.

It isn't possible to do so in an immutable functional context though. Instead, \emph{difference lists} can be used: they are very fast to concatenate, and then to convert back into a list. They tend to emulate the idea of having a mutable (here, write-once) last \emph{cons} cell. Usually, a difference list \mintinline{haskellc}/x1 : ... : xn : □/ is encoded by function \mintinline{haskellc}/\ys → x1 : ... : xn : ys/ taking a last element \mintinline{haskellc}/ys ⩴ [t]/ and returning a value of type \mintinline{haskellc}/[t]/ too.

With such a representation, concatenation is function composition: \mintinline{haskellc}/f1 <> f2 = f1 . f2/, and we have \mintinline{haskellc}/mempty = id/\footnote{\mintinline{haskellc}/mempty/ and \mintinline{haskellc}/<>/ are the usual notations for neutral element and binary operation of a monoid in Haskell.}, \mintinline{haskellc}/toList f = f []/ and \mintinline{haskellc}/fromList xs = \ys → xs ++ ys/.

In DPS, instead of encoding the concept of a write-once hole with a function, we can represent the hole of type \mintinline{haskellc}/[t]/ as a first-class object with a \emph{destination} of type \mintinline{haskellc}/UDest [t]/. A difference list now becomes an actual data structure in memory --- not just a pending computation --- that has two handles: one to the root of the list of type \mintinline{haskellc}/[t]/, and one to the yet-to-be-filled hole in the last cons cell, represented by the destination of type \mintinline{haskellc}/UDest [t]/.

With the function encoding, it isn't possible to read the list until a last element of type \mintinline{haskellc}/[t]/ has been supplied to complete it. With the destination representation, this constraint must persist: the actual list \mintinline{haskellc}/[t]/ shouldn't be readable until the accompanying destination is filled, as pattern-matching on the hole would lead to a dreaded \emph{segmentation fault}. This constraint is embodied by the \mintinline{haskellc}/UAmpar s t/ type of our destination API: \mintinline{haskellc}/t/ is what needs to be linearly consumed to make the \mintinline{haskellc}/s/ readable. The right side often carries the destinations of a structure. A difference list is then \mintinline{haskellc}/type DList t = UAmpar [t] (UDest [t])/: the \mintinline{haskellc}/UDest [t]/ must be filled (with a \mintinline{haskellc}/[t]/) to get a readable \mintinline{haskellc}/[t]/.

The implementation of destination-backed difference lists is presented in Listing~\ref{table:impl-dlist}. More details about the API primitives used by this implementation are given in Section~\ref{sec:api}. For now, it's important to note that \mintinline{haskellc}/fill/ is a function taking a constructor as a type parameter (often used with \mintinline{haskellc}/@/ for type parameter application, and \texttt{\textbf{\textcolor{typcolor}{'}}} to lift a constructor to a type).
% Doesn't bring much more compared to fig:schema-dlist-concat
% \begin{figure}[t]\centering
%   \includegraphics[width=10cm]{fillComp.png}
%   \caption{Memory behavior of \mintinline{haskellc}/fillComp ⩴ UAmpar s t ⊸ UDest s ⊸ t/}
%   \label{fig:schema-fillComp}
% \end{figure}

\begin{listing}[t]
\figtextsize
\begin{minted}{haskellc}
data [a] = {- nil constructor -} [] | {- cons constructor -} (:) a [a]

type DList a = UAmpar [a] (UDest [a])

newUAmparUAmpar ⩴ DList a  -- API primitive (simplified signature w.r.t. Section 4)

append ⩴ DList a ⊸ a → DList a
append i x =
  i `updWith` \d → case fill @'(:) d of
    (dh, dt) → fillLeaf x dh ; dt

concat ⩴ DList a ⊸ DList a ⊸ DList a
concat i1 i2 = i1 `updWith` \dt1 → fillComp i2 dt1

toList ⩴ DList a ⊸ [a]
toList i = unFromUAmpar' (i `updWith` \dt → fill @'[] dt)
\end{minted}
\caption{Implementation of difference lists with destinations}
\label{table:impl-dlist}
\end{listing}

\begin{figure}[t]\centering
  \hspace{-0.5cm}\begin{minipage}{0.3\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/alloc}}
    \caption{\mintinline{haskellc}/newUAmpar/`}
    \label{fig:schema-alloc}
  \end{minipage}\hspace{0cm}%
  \begin{minipage}{0.7\textwidth}
    \scalebox{\figscale}{\tikzfig{schemas/dlist-toList}}
    \caption{Memory behavior of \mintinline{haskellc}/toList i/}
    \label{fig:schema-dlist-toList}
  \end{minipage}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-append}}
  \caption{Memory behavior of \mintinline{haskellc}/append newUAmpar 1/`}
  \label{fig:schema-dlist-append}
\end{figure}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/dlist-concat}}
  \caption{Memory behavior of \mintinline{haskellc}/concat i1 i2/ (based on \mintinline{haskellc}/fillComp/)}
  \label{fig:schema-dlist-concat}
\end{figure}

% \begin{figure}[p]\centering

% \end{figure}

\begin{itemize}
  \item \mintinline{haskellc}/newUAmpar/` (Figure~\ref{fig:schema-alloc}) returns a
    \mintinline{haskellc}/DList t/ which is exactly an
    \mintinline{haskellc}/UAmpar [t] (UDest [t])/ structure. There is no data
    there yet and the list that will be fed in \mintinline{haskellc}/UDest [t]/ is exactly the list that the
    resulting \mintinline{haskellc}/UAmpar/ will hold. This is
    similar to the function encoding where \mintinline{haskellc}/\x → x/ represents the empty difference list;
    

  \item \mintinline{haskellc}/append/ (Figure~\ref{fig:schema-dlist-append}) adds an element at the tail
    position of a difference list. For this, it first uses
    \mintinline{haskellc}/fill @'(:)/ to fill the hole at the end of the list represented by
    \mintinline{haskellc}/d ⩴ UDest [t]/ with a hollow \emph{cons}
    cell with two newUAmpar holes pointed by \mintinline{haskellc}/dh ⩴ UDest t/ and \mintinline{haskellc}/dt ⩴ UDest [t]/. Then,
    \mintinline{haskellc}/fillLeaf/ fills the hole represented by
    \mintinline{haskellc}/dh/ with the value
    of type \mintinline{haskellc}/t/
    to append. The hole of the resulting difference list is the one pointed by \mintinline{haskellc}/dt ⩴ UDest [t]/ which hasn't been filled yet.

  \item \mintinline{haskellc}/concat/ (Figure~\ref{fig:schema-dlist-concat}) concatenates two difference lists,
    \mintinline{haskellc}/i1/ and \mintinline{haskellc}/i2/. It uses \mintinline{haskellc}/fillComp/ to fill the destination \mintinline{haskellc}/dt1/
    of the first difference list with the
    root of the second difference list \mintinline{haskellc}/i2/. The resulting \mintinline{haskellc}/UAmpar/
    object hence has the same root as the first list, holds the
    elements of both lists, and inherits the hole of the second list. Memory-wise,
    \mintinline{haskellc}/concat/ just writes an address into a memory cell; no move is
    required.

  \item \mintinline{haskellc}/toList/ (Figure~\ref{fig:schema-dlist-toList}) completes the UAmpar structure by plugging \emph{nil} into its hole with \mintinline{haskellc}/fill @'[]/ (whose individual behavior is presented in Figure~\ref{fig:schema-fillNil}) and removes the \mintinline{haskellc}/UAmpar/ wrapper as the structure is now complete, using \mintinline{haskellc}/unFromUAmpar'/.
\end{itemize}

To use this API safely, it is imperative that values of type \mintinline{haskellc}/UAmpar/ are used linearly. Otherwise we could first complete a difference list with \mintinline{haskellc}/l = toList i/, then add a newUAmpar cons cell with a hole to \mintinline{haskellc}/i/ with \mintinline{haskellc}/append i x/ (actually reusing the destination inside \mintinline{haskellc}/i/ for the second time). Doing that creates a hole inside \mintinline{haskellc}/l/, although it is of type \mintinline{haskellc}/[t]/ so we are allowed to pattern-match on it (so we might get a segfault)! The simplified API of Listing~\ref{table:impl-dlist} doesn't actually enforce the required linearity properties, I'll address that in Section~\ref{ssec:api-linearity}.

This implementation of difference list matches closely the intended memory behaviour, we can expect it to be more efficient than the functional encoding. We'll see in Section~\ref{sec:benchmark} that the prototype implementation presented in Section~\ref{sec:implementation} cannot yet demonstrate these performance improvements.

\subsection{Breadth-first tree traversal}\label{ssec:bf-tree-traversal}

Consider the problem, which Okasaki attributes to Launchbury~\cite{okasaki_bfs_2000}
\begin{quote}
  Given a tree $T$ , create a newUAmpar tree of the same
  shape, but with the values at the nodes replaced
  by the numbers $1\ldots|T|$ in breadth-first order.
\end{quote}

This problem admits a straightforward implementation if we're allowed
to mutate trees. Nevertheless, a pure implementation is quite
tricky~\cite{okasaki_bfs_2000,jones_gibbons_linearbfs_93} and a very
elegant, albeit very clever, solution was proposed
recently~\cite{gibbons_phases_2023}.



With destinations as first-class objects in our toolbelt, we can
implement a solution that is both easy to come up with and efficient,
doing only a single breadth-first traversal pass on the original
tree. The main idea is to keep a queue of pairs of a tree to be
relabeled and of the destination where the relabeled result is
expected (as destinations can be stored in arbitrary containers!) and
process each of them when their turn comes. The implementation
provided in Listing~\ref{table:impl-bfs-tree-traversal}, implements the
slightly more general \mintinline{haskellc}/mapAccumBFS/ which applies
on each node of the tree a relabeling function that can depend on a
state.

\begin{listing}[t]
\figtextsize
\begin{minted}{haskellc}
data Tree a = ¤Nil | ¤Node a (Tree a) (Tree a)

relabelDPS ⩴ Tree a → Tree Int
relabelDPS tree = fst (mapAccumBFS (\st _ → (st + 1, st)) 1 tree)

mapAccumBFS ⩴ ∀ a b s. (s → a → (s, b)) → s → Tree a → (Tree b, s)
mapAccumBFS f s0 tree =
  unFromUAmpar (    -- simplified newUAmparUAmpar signature w.r.t. Section 4
    newUAmparUAmpar `updWith` \dtree → go s0 (singleton (¤Ur tree, dtree)))
  where
    go ⩴ s → Queue (Ur (Tree a), UDest (Tree b)) ⊸ Ur s
    go st q = case dequeue q of
      ¤Nothing → ¤Ur st
      ¤Just ((utree, dtree), q') → case utree of
        ¤Ur ¤Nil → fill @'Nil dtree ; go st q'
        ¤Ur (¤Node x tl tr) → case fill @'Node dtree of
          (dy, dtl, dtr) →
            let q'' = q' `enqueue` (¤Ur tl, dtl) `enqueue` (¤Ur tr, dtr)
                (st', y) = f st x
              in fillLeaf y dy ; go st' q''
\end{minted}
\caption{Implementation of breadth-first tree traversal with destinations}
\label{table:impl-bfs-tree-traversal}
\end{listing}

Note that the signatures of \mintinline{haskellc}/mapAccumBFS/ and \mintinline{haskellc}/relabelDPS/ don't involve linear types. Linear types only appear in the inner loop \mintinline{haskellc}/go/, which manipulates destinations. Linearity enforces the fact that every destination ever put in the queue is eventually filled at some point, which guarantees that the output tree is complete after the function has run.

As the state-transforming function \mintinline{haskellc}/s → t → (s, u)/ is non-linear, the nodes of the original tree won't be used in a linear fashion. However, we want to store these nodes together with their accompanying destinations in a queue of pairs, and destinations used to construct the queue have to be used linearly (because of \mintinline{haskellc}/`updWith`/ signature, which initially gives the root destination). That forces the queue to be used linearly, so the pairs too, so pairs' components too. Thus, we wrap the nodes of the input tree in the \mintinline{haskellc}/Ur/ wrapper, whose linear consumption allows for unrestricted use of its inner value, as detailed in Section~\ref{sec:intro-linearity}.

This example shows how destinations can be used even in a non-linear setting in order to improve the expressiveness of the language. This more natural and less convoluted implementation of breadth-first traversal also presents great performance gains compared to the fancy functional implementation from~\cite{gibbons_phases_2023}, as detailed in Section~\ref{sec:benchmark}.

\subsection{Deserializing, lifetime, and garbage collection}\label{ssec:parser-sexpr}

In client-server applications, the following pattern is very frequent: the server receives a request from a client with a serialized payload, the server then deserializes the payload, runs some code, and respond to the request. Most often, the deserialized payload is kept alive for the entirety of the request handling. In a garbage collected language, there's a real cost to this: the garbage collector (GC) will traverse the deserialized payload again and again, although we know that all its internal pointers are live for the duration of the request.

Instead, we'd rather consider the deserialized payload as a single heap object, which doesn't need to be traversed, and is freed as a block. GHC supports this use-case with a feature named \emph{compact regions}~\cite{yang_efficient_2015}. Compact regions contain normal heap objects, but the GC never follows pointers into a compact region. The flipside is that a compact region can only be collected when all of the objects it contains are dead.

With compact regions, we would first deserialize the payload normally, in the GC heap, then copy it into a compact region and only keep a reference to the copy. That way, internal pointers of the region copy will never be followed by the GC, and that copy will be collected as a whole later on, whereas the original in the GC heap will be collected immediately.

However, we are still allocating two copies of the deserialized payload. This is wasteful, it would be much better to allocate directly in the region, but this isn't part of the original compact region API. Destinations are one way to accomplish this. In fact, as I'll explain in Section~\ref{sec:implementation}, my implementation of DPS for Haskell is backed by compact regions because they provide more freedom to do low-level memory operations without interfering with GC.

Given a payload serialized as S-expressions, let's see how using destinations and compact regions for the parser can lead to greater performance. S-expressions are parenthesized lists whose elements are separated by spaces. These elements can be of several types: int, string, symbol (a textual token with no quotes around it), or a list of other S-expressions.

Parsing an S-expression can be done naively with mutually recursive functions:
\begin{itemize}
  \item \mintinline{haskellc}/parseSExpr/ scans the next character, and either dispatches to \mintinline{haskellc}/parseSList/ if it encounters an opening parenthesis, or to \mintinline{haskellc}/parseSString/ if it encounters an opening quote, or eventually parses the string into a number or symbol;
  \item \mintinline{haskellc}/parseSList/ calls \mintinline{haskellc}/parseSExpr/ to parse the next token, and then calls itself again until reaching a closing parenthesis, accumulating the parsed elements along the way.
\end{itemize}

Only the implementation of \mintinline{haskellc}/parseSList/ will be presented here as it is enough for our purpose, but the full implementation of both the naive and destination-based versions of the whole parser can be found in \texttt{src/Compact/Pure/SExpr.hs} of~\cite{linear_dest} .

The implementation presented in Listing~\ref{table:impl-parser-naive} is quite standard: the accumulator \mintinline{haskellc}/acc/ collects the nodes that are returned by \mintinline{haskellc}/parseSExpr/ in the reverse order (because it's the natural building order for a linked list without destinations). When the end of the list is reached (line 5), the accumulator is reversed, wrapped in the \mintinline{haskellc}/¤SList/ constructor, and returned.

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExpr ⩴ ByteString → Int → Either Error SExpr
% parseSExpr bs i = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSList bs (i + 1) []
%     '"' → parseSString bs (i + 1) ¤False []
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%          in if null tok then parseSExpr bs (i + 1) else case parseInt tok of
%               ¤Just int → ¤Right (¤SInteger (i + length tok - 1) int)
%               ¤Nothing → ¤Right (¤SSymbol (i + length tok - 1) (toString tok))
% parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
% parseSList bs i acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → ¤Right (¤SList i (reverse acc))
%     | isSpace x → parseSList bs (i + 1) acc
%     | otherwise → case parseSExpr bs i of
%         ¤Left err → ¤Left err
%         ¤Right child → parseSList bs (endPos child + 1) (child : acc)
% parseSString ⩴ ByteString → Int → Bool → [Char] → Either Error SExpr
% parseSString bs i escape acc = case bs !? i of
%   ¤Nothing → ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → ¤Right (SString i (reverse acc))
%     '\\' | not escape → parseSString bs (i + 1) ¤True acc
%     'n'  | escape → parseSString bs (i + 1) ¤False ('\n' : acc)
%     _ → parseSString bs (i + 1) ¤False (x : acc)
% \end{minted}
% \caption{Implementation of the S-expression parser without destinations}
% \label{table:impl-sexpr-parser-without-dest}
% \end{listing}

% \begin{listing}[t]
% \figtextsize
% \begin{minted}[linenos,escapeinside=°°]{haskellc}
% parseSExprDPS ⩴ ByteString → Int → UDest SExpr ⊸ Either Error Int
% parseSExprDPS bs i d = case bs !? i of
%   ¤Nothing → °\\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedEOFSExpr i)
%   ¤Just x → case x of
%     ')' → °\\mnew{fillLeaf defaultSExpr d}° ; ¤Left (¤UnexpectedClosingParen i)
%     '(' → parseSListDPS bs (i + 1) °\\mnew{(fill @'SList d)}°
%     '"' → parseSStringDPS bs (i + 1) ¤False °\\mnew{(fill @'SString d)}°
%     _ → let tok = extractNextToken bs i -- take chars until delimiter/space
%         in if null tok then parseSExprDPS bs (i + 1) d else case parseInt tok of
%               ¤Just int → let °\\mnew{!dint = fill @'SInteger d}°
%                           in °\\mnew{fillLeaf int dint}° ; ¤Right (i + length tok - 1)
%               _ → let °\\mnew{!dsym = fill @'SSymbol d}°
%                    in °\\mnew{fillLeaf (toString tok) dsym}° ; ¤Right (i + length tok - 1)
% parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
% parseSListDPS bs i d = case bs !? i of
%   ¤Nothing → °\\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSList i)
%   ¤Just x → if
%     | x == ')' → °\\mnew{fill @'[] d}° ; ¤Right i
%     | isSpace x → parseSListDPS bs (i + 1) d
%     | otherwise → let !(dh, dt) = °\\mnew{fill @'(:) d}°
%                    in case parseSExprDPS bs i °\\mnew{dh}° of
%                         ¤Left err → fill @'[] dt ; ¤Left err
%                         ¤Right endPos → parseSListDPS bs (endPos + 1) °\\mnew{dt}°
% parseSStringDPS ⩴ ByteString → Int → Bool → UDest [Char] ⊸ Either Error Int
% parseSStringDPS bs i escape d = case bs !? i of
%   ¤Nothing → °\\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSString i)
%   ¤Just x → case x of
%     '"'  | not escape → °\\mnew{fill @'[] d}° ; ¤Right i
%     '\\' | not escape → parseSStringDPS bs (i + 1) ¤True d
%     'n'  | escape → let °\\mnew{!(dh, dt) = fill @'(:) d}°
%                      in °\\mnew{fillLeaf '\textbackslash{}n' dh}° ; parseSStringDPS bs (i + 1) ¤False °\\mnew{dt}°
%     _ → let °\\mnew{!(dh, dt) = fill @'(:) d}°
%          in °\\mnew{fillLeaf x dh}° ; parseSStringDPS bs (i + 1) ¤False °\\mnew{dt}°
% \end{minted}
% \caption{Implementation of the S-expression parser with destinations}
% \label{table:impl-sexpr-parser-with-dest}
% \end{listing}

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSList ⩴ ByteString → Int → [SExpr] → Either Error SExpr
parseSList bs i acc = case bs !? i of
  ¤Nothing → ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → ¤Right (¤SList i (reverse acc))
    | isSpace x → parseSList bs (i + 1) acc
    | otherwise → case parseSExpr bs i of
        ¤Left err → ¤Left err
        ¤Right child → parseSList bs (endPos child + 1) (child : acc)
\end{minted}
\caption{Implementation of the S-expression parser without destinations}
\label{table:impl-parser-naive}
\end{listing}

\begin{listing}[b]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parseSListDPS ⩴ ByteString → Int → UDest [SExpr] ⊸ Either Error Int
parseSListDPS bs i d = case bs !? i of
  ¤Nothing → °\\mnew{fill @'[] d}° ; ¤Left (¤UnexpectedEOFSList i)
  ¤Just x → if
    | x == ')' → °\\mnew{fill @'[] d}° ; ¤Right i
    | isSpace x → parseSListDPS bs (i + 1) d
    | otherwise →
        case °\\mnew{fill @'(:) d}° of
          (dh, dt) → case parseSExprDPS bs i °\\mnew{dh}° of
              ¤Left err → fill @'[] dt ; ¤Left err
              ¤Right endPos → parseSListDPS bs (endPos + 1) °\\mnew{dt}°
\end{minted}
\caption{Implementation of the S-expression parser with destinations}
\label{table:impl-parser-dps}
\end{listing}

We will see that destinations can bring very significative performance gains with only very little stylistic changes in the code. Accumulators of tail-recursive functions just have to be changed into destinations. Instead of writing elements into a list that will be reversed at the end as we did before, the program in the destination style will directly write the elements into their final location.

Code for \mintinline{haskellc}/parseSListDPS/ is presented in Listing~\ref{table:impl-parser-dps}. Let's see what changed compared to the naive implementation:

\begin{itemize}
  \item even for error cases, we are forced to consume the destination that we receive as an argument (to stay linear), hence we write some sensible default data to it (see line 3);
  \item the \mintinline{haskellc}/SExpr/ value resulting from \mintinline{haskellc}/parseSExprDPS/ is not collected by \mintinline{haskellc}/parseSListDPS/ but instead written directly into its final location by \mintinline{haskellc}/parseSExprDPS/ through the passing and filling of destination \mintinline{haskellc}/dh/ (see line 9);
  \item adding an element of type \mintinline{haskellc}/SExpr/ to the accumulator \mintinline{haskellc}/[SExpr]/ is replaced with adding a newUAmpar cons cell with \mintinline{haskellc}/fill @'(:)/ into the hole represented by \mintinline{haskellc}/UDest [SExpr]/, writing an element to the \emph{head} destination, and then doing a recursive call with the \emph{tail} destination passed as an argument (which has type \mintinline{haskellc}/UDest [SExpr]/ again);
  \item instead of reversing and returning the accumulator at the end of the processing, it is enough to complete the list by writing a nil element to the tail destination (with \mintinline{haskellc}/fill @'[]/, see line 5), as the list has been built in a top-down approach;
  \item DPS functions return the offset of the next character to read instead of a parsed value.
\end{itemize}

Thanks to that newUAmpar implementation which is barely longer (in terms of lines of code) than the naive one, the program runs almost twice as fast, mostly because garbage-collection time goes to almost zero. The detailed benchmark is available in Section~\ref{sec:benchmark}.

\section{API Design}\label{sec:api}

Table~\ref{table:destination-api} presents my pure API for functional DPS programming. This API is sufficient to implement all the examples of Section~\ref{sec:motivating-examples}. This section explains its various parts in detail.

\begin{listing}[t]
\figtextsize
\begin{minted}{haskellc}
data Token
consume   ⩴      Token ⊸ ()
dup2      ⩴      Token ⊸ (Token, Token)
withToken ⩴ ∀ a. (Token ⊸ Ur a) ⊸ Ur a

data UAmpar a b
updWith                ⩴ ∀ a b c. UAmpar a b ⊸ (b ⊸ c) ⊸ UAmpar b c
newUAmparUAmpar               ⩴ ∀ a.     Token ⊸ UAmpar a (UDest a)
toUAmpar      ⩴ ∀ a.     Token ⊸ a → UAmpar a ()
fromUAmpar'     ⩴ ∀ a.     UAmpar a () ⊸ Ur a
fromUAmpar      ⩴ ∀ a b.   UAmpar a (Ur c) ⊸ Ur (a, c)

data UDest a
type family UDestsOf lCtor a -- returns dests associated to fields of constructor
fill     ⩴ ∀ lCtor a. UDest a ⊸ UDestsOf lCtor a
fillComp ⩴ ∀ a b.     UAmpar a b ⊸ UDest a ⊸ b
fillLeaf ⩴ ∀ a.       a → UDest a ⊸ ()
\end{minted}
% unFromUAmpar' ⩴ ∀ a.     UAmpar a () ⊸ a
% unFromUAmpar  ⩴ ∀ a b.   UAmpar a (Ur c) ⊸ (a, c)
\caption{Destination API for Haskell}
\label{table:destination-api}
\end{listing}

\subsection{The \texttt{UAmpar} type}

The main design principle behind DPS structure building is that no structure can be read before all its destinations have been filled. That way, UAmpar data structures can be freely passed around and stored, but need to be completed before any pattern-matching can be made on them.

Hence we introduce a newUAmpar data type \mintinline{haskellc}/UAmpar s t/ where \mintinline{haskellc}/s/ stands for the type of the structure being built, and \mintinline{haskellc}/t/ is the type of what needs to be linearly consumed before the structure can be read. The idea is that one can map over the right side, which will contain destinations or containers with destinations inside, until there is no destination left but just a non-linear value that can safely escape (e.g. \mintinline{haskellc}/()/, \mintinline{haskellc}/Int/, or something wrapped in \mintinline{haskellc}/Ur/). When destinations from the right side are consumed, the structure on the left side is built little by little in a top-down fashion, as we showed in Figures~\ref{fig:schema-dlist-append} and \ref{fig:schema-dlist-concat}. And when no destination remains on the right side, the value of type \mintinline{haskellc}/s/ no longer has holes, thus is ready to be released/read.

It can be released in two ways: with \mintinline{haskellc}/fromUAmpar'/, the value on the \mintinline{haskellc}/t/ side must be unit (\mintinline{haskellc}/()/), and just the complete \mintinline{haskellc}/s/ is returned, wrapped in \mintinline{haskellc}/Ur/. With \mintinline{haskellc}/fromUAmpar/, the type on the \mintinline{haskellc}/t/ side must be of the form \mintinline{haskellc}/Ur t'/, and then a pair \mintinline{haskellc}/Ur (s, t')/ is returned.

It is actually safe to wrap the structure that has been built in \mintinline{haskellc}/Ur/ because its leaves either come from non-linear sources (as \mintinline{haskellc}/fillLeaf ⩴ t → UDest t ⊸ ()/ consumes its first argument non-linearly) or are made of 0-ary constructors added with \mintinline{haskellc}/fill/, both of which can be used in an unrestricted fashion safely. Variants \mintinline{haskellc}/unFromUAmpar'/ and \mintinline{haskellc}/unFromUAmpar/ from the beginning of this article just drop the \mintinline{haskellc}/Ur/ wrapper.

Conversely, the function \mintinline{haskellc}/toUAmpar/ takes a non-linear argument of type \mintinline{haskellc}/s/ and wraps it into an \mintinline{haskellc}/UAmpar/ with no destinations left to be consumed.

\subsection{Ensuring write-once model for holes with linear types}\label{ssec:api-linearity}

Types aren't linear by themselves in Linear Haskell. Instead, functions can be made to use their arguments linearly or not. So in direct style, where the consumer of a resource isn't tied to the resource creation site, there is no way to state that the resource must be used exactly once:

\begin{unbreakable}
{\figtextsize
\begin{minted}{haskellc}
createR           ⩴ Resource -- no way to force the result to be used exactly once
consumeR          ⩴ Resource ⊸ ()
exampleShouldFail ⩴ () =      
  let x = createR in consumeR x ; consumeR x -- valid even if x is consumed twice
\end{minted}
}
\end{unbreakable}

The solution is to force the consumer of a resource to become explicit at the creation site of the resource, and to check through its signature that it is indeed a linear continuation:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
withR       ⩴ (Resource ⊸ a) ⊸ a
consumeR    ⩴ Resource ⊸ ()
exampleFail ⩴ () = withR (\x → consumeR °\mold{x}° ; consumeR °\mold{x}°) -- not linear
\end{minted}
}
\end{unbreakable}

The \mintinline{haskellc}/Resource/ type is in positive position in the signature of \mintinline{haskellc}/withR/, so that the function should somehow know how to produce a \mintinline{haskellc}/Resource/, but this is opaque for the user. What matters is that a resource can only be accessed by providing a linear continuation to \mintinline{haskellc}/withR/.

Still, this is not enough; because \mintinline{haskellc}/\x → x/ is indeed a linear continuation, one could use \mintinline{haskellc}/withR (\x → x)/ to leak a \mintinline{haskellc}/Resource/, and then use it in a non-linear fashion in the outside world. Hence we must forbid the resource from appearing anywhere in the return type of the continuation. To do that, we ask the return type to be wrapped in \mintinline{haskellc}/Ur/: because the resource comes from the left of a linear arrow, and doesn't implement \mintinline{haskellc}/Movable/, it cannot be wrapped in \mintinline{haskellc}/Ur/ without breaking linearity (see Section~\ref{sec:intro-linearity}). On the other hand, a \mintinline{haskellc}/Movable/ value of type \mintinline{haskellc}/()/ or \mintinline{haskellc}/Int/ can be returned:
\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
withR'       ⩴ (Resource ⊸ Ur a) ⊸ Ur a
consumeR     ⩴ Resource ⊸ ()
exampleOk'   ⩴ Ur ()       = withR' (\x → let u ⩴ () = consumeR x' in move u)
exampleFail' ⩴ Ur Resource = withR' (\x → °\mold{¤Ur x}°) -- not linear
\end{minted}
}
\end{unbreakable}

This explicit \emph{scope function} trick will no longer be necessary when linear constraints will land in GHC (see \cite{spiwack_linearly_2022}). In the meantime, this principle has been used to ensure safety of the DPS implementation in Haskell.

% \mintinline{haskellc}/UAmpar s t/ has a linear functor instance to map on the \mintinline{haskellc}/t/ side (the one carrying destinations) which forces the continuation to be linear:

% {\figtextsize
% \begin{minted}[escapeinside=°°]{haskellc}
% instance Functor (UAmpar a) where
%   fmap ⩴ ∀ b c. (b ⊸ c) ⊸ UAmpar a b ⊸ UAmpar b c
%   fmap f (¤UAmpar (x, d)) = ¤UAmpar (x, f d)
% \end{minted}
% }

% And \mintinline{haskellc}/newUAmpar ⩴ ∀ s. Token ⊸ UAmpar s (UDest s)/` is the only function in which a \mintinline{haskellc}/UDest/ appears in positive position, but locked by an \mintinline{haskellc}/UAmpar/ (which is an opaque wrapper for the user). So destinations can only ever be accessed by mapping over an \mintinline{haskellc}/UAmpar/ with \mintinline{haskellc}/fmap//\mintinline{haskellc}/`updWith`/, and cannot leak to the outside. It isn't possible either for a \mintinline{haskellc}/UDest t/ to be linearly consumed by filling another \mintinline{haskellc}/UDest (UDest t)/ with \mintinline{haskellc}/fillLeaf/, as the first argument of the \mintinline{haskellc}/fillLeaf/ function isn't used linearly.\footnote{It would actually be desirable to have \mintinline{haskellc}/UDest (UDest t)/ work. But it turns out that doing so naively compromises the type safety properties related to linearity that we describe in this section. How to recover type safety in presence of destinations of destinations is still an open problem.}

% Morally, this linear \mintinline{haskellc}/Functor/ instance says that one can temporary forget about the root of the structure being built, and just manipulate the destinations as first-class objects that will produce remote building effects onto the structure that is invisible in the inner scope.

\paragraph{Ensuring linear use of \texttt{UAmpar} objects}

If an \mintinline{haskellc}/UAmpar/ object is used linearly, then its destinations will be written to exactly once; this is ensured by the signature of \mintinline{haskellc}/updWith/ for \mintinline{haskellc}/UAmpar/s. So we need to ensure that \mintinline{haskellc}/UAmpar/ objects are used linearly. For that, we introduce a newUAmpar type \mintinline{haskellc}/Token/. A token can be linearly exchanged one-for-one with an \mintinline{haskellc}/UAmpar/ of any type with \mintinline{haskellc}/newUAmpar/`, linearly duplicated with \mintinline{haskellc}/dup2/, or linearly deleted with \mintinline{haskellc}/consume/. However, it cannot be linearly stored in \mintinline{haskellc}/Ur/ as it doesn't implement \mintinline{haskellc}/Movable/.

As in the example above, we just ensure that \mintinline{haskellc}/withToken ⩴ (Token ⊸ Ur t) ⊸ Ur t/ is the only source of \mintinline{haskellc}/Token/s around. Now, to produce an \mintinline{haskellc}/UAmpar/, one must get a token first, so has to be in the scope of a continuation passed to \mintinline{haskellc}/withToken/. Putting either a \mintinline{haskellc}/Token/ or \mintinline{haskellc}/UAmpar/ in \mintinline{haskellc}/Ur/ inside the continuation would make it non-linear. So none of them can escape the scope as is, but a structure built from an \mintinline{haskellc}/UAmpar/ and finalized with \mintinline{haskellc}/fromUAmpar/ would be automatically wrapped in \mintinline{haskellc}/Ur/, thus could safely escape\footnote{This is why the \mintinline{haskellc}/unFromUAmpar/ and \mintinline{haskellc}/unFromUAmpar'/ variants aren't that useful in the actual memory-safe API (which differs slightly from the simplified examples of Section~\ref{sec:motivating-examples}): here the built structure would be stuck in the scope function without its \mintinline{haskellc}/Ur/ escape pass.}.

\subsection{Filling functions for destinations}

The last part of the API is the one in charge of actually building the structures in a top-down fashion. To fill a hole represented by \mintinline{haskellc}/UDest t/, three functions are available:

\mintinline{haskellc}/fillLeaf ⩴ ∀ t. t → UDest t ⊸ ()/ uses a value of type \mintinline{haskellc}/t/ to fill the hole represented by the destination. The destination is consumed linearly, but the value to fill the hole isn't (as indicated by the first non-linear arrow). Memory-wise, the address of the object \mintinline{haskellc}/t/ is written into the memory cell pointed to by the destination (see Figure~\ref{fig:schema-fillLeaf}).

\mintinline{haskellc}/fillComp ⩴ ∀ s t. UAmpar s t ⊸ UDest s ⊸ t/ is used to plug two \mintinline{haskellc}/UAmpar/ objects together. The target \mintinline{haskellc}/UAmpar/ isn't represented in the signature of the function. Instead, only the target hole that will receive the address of the child is represented by \mintinline{haskellc}/UDest s/; and \mintinline{haskellc}/UAmpar s t/ in the signature refers to the child object. A call to \mintinline{haskellc}/fillComp/ always takes place in the scope of \mintinline{haskellc}/`updWith`/ over the parent object:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
parent ⩴ UAmpar BigStruct (UDest SmallStruct, UDest OtherStruct)
child ⩴ UAmpar SmallStruct (UDest Int)
comp = parent `updWith` \(ds, extra) → fillComp child ds
       ⩴ UAmpar BigStruct (UDest Int, UDest OtherStruct)
\end{minted}
}
\end{unbreakable}

The resulting structure \mintinline{haskellc}/comp/ is morally a \mintinline{haskellc}/BigStruct/ like \mintinline{haskellc}/parent/, that inherited the hole from the child structure (\mintinline{haskellc}/UDest Int/) and still has its other hole (\mintinline{haskellc}/UDest OtherStruct/) to be filled. An example of memory behavior of \mintinline{haskellc}/fillComp/ in action can be seen in Figure~\ref{fig:schema-dlist-concat}.

\mintinline{haskellc}/fill ⩴ ∀ lCtor t. UDest t ⊸ UDestsOf lCtor t/ lets us build structures using layers of hollow constructors. It takes a constructor as a type parameter (\mintinline{haskellc}/lCtor/) and allocates a hollow heap object that has the same header/tag as the specified constructor but unspecified fields. The address of the allocated hollow constructor is written in the destination that is passed to \mintinline{haskellc}/fill/. As a result, one hole is now filled, but there is one newUAmpar hole in the structure for each field left unspecified in the hollow constructor that is now part of the bigger structure. So \mintinline{haskellc}/fill/ returns one destination of matching type for each of the fields of the constructor. An example of the memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/ is given in Figure~\ref{fig:schema-fillCons} and the one of \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/ is given in Figure~\ref{fig:schema-fillNil}.

\mintinline{haskellc}/UDestsOf/ is a type family (i.e. a function operating on types) whose role is to map a constructor to the type of destinations for its fields. For example, \mintinline{haskellc}/UDestsOf '[] [t] = ()/ and \mintinline{haskellc}/UDestsOf '(:) [t] = (UDest t, UDest [t])/. More generally, there is a duality between the type of a constructor \mintinline[escapeinside=°°]{haskellc}/¤Ctor ⩴ (¤f°$_1\ldots\,$°¤f°$_n$°) → t/ and of the associated destination-filling functions \mintinline[escapeinside=°°]{haskellc}/fill @'Ctor ⩴ UDest t ⊸ (UDest ¤f°$_1\ldots\,$°UDest ¤f°$_n$°)/. Destination-based data building can be seen as more general than the usual bottom-up constructor approach, as we can recover \mintinline{haskellc}/¤Ctor/ from the associated function \mintinline[escapeinside=°°]{haskellc}/fill @'Ctor/, but not the reverse:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
¤Ctor ⩴ (¤f°$_1\ldots\,$°¤f°$_n$°) → a
¤Ctor (x°$_1\ldots\,$°x°$_n$°) = unFromUAmpar' (
  newUAmparUAmpar `updWith` \(d ⩴ UDest a) → case fill @'Ctor d of
    (dx°$_1\ldots\,$°dx°$_n$°) → fillLeaf x°$_1$° dx°$_1$° ; °$\ldots\,$° ; fillLeaf x°$_n$° dx°$_n$°)
\end{minted}
}
\end{unbreakable}

\begin{figure}[t]\centering
  \scalebox{\figscale}{\tikzfig{schemas/fillCons}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'(:) ⩴ UDest [t] ⊸ (UDest t, UDest [t])/}
  \label{fig:schema-fillCons}

  \scalebox{\figscale}{\tikzfig{schemas/fillNil}}
  \caption{Memory behavior of \mintinline{haskellc}/fill @'[] ⩴ UDest [t] ⊸ ()/}
  \label{fig:schema-fillNil}

  \scalebox{\figscale}{\tikzfig{schemas/fillLeaf}}
  \caption{Memory behavior of \mintinline{haskellc}/fillLeaf ⩴ t → UDest [t] ⊸ ()/}
  \label{fig:schema-fillLeaf}
\end{figure}

\section{Implementing destinations in Haskell}\label{sec:implementation}

Having UAmpar structures in the memory inherently introduces a lot of tension with both the garbage collector and compiler. Indeed, the GC assumes that every heap object it traverses is well-formed, whereas UAmpar structures are absolutely ill-formed: they contain uninitialized pointers, which the GC should absolutely not follow.

The tension with the compiler is of lesser extent. The compiler can make some optimizations because it assumes that every object is immutable, while DPS programming breaks that guarantee by mutating constructors after they have been allocated (albeit only one update can happen). Fortunately, these errors are easily detected when implementing the API, and fixed by asking GHC not to inline specific parts of the code (with pragmas).

\subsection{Compact Regions}\label{ssec:impl-compact-regions}

As I teased in Section~\ref{ssec:parser-sexpr}, \emph{compact regions} from~\cite{yang_efficient_2015} make it very convenient to implement DPS programming in 
Haskell. A compact region represents a memory area in the Haskell heap that is almost fully independent from the GC and the rest of the garbage-collected heap. For the GC, each compact region is seen as a single heap object with a single lifetime. The GC can efficiently check whether there is at least one pointer in the garbage-collected heap that points into the region, and while this is the case, the region is kept alive. When this condition is no longer matched, the whole region is discarded. The result is that the GC won't traverse any node from the region: it is treated as one opaque block (even though it is actually implemented as a chain of blocks of the same size, that doesn't change the principle). Also, compact regions are immobile in memory; the GC won't move them, so a destination can just be implemented as a raw pointer (type \mintinline{haskellc}/Addr#/ in Haskell): \mintinline{haskellc}/data UDest r t = ¤UDest Addr#/

By using compact regions to implement DPS programming, we completely elude the concerns of tension between the garbage collector and UAmpar structures we want to build. Instead, we get two extra restrictions. First, every structure in a region must be in a fully-evaluated form. Regions are strict, and a heap object that is copied to a region is first forced into normal form. This might not always be a win; sometimes laziness, which is the default \emph{modus operandi} of the garbage-collected heap, might be preferable.

Secondly, data in a region cannot contain pointers to the garbage-collected heap, or pointers to other regions: it must be self-contained. That forces us to slightly modify the API, to add a phantom type parameter \mintinline{haskellc}/r/ which tags each object with the identifier of the region it belongs to. There are two related consequences: \mintinline{haskellc}/fillLeaf/ has to copy each \emph{leaf} value from the garbage-collected heap into the region in which it will be used as a leaf; and \mintinline{haskellc}/fillComp/ can only plug together two \mintinline{haskellc}/UAmpar/s that come from the same region.

A typeclass \mintinline{haskellc}/Region r/ is also needed to carry around the details about a region that are required for the implementation. This typeclass has a single method \mintinline{haskellc}/reflect/, not available to the user, that returns the \mintinline{haskellc}/RegionInfo/ structure associated to identifier \mintinline{haskellc}/r/.

The \mintinline{haskellc}/withRegion/ function is the newUAmpar addition to the modified API presented in Listing~\ref{table:destination-api-regions} (the \mintinline{haskellc}/Token/ type and its associated functions \mintinline{haskellc}/dup2/ and \mintinline{haskellc}/consume/ are unchanged). \mintinline{haskellc}/withRegion/ is mostly a refinement over the \mintinline{haskellc}/withToken/ function from Listing~\ref{table:destination-api}. It receives a continuation in which \mintinline{haskellc}/r/ must be a free type variable. It then spawns both a newUAmpar compact region and a fresh type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ (not a variable), and uses the \mintinline{text}/reflection/ library to provide an instance of \mintinline[escapeinside=°°]{haskellc}/Region °\muline{r}°/ on-the-fly that links \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/ and the \mintinline{haskellc}/RegionInfo/ for the newUAmpar region, and calls the continuation at type \mintinline[escapeinside=°°]{haskellc}/°\muline{r}°/. This is fairly standard practice since~\cite{launchbury_lazy_1994}.

\begin{listing}[t]
\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
type Region r ⩴ Constraint
°\\mnew{withRegion ⩴ ∀ a. (∀ r. Region r ⇒ Token ⊸ Ur a) ⊸ Ur a}°

data UAmpar r a b
updWith            ⩴ ∀ r a b c. UAmpar r a b ⊸ (b ⊸ c) ⊸ UAmpar r b c
newUAmparUAmpar           ⩴ ∀ r a.     Region r ⇒ Token ⊸ UAmpar r a (UDest r a)
toUAmpar  ⩴ ∀ r a.     Region r ⇒ Token ⊸ a → UAmpar r a ()
fromUAmpar' ⩴ ∀ r a.     Region r ⇒ UAmpar r a () ⊸ Ur a
fromUAmpar  ⩴ ∀ r a b.   Region r ⇒ UAmpar r a (Ur c) ⊸ Ur (a, c)

data UDest r a
type family UDestsOf lCtor r a
fill     ⩴ ∀ lCtor r a. Region r ⇒ UDest r a ⊸ UDestsOf lCtor r a
fillComp ⩴ ∀ r a b.     Region r ⇒ UAmpar r a b ⊸ UDest r a ⊸ b
fillLeaf ⩴ ∀ r a.       Region r ⇒ a → UDest r a ⊸ ()
\end{minted}
\caption{Destination API using compact regions}
\label{table:destination-api-regions}

\medskip

\centering
  \scalebox{\figscale}{\tikzfig{schemas/alloc-region}}
  \captionof{figure}{Memory behaviour of \mintinline{haskellc}/newUAmpar/` and \mintinline{haskellc}/toUAmpar/ in the region implementation}
  \label{fig:schema-alloc-region}
\end{listing}

\subsection{Representation of \texttt{UAmpar} objects}

Ideally, as we detailed in the API, we want \mintinline{haskellc}/UAmpar r s t/ to contains an \mintinline{haskellc}/s/ and a \mintinline{haskellc}/t/, and let the \mintinline{haskellc}/s/ free when the \mintinline{haskellc}/t/ is fully consumed (or linearly transformed into \mintinline{haskellc}/Ur t'/). So the most straightforward implementation for \mintinline{haskellc}/UAmpar/ would be a pair \mintinline{haskellc}/(s, t)/, where \mintinline{haskellc}/s/ in the pair is only partially complete.

It is also natural for \mintinline{haskellc}/newUAmpar/` to return an \mintinline{haskellc}/UAmpar r s (UDest s)/: there is nothing more here than an empty memory cell (named \emph{root receiver}) of type \mintinline{haskellc}/s/ which the associated destination of type \mintinline{haskellc}/UDest s/ points to, as presented in Figure~\ref{fig:schema-alloc}. A bit like the identity function, whatever goes in the hole is exactly what will be retrieved in the \mintinline{haskellc}/s/ side.

If \mintinline{haskellc}/UAmpar r s t/ is represented by a pair \mintinline{haskellc}/(s, t)/, then the root receiver should be the first field of the pair. However, the root receiver must be in the region, otherwise the GC might follow the garbage pointer that lives inside; whereas the \mintinline{haskellc}/UAmpar/ wrapper must be in the garbage-collected heap so that it can sometimes be optimized away by the compiler, and always deallocated as soon as possible.

One potential solution is to represent \mintinline{haskellc}/UAmpar r s t/ by a pair \mintinline{haskellc}/(Ur s, t)/ where \mintinline{haskellc}/Ur/ is allocated inside the region and its field \mintinline{haskellc}/s/ serves as the root receiver. With this approach, the issue of \mintinline{haskellc}/newUAmpar/` representation is solved, but every \mintinline{haskellc}/UAmpar/ will now allocate a few words in the region (to host the \mintinline{haskellc}/Ur/ constructor) that won't be collected by the GC for a long time even if the parent \mintinline{haskellc}/UAmpar/ is collected. This makes \mintinline{haskellc}/toUAmpar/ quite inefficient memory-wise too, as the \mintinline{haskellc}/Ur/ wrapper is useless for already complete structures.

The desired outcome is to only allocate a root receiver in the region for actual UAmpar structures, and skip that allocation for already complete structures that are turned into an \mintinline{haskellc}/UAmpar/ object, while preserving a same type for both use-cases. This is made possible by replacing the \mintinline{haskellc}/Ur/ wrapper inside the \mintinline{haskellc}/UAmpar/ by an indirection object (\mintinline{haskellc}/stg_IND/ label) for the actually-UAmpar case. \mintinline{haskellc}/UAmpar r s t/ will be represented by a pair \mintinline{haskellc}/(s, t)/ allocated in the garbage-collected heap, with slight variations as illustrated in Figure~\ref{fig:schema-alloc-region}:
\begin{itemize}
  \item in the pair \mintinline{haskellc}/(s, t)/ returned by \mintinline{haskellc}/newUAmpar/`, the \mintinline{haskellc}/s/ side points to an indirection object (a sort of constructor with one field, whose resulting type \mintinline{haskellc}/s/ is the same as the field type \mintinline{haskellc}/s/), that is allocated in the region, and serves as the root receiver;
  \item in the pair \mintinline{haskellc}/(s, t)/ returned by \mintinline{haskellc}/toUAmpar/, the \mintinline{haskellc}/s/ side directly points to the object of type \mintinline{haskellc}/s/ that has been copied to the region.
\end{itemize}

The implementation of \mintinline{haskellc}/fromUAmpar'/ is then relatively straightforward. It allocates a hollow \mintinline{haskellc}/¤Ur □/ in the region, writes the address of the complete structure into it, and returns the \mintinline{haskellc}/¤Ur/ (an alternative would have been to use a regular \mintinline{haskellc}/¤Ur/ allocated in the GC heap).

\subsection{Deriving \texttt{fill} for all constructors with \texttt{Generics}}\label{ssec:impl-generics}

The \mintinline{haskellc}/fill @lCtor @r @t/ function should plug a newUAmpar hollow constructor \mintinline{haskellc}/¤Ctor □ ⩴ t/ into the hole of an existing UAmpar structure, and return one destination object per newUAmpar hole in the structure (corresponding to the unspecified fields of the newUAmpar hollow constructor). Naively, we would need one \mintinline{haskellc}/fill/ function per constructor, but that cannot be realistically implemented. Instead, we have to generalize all \mintinline{haskellc}/fill/ functions into a typeclass \mintinline{haskellc}/Fill lCtor t/, and derive an instance of the typeclass (i.e. implement \mintinline{haskellc}/fill/) generically for any constructor, based only on statically-known information about that constructor.

In Section~\ref{ssec:impl-ghc}, we will see how to allocate a hollow heap object for a specified constructor (which is known at compile-time). The only other information we need to implement \mintinline{haskellc}/fill/ generically is the shape of the constructor, and more precisely the number and type of its fields. So we will leverage \mintinline{haskellc}/GHC.Generics/ to find the required information.

\mintinline{haskellc}/GHC.Generics/ is a built-in Haskell library that provides compile-time inspection of a type metadata through the \mintinline{haskellc}/Generic/ typeclass: list of constructors, their fields, memory representation, etc. And that typeclass can be derived automatically for any type! Here's, for example, the \mintinline{haskellc}/Generic/ representation of \mintinline{haskellc}/Maybe t/:

\begin{unbreakable}
{\figtextsize
\begin{minted}[linenos,escapeinside=°°]{haskellc}
repl> :k! Rep (Maybe a) () -- display the Generic representation of Maybe a
M1 D (MetaData "Maybe" "GHC.Maybe" "base" False) (
  M1 C (MetaCons "¤Nothing" PrefixI False) U1
  :+: M1 C (MetaCons "¤Just" PrefixI False) (M1 S ¤[...¤] (K1 R a)))
\end{minted}
}
\end{unbreakable}

We see that there are two different constructors (indicated by \mintinline{haskellc}/M1 C .../ lines): \mintinline{haskellc}/¤Nothing/ has zero fields (indicated by \mintinline{haskellc}/U1/) and \mintinline{haskellc}/¤Just/ has one field of type \mintinline{haskellc}/t/ (indicated by \mintinline{haskellc}/K1 R t/).

With a bit of type-level programming\footnote{see \texttt{src/Compact/Pure/Internal.hs:418} in~\cite{linear_dest}}, we can extract the parts of that representation which are related to the constructor \mintinline{haskellc}/lCtor/ and use them inside the instance head of \mintinline{haskellc}/Fill lCtor t/ so the implementation of \mintinline{haskellc}/fill/ can depend on them. That's how we can give the proper types to the destinations returned by that function for a specified constructor. The \mintinline{haskellc}/UDestsOf lCtor t ⩴ Type/ type family also uses the generic representation of \mintinline{haskellc}/t/ to extract what it needs to know about \mintinline{haskellc}/lCtor/ and its fields.

\subsection{Changes to GHC internals and RTS}\label{ssec:impl-ghc}

We will see here how to allocate a hollow heap object for a given constructor, but let's first take a detour to give more context about the internals of the compiler.

Haskell's runtime system (RTS) is written in a mix of C and C-{}-. The RTS has many roles, among which managing threads, organizing garbage collection or managing compact regions. It also defines various primitive operations, named \emph{external primops}, that expose the RTS capabilities as normal functions. Despite all its responsibilities, however, the RTS is not responsible for the allocation of normal constructors (built in the garbage-collected heap). One reason is that it doesn't have all the information needed to build a constructor heap object, namely, the info table associated to the constructor.

The info table is what defines both the layout and behavior of a heap object. All heap objects representing a same constructor (let's say \mintinline{haskellc}/¤Just/) have the same info table, even when the associated types are different (e.g. \mintinline{haskellc}/Maybe Int/ and \mintinline{haskellc}/Maybe Bool/). Heap objects representing this constructor point to a label \mintinline{text}/<ctor>_con_info/ that will be later resolved by the linker into an actual pointer to the shared info table.

The RTS is in fact a static piece of code that is compiled once when GHC is built. So the RTS has no direct way to access the information emitted during the compilation of a program. In other words, when the RTS runs, it has no way to inspect the program that it runs and info table labels have long been replaced by actual pointers so it cannot find them itself. But it is the one which knows how to allocate space inside a compact region.

As a result, I need to add two newUAmpar primitives to GHC to allocate a hollow constructor:

\begin{itemize}
\item one \emph{external primop} to allocate space inside a compact region for a hollow constructor. This primop has to be implemented inside the RTS for the aforementioned reasons;
\item one \emph{internal primop} (internal primops are macros which generates C-{}- code) that will be resolved into a normal albeit static value representing the info table pointer of a given constructor. This value will be passed as an argument to the external primop.
\end{itemize}

All the alterations to GHC that will be showed here are available in full form in~\cite{custom_ghc}.

\paragraph{External primop: allocate a hollow constructor in a region}

The implementation of the external primop is presented in Listing~\ref{table:impl-compactAddHollow}. The \mintinline{c}/stg_compactAddHollowzh/ function (whose equivalent on the Haskell side is \mintinline{haskellc}/compactAddHollow#/) is mostly a glorified call to the \mintinline{haskellc}/ALLOCATE/ macro defined in the \mintinline{text}/Compact.cmm/ file, which tries to do a pointer-bumping allocation in the current block of the compact region if there is enough space, and otherwise add a newUAmpar block to the region.

As announced, this primop takes the info table pointer of the constructor to allocate as its second parameter (\mintinline{c}/W_ info/) because it cannot access that information itself. The info table pointer is then written to the first word of the heap object in the call to \mintinline{c}/SET_HDR/.

\paragraph{Internal primop: reify an info table label into a runtime value}

The only way, in Haskell, to pass a constructor to a primop so that the primop can inspect it, is to lift the constructor into a type-level literal. It's common practice to use a \mintinline{haskellc}/Proxy t/ (the unit type with a phantom type parameter) to pass the type \mintinline{haskellc}/t/ as an input to a function. Unfortunately, due to a quirk of the compiler, primops don't have access to the type of their arguments. They can, however, access their return type. So I'm using a phantom type \mintinline{haskellc}/InfoPtrPlaceholder# t/ as the return type, to pass the contructor as an input!

The gist of this implementation is presented in Listing~\ref{table:impl-reifyInfoPtr}. The primop \mintinline{haskellc}/reifyInfoPtr#/ pattern-matches on the type \mintinline{haskellc}/resTy/ of its return value. In the case it reads a string literal, it resolves the primop call into the label \mintinline{text}/stg_<name>/ (this is used in particular to retrieve \mintinline{haskellc}/stg_IND/ to allocate indirection heap objects). In the case it reads a lifted data constructor, it resolves the primop call into the label which corresponds to the info table pointer of that constructor. The returned \mintinline{haskellc}/InfoPtrPlaceholder# t/ can later be converted back to an \mintinline{haskellc}/Addr#/ using the \mintinline{haskellc}/unsafeCoerceAddr/ function.

As an example, here is how to allocate a hollow \mintinline{haskellc}/¤Just/ constructor in a compact region:

\begin{unbreakable}
{\figtextsize
\begin{minted}{haskellc}
hollowJust ⩴ Maybe a = compactAddHollow#
  compactRegion#
  (unsafeCoerceAddr (reifyInfoPtr# (# #) ⩴ InfoPtrPlaceholder# 'Just ))
\end{minted}
\vspace{-0.8\baselineskip}
}
\end{unbreakable}

\paragraph{Built-in type family to go from a lifted constructor to the associated symbol}

The internal primop \mintinline{haskellc}/reifyInfoPtr#/ that we introduced above takes as input a constructor lifted into a type-level literal, so this is also what \mintinline{haskellc}/fill/ will use to know which constructor it should operate with. But \mintinline{haskellc}/UDestsOf/ have to find the metadata of a constructor in the \mintinline{haskellc}/Generic/ representation of a type, in which only the constructor name appears.

So we added a newUAmpar type family \mintinline{haskellc}/LCtorToSymbol/ inside GHC that inspects its (type-level) parameter representing a constructor, fetches its associated \mintinline{haskellc}/DataCon/ structure, and returns a type-level string (kind \mintinline{haskellc}/Symbol/) carrying the constructor name, as presented in Listing~\ref{table:impl-LCtorToSymbol}.

\begin{listing}[p]
\figtextsize
\begin{minted}{c}
// compactAddHollow#
//   ⩴ Compact# → Addr# → State# RealWorld → (# State# RealWorld, a #)
stg_compactAddHollowzh(P_ compact, W_ info) {
    W_ pp, ptrs, nptrs, size, tag, hp;
    P_ to, p; p = NULL;  // p isn't actually used by ALLOCATE macro
    again: MAYBE_GC(again); STK_CHK_GEN();

    pp = compact + SIZEOF_StgHeader + OFFSET_StgCompactNFData_result;
    ptrs  = TO_W_(%INFO_PTRS(%STD_INFO(info)));
    nptrs  = TO_W_(%INFO_NPTRS(%STD_INFO(info)));
    size = BYTES_TO_WDS(SIZEOF_StgHeader) + ptrs + nptrs;
    
    ALLOCATE(compact, size, p, to, tag);
    P_[pp] = to;
    SET_HDR(to, info, CCS_SYSTEM);
  #if defined(DEBUG)
    ccall verifyCompact(compact);
  #endif
    return (P_[pp]);
}
\end{minted}
\caption{\texttt{compactAddHollow\#} implementation in \texttt{rts/Compact.cmm}}
\label{table:impl-compactAddHollow}
\end{listing}

\begin{listing}[p]
\figtextsize
\begin{minted}{haskellc}
case primop of
  [...]
  ¤ReifyStgInfoPtrOp → \_ →  -- we don't care about the function argument (# #)
    opIntoRegsTy $ \[res] resTy → emitAssign (¤CmmLocal res) $ case resTy of
      -- when 'a' is a Symbol, and extracts the symbol value in 'sym'
      ¤TyConApp _addrLikeTyCon [_typeParamKind, ¤LitTy (¤StrTyLit sym)] →
          ¤CmmLit (¤CmmLabel (
            mkCmmInfoLabel rtsUnitId (fsLit "stg_" `appendFS` sym)))
      -- when 'a' is a lifted data constructor, extracts it as a DataCon
      ¤TyConApp _addrLikeTyCon [_typeParamKind, ¤TyConApp tyCon _]
        | ¤Just dataCon ← isPromotedDataCon_maybe tyCon →
          ¤CmmLit (¤CmmLabel (
            mkConInfoTableLabel (dataConName dataCon) ¤DefinitionSite))
      _ → [...] -- error when no pattern matches
\end{minted}
\caption{\texttt{reifyInfoPtr\#} implementation in \texttt{compiler/GHC/StgToCmm/Prim.hs}}
\label{table:impl-reifyInfoPtr}
\end{listing}

\begin{listing}[p]
\figtextsize
\begin{minted}{haskellc}
matchFamLCtorToSymbol ⩴ [Type] → Maybe (CoAxiomRule, [Type], Type)
matchFamLCtorToSymbol [kind, ty]
  | ¤TyConApp tyCon _ ← ty, ¤Just dataCon ← isPromotedDataCon_maybe tyCon =
      let symbolLit = (mkStrLitTy . occNameFS . occName . getName $ dataCon)
       in ¤Just (axLCtorToSymbolDef, [kind, ty], symbolLit)
matchFamLCtorToSymbol tys = ¤Nothing

axLCtorToSymbolDef =
  mkBinAxiom "LCtorToSymbolDef" typeLCtorToSymbolTyCon ¤Just
    (\case { ¤TyConApp tyCon _ → isPromotedDataCon_maybe tyCon ; _ → ¤Nothing })
    (\_ dataCon → ¤Just (mkStrLitTy . occNameFS . occName . getName $ dataCon))
\end{minted}
\caption{\mintinline{haskellc}/LCtorToSymbol/ implementation in \texttt{compiler/GHC/Builtin/Types/Literal.hs}}
\label{table:impl-LCtorToSymbol}
\end{listing}

\section{Evaluating the performance of DPS programming}\label{sec:benchmark}

\paragraph{Benchmarking methodology}

All over this article, I talked about programs in both naive style and DPS style. With DPS programs, the result is stored in a compact region, which also forces strictness i.e. the structure is automatically in fully evaluated form.

For naive versions, we have a choice to make on how to fully evaluate the result: either force each chunk of the result inside the GC heap (using \mintinline{haskellc}/Control.DeepSeq.force/), or copy the result in a compact region that is strict by default (using \mintinline{haskellc}/Data.Compact.compact/).

In programs where there is no particular long-lived piece of data, having the result of the function copied into a compact region isn't particularly desirable since it will generally inflate memory allocations. So we use \mintinline{haskellc}/force/ to benchmark the naive version of those programs (the associated benchmark names are denoted with a ``*'' suffix).

\begin{figure}[t]\centering
  \hspace*{-1.5cm}\includegraphics[width=16.8cm]{graphics/bench-charts.pdf}
  \caption{Benchmarks performed on AMD EPYC 7401P @ 2.0 GHz (single core, \texttt{-N1 -O2})}
  \label{fig:bench-charts}
\end{figure}

\paragraph{Concatenating lists and difference lists}

We compared three implementations. \\\mintinline{haskellc}/foldr (++)/* has calls to \mintinline{haskellc}/(++)/ nested to the right, giving the most optimal context for list concatenation (it should run in $\mathcal{O}(n)$ time). \mintinline[escapeinside=°°]{haskellc}/foldl' concat°$\lambda$°/* uses function-backed difference lists, and \mintinline{haskellc}/foldl' concatDPS/ uses destin\-ation-backed ones, so both should run in $\mathcal{O}(n)$ even if calls to concat are nested to the left.

We see in part \textbf{A} of Figure~\ref{fig:bench-charts} that the destination-backed difference lists have a comparable memory use as the two other linear implementations, while being quite slower (by a factor 2-4) on all datasets. We would expect better results though for a DPS implementation outside of compact regions because those cause extra copying.

\paragraph{Breadth-first relabeling}\label{par:benchmark-bf-tree-traversal}

We see in part \textbf{B} of Figure~\ref{fig:bench-charts} that the destination-based tree traversal is almost one order of magnitude more efficient, both time-wise and memory-wise, compared to the implementation based on \emph{Phases} applicatives presented in~\cite{gibbons_phases_2023}.

\paragraph{Parsing S-expressions}

In part \textbf{C} of Figure~\ref{fig:bench-charts}, we compare the naive implementation of the S-expression parser and the DPS one (see Section~\ref{ssec:parser-sexpr}). For this particular program, where using compact regions might reduce the future GC load of the application, it is relevant to benchmark the naive version twice: once with \mintinline{haskellc}/force/ and once with \mintinline{haskellc}/compact/.

The DPS version starts by being less efficient than the naive versions for small inputs, but gets an edge as soon as garbage collection kicks in (on datasets of size $\leq 2^{16}$, no garbage collection cycle is required as the heap size stays small).

On the largest dataset ($2^{22} \simeq 4$MiB file), the DPS version still makes about 45\% more allocations than the starred naive version, but uses 35\% less memory at its peak, and more importantly, spends 47$\times$ less time in garbage collection. As a result, the DPS version only takes 0.55-0.65$\times$ the time spent by the naive versions, thanks to garbage collection savings. All of this also indicates that most of the data allocated in the GC heap by the DPS version just lasts one generation and thus can be discarded very early by the GC, without needing to be copied into the next generation, unlike most nodes allocated by the naive versions.

Finally, copying the result of the naive version to a compact region (for future GC savings) incurs a significant time and memory penalty, that the DPS version offers to avoid.

% \subsection{Mapping a function over a list}\label{ssec:benchmark-map}

% It seemed important to also measure the performance of a \mintinline{haskellc}/map/ function implementation using destinations. In a strict functional language such as OCaml, the choice of implementation for \mintinline{haskellc}/map/ is crucial as the naive one makes the stack grow linearly with the size of the processed list. A strict tail-recursive version (\mintinline{haskellc}/mapTR'/) takes $\mathcal{O}(1)$ space, but it requires an extra $\mathcal{O}(n)$ operation at the end of the processing (reversing the accumulator). 

% With destinations, \mintinline{haskellc}/map/ can be implemented in a tail-recursive fashion without the need for the reverse operation (as the list is built in a top-down approach). It can also be implemented as a fold:
% {\figtextsize
% \begin{minted}{haskellc}
% append ⩴ UDest [a] ⊸ a → UDest [a]
% append d x = let !(dh, dt) = fill @'(:) d in fillLeaf x dh ; dt

% mapDPS' _ [] d = fill @'[] d
% mapDPS' f (x : xs) d = let !y = f x ; !d' = append d y in mapDPS' f xs d'

% mapDPSFold' f l dl = fill @'[] (foldl' (\d x → let !y = f x in append d y) d l)
% \end{minted}
% }

% We see in part 4 of Figure~\ref{fig:bench-charts} that the destination-based implementations takes 1.5-4$\times$ more time than \mintinline{haskellc}/map/ and \mintinline{haskellc}/mapTR'/ (depending on the dataset size), but memory-wise both \mintinline{haskellc}/mapDPS'/ and \mintinline{haskellc}/mapDPSFold'/ are more efficient than \mintinline{haskellc}/map/; and \mintinline{haskellc}/mapDPS'/ even manage to make 13\% fewer allocs than \mintinline{haskellc}/mapTR'/ on the largest dataset.

% In OCaml, \mintinline{haskellc}/mapDPS'/ is actually more performant time-wise than \mintinline{haskellc}/mapTR'/ ($0.5-0.85\times$) even for small lists, as detailed in~\cite{bour_tmc_2021}.

\section{Related work}

The idea of functional data structures with write-once holes is not newUAmpar. Minamide already proposed in~\cite{minamide_functional_1998} a variant of $\lambda$-calculus with support for \emph{hole abstractions}, which can be represented in memory by an UAmpar structure with one hole and can be composed efficiently with each other (as with \mintinline{haskellc}/fillComp/ in Figure~\ref{fig:schema-dlist-concat}). With such a framework, it is fully possible to implement destination-backed difference lists for example.

However, in Minamide's work, there is no concept of destination: the hole in a structure can only be filled if one has the structure itself at hand. On the other hand, our approach introduces destinations, as a way to interact with a hole remotely, even when one doesn't have a handle to the associated structure. Because destinations are first-class objects, they can be passed around or stored in collections or other structure, while preserving memory safety. This is the major step forward that our paper presents.

More recently, \cite{protzenko_mezzo_2013} introduced the Mezzo programming language, in which mutable data structures can be freezed into immutable ones after having been completed. This principle is used to some extend in their list standard library module, to mimic a form of DPS programming. An earlier appearance of DPS programming as a mean to achieve better performance in a mutable language can also be seen in~\cite{larus_restructuring_1989}.

Finally, both \cite{shaikhha_destination-passing_2017} and \cite{bour_tmc_2021} use DPS programming to make list or array processing algorithms more efficient in a functional, immutable context, by turning non tail-recursive functions into tail-recursive DPS ones. More importantly, they present an automatized way to go from a naive program to its tail-recursive version. However, holes/destinations are only supported at an intermediary language level, while both~\cite{minamide_functional_1998} and our present work support safe DPS programming in user-land. In a broader context, \cite{lorenzen_fp_2023} presents a system in which linearity is used to identify where destructive updates can be made, so as to reuse the same constructor instead of deallocating and reallocating one; but this optimization technique is still mostly invisible for the user, unlike ours which is made explicit.

\section{Conclusion and future work}

Programming with destinations definitely has a place in the realm of functional programming, as the recent adoption of \emph{Tail Modulo Cons}~\cite{bour_tmc_2021} in the OCaml compiler shows. In this paper, we have shown how destination-passing style programming can be used in user-land in Haskell safely, thanks to a linear type discipline. Adopting DPS programming opens the way for more natural and efficient programs in a variety of contexts, where the major points are being able to build structures in a top-down fashion, manipulating and composing UAmpar structures, and managing holes in these structures through first-class objects (destinations). Our DPS implementation relies only on a few alterations to the compiler, thanks to \emph{compact regions} that are already available as part of GHC. Simultaneously, it allows to build structures in those regions without copying, which wasn't possible before.

There are two limitations that we would like to lift in the future. First, DPS programming could be useful outside of compact regions: destinations could probably be used to manipulate the garbage-collected heap (with proper read barriers in place), or other forms of secluded memory areas that aren't traveled by the GC (RDMA, network serialized buffers, etc.). Secondly, at the moment, the type of \mintinline{haskellc}/fillLeaf/ implies that we can't store destinations (which are always linear) in a difference list implemented as in Section~\ref{ssec:dlist}, whereas we can store them in a regular list or queue (like we do, for instance, in Section~\ref{ssec:bf-tree-traversal}). This unwelcome restriction ensures memory safety but it's quite coarse grain. In the future we'll be trying to have a more fine-grained approach that would still ensure safety.
